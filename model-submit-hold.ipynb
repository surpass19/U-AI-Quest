{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b68216d-b2a0-49d3-bf0c-3f02f1885fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pandas_profiling as pdp\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "#回帰の可視化\n",
    "#関数の処理で必要なライブラリ\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    ExtraTreesRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "\n",
    "import shap\n",
    "# import xgboost\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced296b8-1144-4d56-bd63-bc2d74e5ff8d",
   "metadata": {},
   "source": [
    "# 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dd9fd9d-f204-4c84-b647-bc113b63701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gather_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd031d3-01f7-41a7-abd5-f54a55b95c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gather_function' from '/Users/ryosuke/Desktop/副業/AI Quest/assessment/gather_function.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(gather_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0acb003c-6d50-4565-845e-f201a30da0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_data = pd.read_csv('train.csv')\n",
    "original_test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "495a74fe-9c79-4f33-b2be-dc5505d71722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train)= 55583\n",
      "len(test) 18528\n",
      "0.3333393303707968\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "del train['id']\n",
    "del test['id']\n",
    "\n",
    "print('len(train)=', len(train))\n",
    "print('len(test)', len(test))\n",
    "print(len(test)/len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1253149-c028-4033-a3b6-05b2808de814",
   "metadata": {},
   "source": [
    "# 説明変数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ef9b3b-9754-4bae-b22b-12b8ed15a24f",
   "metadata": {},
   "source": [
    "|カラム|ヘッダ名称|データ型|説明|\n",
    "|-|-|-|-|\n",
    "|0|\tid|\tint| インデックスとして使用|\n",
    "|1|\taccommodates|\tint|\t収容可能人数|\n",
    "|2|\tamenities|\tchar|\tアメニティ|\n",
    "|3|\tbathrooms|\tfloat|\t風呂数|\n",
    "|4|\tbed_type|\tchar|\tベッドの種類|\n",
    "|5|\tbedrooms|\tfloat|\tベッドルーム数|\n",
    "|6|\tbeds|\tfloat|\tベッド数|\n",
    "|7|\tcancellation_policy|\tchar|\tキャンセルポリシー|\n",
    "|8|\tcity|\tchar|\t都市|\n",
    "|9|\tcleaning_fee|\tint|\tクリーニング料金を含むか|\n",
    "|10|\tdescription|\tchar|\t説明|\n",
    "|11|\tfirst_review|\tchar|\t最初のレビュー日|\n",
    "|12|\thost_has_profile_pic|\tint|\tホストの写真があるかどうか|\n",
    "|13|\thost_identity_verified|\tint|\tホストの身元確認が取れているか|\n",
    "|14|\thost_response_rate|\tchar|\tホストの返信率|\n",
    "|15|\thost_since|\tchar|\tホストの登録日|\n",
    "|16|\tinstant_bookable|\tchar|\t即時予約可能か|\n",
    "|17|\tlast_review\t|char|\t最後のレビュー日|\n",
    "|18|\tlatitude|\tfloat|\t緯度|\n",
    "|19|longitude|\tfloat|\t経度|\n",
    "|20|\tname|\tchar|\t物件名|\n",
    "|21|\tneighbourhood|\tchar|\t近隣情報|\n",
    "|22|\tnumber_of_reviews|\tint|\tレビュー数|\n",
    "|23|\tproperty_type|\tchar|\t物件の種類|\n",
    "|24|\treview_scores_rating|\tfloat|\tレビュースコア|\n",
    "|25|\troom_type|\tchar|\t部屋の種類|\n",
    "|26|\tthumbnail_url|\tchar|\tサムネイル画像リンク|\n",
    "|27|\tzipcode|\tint|\t郵便番号|\n",
    "|28|    y| float|\t宿泊価格|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9883c9c-7e4b-4584-b022-fcd6f44a5c7a",
   "metadata": {},
   "source": [
    "# トレーニングデータの処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b8d1488-8165-4c60-bb8e-a9ee2a3aaea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train['y']\n",
    "train_X = train.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76992950-5e73-4e3a-96fc-569d1fa4e1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 86/86 [00:02<00:00, 29.61it/s]\n"
     ]
    }
   ],
   "source": [
    "train_X_addEDA, max_amenities_list = gather_function.preprocessing(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ae5b6bc-5b52-4cd8-8c8b-c382a094288d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55583 entries, 0 to 55582\n",
      "Data columns (total 99 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   accommodates                   55583 non-null  int64  \n",
      " 1   bathrooms                      55583 non-null  int64  \n",
      " 2   bed_type                       55583 non-null  object \n",
      " 3   bedrooms                       55583 non-null  int64  \n",
      " 4   beds                           55583 non-null  int64  \n",
      " 5   cancellation_policy            55583 non-null  object \n",
      " 6   city                           55583 non-null  object \n",
      " 7   cleaning_fee                   55583 non-null  object \n",
      " 8   host_has_profile_pic           55583 non-null  object \n",
      " 9   host_identity_verified         55583 non-null  object \n",
      " 10  host_response_rate             55583 non-null  int64  \n",
      " 11  instant_bookable               55583 non-null  object \n",
      " 12  latitude                       55583 non-null  float64\n",
      " 13  longitude                      55583 non-null  float64\n",
      " 14  neighbourhood                  55583 non-null  object \n",
      " 15  number_of_reviews              55583 non-null  int64  \n",
      " 16  property_type                  55583 non-null  object \n",
      " 17  review_scores_rating           43027 non-null  float64\n",
      " 18  room_type                      55583 non-null  object \n",
      " 19  thumbnail_url                  49438 non-null  float64\n",
      " 20  bathrooms_par_1                55583 non-null  float64\n",
      " 21  bedrooms_par_1                 55583 non-null  float64\n",
      " 22  beds_par_1                     55583 non-null  float64\n",
      " 23  bed_par_bedrooms               55558 non-null  float64\n",
      " 24  latitude_int                   55583 non-null  int64  \n",
      " 25  longitude_int                  55583 non-null  int64  \n",
      " 26  review_score_total             55583 non-null  float64\n",
      " 27  review_score_weight            55583 non-null  float64\n",
      " 28  amenities_count                55583 non-null  int64  \n",
      " 29  TV                             55583 non-null  object \n",
      " 30  Cable TV                       55583 non-null  object \n",
      " 31  Wireless Internet              55583 non-null  object \n",
      " 32  Air conditioning               55583 non-null  object \n",
      " 33  Kitchen                        55583 non-null  object \n",
      " 34  Free parking on premises       55583 non-null  object \n",
      " 35  Pets allowed                   55583 non-null  object \n",
      " 36  Breakfast                      55583 non-null  object \n",
      " 37  Elevator                       55583 non-null  object \n",
      " 38  Hot tub                        55583 non-null  object \n",
      " 39  Indoor fireplace               55583 non-null  object \n",
      " 40  Heating                        55583 non-null  object \n",
      " 41  Family/kid friendly            55583 non-null  object \n",
      " 42  Suitable for events            55583 non-null  object \n",
      " 43  Washer                         55583 non-null  object \n",
      " 44  Dryer                          55583 non-null  object \n",
      " 45  Smoke detector                 55583 non-null  object \n",
      " 46  Carbon monoxide detector       55583 non-null  object \n",
      " 47  First aid kit                  55583 non-null  object \n",
      " 48  Safety card                    55583 non-null  object \n",
      " 49  Fire extinguisher              55583 non-null  object \n",
      " 50  Essentials                     55583 non-null  object \n",
      " 51  Shampoo                        55583 non-null  object \n",
      " 52  Lock on bedroom door           55583 non-null  object \n",
      " 53  Hangers                        55583 non-null  object \n",
      " 54  Hair dryer                     55583 non-null  object \n",
      " 55  Iron                           55583 non-null  object \n",
      " 56  Laptop friendly workspace      55583 non-null  object \n",
      " 57  Self Check-In                  55583 non-null  object \n",
      " 58  Keypad                         55583 non-null  object \n",
      " 59  Private entrance               55583 non-null  object \n",
      " 60  Baby monitor                   55583 non-null  object \n",
      " 61  Bathtub                        55583 non-null  object \n",
      " 62  Baby bath                      55583 non-null  object \n",
      " 63  Changing table                 55583 non-null  object \n",
      " 64  Children’s books and toys      55583 non-null  object \n",
      " 65  Window guards                  55583 non-null  object \n",
      " 66  Table corner guards            55583 non-null  object \n",
      " 67  Fireplace guards               55583 non-null  object \n",
      " 68  Babysitter recommendations     55583 non-null  object \n",
      " 69  Crib                           55583 non-null  object \n",
      " 70  Room-darkening shades          55583 non-null  object \n",
      " 71  Game console                   55583 non-null  object \n",
      " 72  Hot water                      55583 non-null  object \n",
      " 73  Bed linens                     55583 non-null  object \n",
      " 74  Extra pillows and blankets     55583 non-null  object \n",
      " 75  Ethernet connection            55583 non-null  object \n",
      " 76  Pocket wifi                    55583 non-null  object \n",
      " 77  Microwave                      55583 non-null  object \n",
      " 78  Coffee maker                   55583 non-null  object \n",
      " 79  Refrigerator                   55583 non-null  object \n",
      " 80  Dishwasher                     55583 non-null  object \n",
      " 81  Dishes and silverware          55583 non-null  object \n",
      " 82  Cooking basics                 55583 non-null  object \n",
      " 83  Oven                           55583 non-null  object \n",
      " 84  Stove                          55583 non-null  object \n",
      " 85  EV charger                     55583 non-null  object \n",
      " 86  Single level home              55583 non-null  object \n",
      " 87  BBQ grill                      55583 non-null  object \n",
      " 88  Patio or balcony               55583 non-null  object \n",
      " 89  Garden or backyard             55583 non-null  object \n",
      " 90  Beach essentials               55583 non-null  object \n",
      " 91  Luggage dropoff allowed        55583 non-null  object \n",
      " 92  Long term stays allowed        55583 non-null  object \n",
      " 93  Wide hallway clearance         55583 non-null  object \n",
      " 94  Step-free access               55583 non-null  object \n",
      " 95  Wide doorway                   55583 non-null  object \n",
      " 96  Flat                           55583 non-null  object \n",
      " 97   smooth pathway to front door  55583 non-null  object \n",
      " 98  Well-lit path to entrance      55583 non-null  object \n",
      "dtypes: float64(10), int64(9), object(80)\n",
      "memory usage: 42.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_X_addEDA[train_X_addEDA.columns[:99]].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6014f5-2968-4455-8c9e-5f4601ccb0c7",
   "metadata": {},
   "source": [
    "## 対数変換した説明変数を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32dea8cf-1c00-4b98-bfff-80b6aade7e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beds_par_1', 'bathrooms_par_1', 'bathrooms', 'review_score_total', 'number_of_reviews', 'beds', 'accommodates', 'bedrooms', 'bedrooms_par_1', 'rare_amenities_count', 'amenities_count', 'latitude', 'host_response_rate_weight', 'review_score_weight', 'description_word_count', 'host_response_rate']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X_addEDA_log, num_col_feat_list, pt = gather_function.logarithmic_transformation(train_X_addEDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04079db4-256a-4d0f-a3f5-8df3b8be227a",
   "metadata": {},
   "source": [
    "## カテゴリー変数化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13c4e022-2170-4edd-a67f-b283e743c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot変換をせずにlabelencodingする → カテゴリ変数化\n",
    "categorical_columns = ['neighbourhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46fd5896-0381-44e8-97ae-2d8b906047b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 691.67it/s]\n"
     ]
    }
   ],
   "source": [
    "train_X_addEDA_log_dummy = gather_function.process_categorical(train_X_addEDA_log, categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f45744a1-94ba-40bf-808d-342bf668f7e9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55583 entries, 0 to 55582\n",
      "Data columns (total 99 columns):\n",
      " #   Column                               Non-Null Count  Dtype   \n",
      "---  ------                               --------------  -----   \n",
      " 0   accommodates                         55583 non-null  int64   \n",
      " 1   bathrooms                            55583 non-null  int64   \n",
      " 2   bedrooms                             55583 non-null  int64   \n",
      " 3   beds                                 55583 non-null  int64   \n",
      " 4   host_response_rate                   55583 non-null  int64   \n",
      " 5   latitude                             55583 non-null  float64 \n",
      " 6   longitude                            55583 non-null  float64 \n",
      " 7   neighbourhood                        55583 non-null  category\n",
      " 8   number_of_reviews                    55583 non-null  int64   \n",
      " 9   review_scores_rating                 43027 non-null  float64 \n",
      " 10  thumbnail_url                        49438 non-null  float64 \n",
      " 11  bathrooms_par_1                      55583 non-null  float64 \n",
      " 12  bedrooms_par_1                       55583 non-null  float64 \n",
      " 13  beds_par_1                           55583 non-null  float64 \n",
      " 14  bed_par_bedrooms                     55558 non-null  float64 \n",
      " 15  latitude_int                         55583 non-null  int64   \n",
      " 16  longitude_int                        55583 non-null  int64   \n",
      " 17  review_score_total                   55583 non-null  float64 \n",
      " 18  review_score_weight                  55583 non-null  float64 \n",
      " 19  amenities_count                      55583 non-null  int64   \n",
      " 20  rare_amenities_count                 55583 non-null  int64   \n",
      " 21  description_word_count               55583 non-null  int64   \n",
      " 22  host_response_rate_weight            55583 non-null  float64 \n",
      " 23  first_review_Year                    43675 non-null  float64 \n",
      " 24  first_review_Month                   43675 non-null  float64 \n",
      " 25  first_review_Day                     43675 non-null  float64 \n",
      " 26  BusinessOld                          43675 non-null  float64 \n",
      " 27  host_since_Year                      55435 non-null  float64 \n",
      " 28  host_since_Month                     55435 non-null  float64 \n",
      " 29  host_since_Day                       55435 non-null  float64 \n",
      " 30  BusinessOld2                         55435 non-null  float64 \n",
      " 31  first_reviewOld                      43562 non-null  float64 \n",
      " 32  last_review_Year                     43703 non-null  float64 \n",
      " 33  last_review_Month                    43703 non-null  float64 \n",
      " 34  last_review_Day                      43703 non-null  float64 \n",
      " 35  BusinessOld3                         43703 non-null  float64 \n",
      " 36  BusinessUpdate                       43703 non-null  float64 \n",
      " 37  BusinessPeriod                       43675 non-null  float64 \n",
      " 38  zipcode_int                          55583 non-null  int64   \n",
      " 39  Log_beds_par_1                       55583 non-null  float64 \n",
      " 40  Log_bathrooms_par_1                  55583 non-null  float64 \n",
      " 41  Log_bathrooms                        55583 non-null  float64 \n",
      " 42  Log_review_score_total               55583 non-null  float64 \n",
      " 43  Log_number_of_reviews                55583 non-null  float64 \n",
      " 44  Log_beds                             55583 non-null  float64 \n",
      " 45  Log_accommodates                     55583 non-null  float64 \n",
      " 46  Log_bedrooms                         55583 non-null  float64 \n",
      " 47  Log_bedrooms_par_1                   55583 non-null  float64 \n",
      " 48  Log_rare_amenities_count             55583 non-null  float64 \n",
      " 49  Log_amenities_count                  55583 non-null  float64 \n",
      " 50  Log_latitude                         55583 non-null  float64 \n",
      " 51  Log_host_response_rate_weight        55583 non-null  float64 \n",
      " 52  Log_review_score_weight              55583 non-null  float64 \n",
      " 53  Log_description_word_count           55583 non-null  float64 \n",
      " 54  Log_host_response_rate               55583 non-null  float64 \n",
      " 55  bed_type_Couch                       55583 non-null  uint8   \n",
      " 56  bed_type_Futon                       55583 non-null  uint8   \n",
      " 57  bed_type_Pull-out Sofa               55583 non-null  uint8   \n",
      " 58  bed_type_Real Bed                    55583 non-null  uint8   \n",
      " 59  cancellation_policy_moderate         55583 non-null  uint8   \n",
      " 60  cancellation_policy_strict           55583 non-null  uint8   \n",
      " 61  cancellation_policy_super_strict_30  55583 non-null  uint8   \n",
      " 62  cancellation_policy_super_strict_60  55583 non-null  uint8   \n",
      " 63  city_Chicago                         55583 non-null  uint8   \n",
      " 64  city_DC                              55583 non-null  uint8   \n",
      " 65  city_LA                              55583 non-null  uint8   \n",
      " 66  city_NYC                             55583 non-null  uint8   \n",
      " 67  city_SF                              55583 non-null  uint8   \n",
      " 68  cleaning_fee_t                       55583 non-null  uint8   \n",
      " 69  host_has_profile_pic_f               55583 non-null  uint8   \n",
      " 70  host_has_profile_pic_t               55583 non-null  uint8   \n",
      " 71  host_identity_verified_f             55583 non-null  uint8   \n",
      " 72  host_identity_verified_t             55583 non-null  uint8   \n",
      " 73  instant_bookable_t                   55583 non-null  uint8   \n",
      " 74  property_type_Bed & Breakfast        55583 non-null  uint8   \n",
      " 75  property_type_Boat                   55583 non-null  uint8   \n",
      " 76  property_type_Boutique hotel         55583 non-null  uint8   \n",
      " 77  property_type_Bungalow               55583 non-null  uint8   \n",
      " 78  property_type_Cabin                  55583 non-null  uint8   \n",
      " 79  property_type_Camper/RV              55583 non-null  uint8   \n",
      " 80  property_type_Casa particular        55583 non-null  uint8   \n",
      " 81  property_type_Castle                 55583 non-null  uint8   \n",
      " 82  property_type_Cave                   55583 non-null  uint8   \n",
      " 83  property_type_Chalet                 55583 non-null  uint8   \n",
      " 84  property_type_Condominium            55583 non-null  uint8   \n",
      " 85  property_type_Dorm                   55583 non-null  uint8   \n",
      " 86  property_type_Earth House            55583 non-null  uint8   \n",
      " 87  property_type_Guest suite            55583 non-null  uint8   \n",
      " 88  property_type_Guesthouse             55583 non-null  uint8   \n",
      " 89  property_type_Hostel                 55583 non-null  uint8   \n",
      " 90  property_type_House                  55583 non-null  uint8   \n",
      " 91  property_type_Hut                    55583 non-null  uint8   \n",
      " 92  property_type_In-law                 55583 non-null  uint8   \n",
      " 93  property_type_Island                 55583 non-null  uint8   \n",
      " 94  property_type_Loft                   55583 non-null  uint8   \n",
      " 95  property_type_Other                  55583 non-null  uint8   \n",
      " 96  property_type_Parking Space          55583 non-null  uint8   \n",
      " 97  property_type_Serviced apartment     55583 non-null  uint8   \n",
      " 98  property_type_Tent                   55583 non-null  uint8   \n",
      "dtypes: category(1), float64(42), int64(12), uint8(44)\n",
      "memory usage: 25.4 MB\n"
     ]
    }
   ],
   "source": [
    "train_X_addEDA_log_dummy[train_X_addEDA_log_dummy.columns[:99]].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ce0c33b-f9ec-4c3a-8b5f-fb3f7854ea81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>thumbnail_url</th>\n",
       "      <th>bathrooms_par_1</th>\n",
       "      <th>bedrooms_par_1</th>\n",
       "      <th>beds_par_1</th>\n",
       "      <th>bed_par_bedrooms</th>\n",
       "      <th>latitude_int</th>\n",
       "      <th>longitude_int</th>\n",
       "      <th>review_score_total</th>\n",
       "      <th>review_score_weight</th>\n",
       "      <th>amenities_count</th>\n",
       "      <th>rare_amenities_count</th>\n",
       "      <th>description_word_count</th>\n",
       "      <th>host_response_rate_weight</th>\n",
       "      <th>first_review_Year</th>\n",
       "      <th>first_review_Month</th>\n",
       "      <th>first_review_Day</th>\n",
       "      <th>BusinessOld</th>\n",
       "      <th>host_since_Year</th>\n",
       "      <th>host_since_Month</th>\n",
       "      <th>host_since_Day</th>\n",
       "      <th>BusinessOld2</th>\n",
       "      <th>first_reviewOld</th>\n",
       "      <th>last_review_Year</th>\n",
       "      <th>last_review_Month</th>\n",
       "      <th>last_review_Day</th>\n",
       "      <th>BusinessOld3</th>\n",
       "      <th>BusinessUpdate</th>\n",
       "      <th>BusinessPeriod</th>\n",
       "      <th>zipcode_int</th>\n",
       "      <th>Log_beds_par_1</th>\n",
       "      <th>Log_bathrooms_par_1</th>\n",
       "      <th>Log_bathrooms</th>\n",
       "      <th>Log_review_score_total</th>\n",
       "      <th>Log_number_of_reviews</th>\n",
       "      <th>Log_beds</th>\n",
       "      <th>Log_accommodates</th>\n",
       "      <th>Log_bedrooms</th>\n",
       "      <th>Log_bedrooms_par_1</th>\n",
       "      <th>Log_rare_amenities_count</th>\n",
       "      <th>Log_amenities_count</th>\n",
       "      <th>Log_latitude</th>\n",
       "      <th>Log_host_response_rate_weight</th>\n",
       "      <th>Log_review_score_weight</th>\n",
       "      <th>Log_description_word_count</th>\n",
       "      <th>Log_host_response_rate</th>\n",
       "      <th>bed_type_Couch</th>\n",
       "      <th>bed_type_Futon</th>\n",
       "      <th>bed_type_Pull-out Sofa</th>\n",
       "      <th>bed_type_Real Bed</th>\n",
       "      <th>cancellation_policy_moderate</th>\n",
       "      <th>cancellation_policy_strict</th>\n",
       "      <th>cancellation_policy_super_strict_30</th>\n",
       "      <th>cancellation_policy_super_strict_60</th>\n",
       "      <th>city_Chicago</th>\n",
       "      <th>city_DC</th>\n",
       "      <th>city_LA</th>\n",
       "      <th>city_NYC</th>\n",
       "      <th>city_SF</th>\n",
       "      <th>cleaning_fee_t</th>\n",
       "      <th>host_has_profile_pic_f</th>\n",
       "      <th>host_has_profile_pic_t</th>\n",
       "      <th>host_identity_verified_f</th>\n",
       "      <th>host_identity_verified_t</th>\n",
       "      <th>instant_bookable_t</th>\n",
       "      <th>property_type_Bed &amp; Breakfast</th>\n",
       "      <th>property_type_Boat</th>\n",
       "      <th>property_type_Boutique hotel</th>\n",
       "      <th>property_type_Bungalow</th>\n",
       "      <th>property_type_Cabin</th>\n",
       "      <th>property_type_Camper/RV</th>\n",
       "      <th>property_type_Casa particular</th>\n",
       "      <th>property_type_Castle</th>\n",
       "      <th>property_type_Cave</th>\n",
       "      <th>property_type_Chalet</th>\n",
       "      <th>property_type_Condominium</th>\n",
       "      <th>property_type_Dorm</th>\n",
       "      <th>property_type_Earth House</th>\n",
       "      <th>property_type_Guest suite</th>\n",
       "      <th>property_type_Guesthouse</th>\n",
       "      <th>property_type_Hostel</th>\n",
       "      <th>property_type_House</th>\n",
       "      <th>property_type_Hut</th>\n",
       "      <th>property_type_In-law</th>\n",
       "      <th>property_type_Island</th>\n",
       "      <th>property_type_Loft</th>\n",
       "      <th>property_type_Other</th>\n",
       "      <th>property_type_Parking Space</th>\n",
       "      <th>property_type_Serviced apartment</th>\n",
       "      <th>property_type_Tent</th>\n",
       "      <th>property_type_Timeshare</th>\n",
       "      <th>property_type_Tipi</th>\n",
       "      <th>property_type_Townhouse</th>\n",
       "      <th>property_type_Train</th>\n",
       "      <th>property_type_Treehouse</th>\n",
       "      <th>property_type_Vacation home</th>\n",
       "      <th>property_type_Villa</th>\n",
       "      <th>property_type_Yurt</th>\n",
       "      <th>room_type_Private room</th>\n",
       "      <th>room_type_Shared room</th>\n",
       "      <th>TV_True</th>\n",
       "      <th>Cable TV_True</th>\n",
       "      <th>Wireless Internet_True</th>\n",
       "      <th>Air conditioning_True</th>\n",
       "      <th>Kitchen_True</th>\n",
       "      <th>Free parking on premises_True</th>\n",
       "      <th>Pets allowed_True</th>\n",
       "      <th>Breakfast_True</th>\n",
       "      <th>Elevator_True</th>\n",
       "      <th>Hot tub_True</th>\n",
       "      <th>Indoor fireplace_True</th>\n",
       "      <th>Heating_True</th>\n",
       "      <th>Family/kid friendly_True</th>\n",
       "      <th>Suitable for events_True</th>\n",
       "      <th>Washer_True</th>\n",
       "      <th>Dryer_True</th>\n",
       "      <th>Smoke detector_True</th>\n",
       "      <th>Carbon monoxide detector_True</th>\n",
       "      <th>First aid kit_True</th>\n",
       "      <th>Safety card_True</th>\n",
       "      <th>Fire extinguisher_True</th>\n",
       "      <th>Essentials_True</th>\n",
       "      <th>Shampoo_True</th>\n",
       "      <th>Lock on bedroom door_True</th>\n",
       "      <th>Hangers_True</th>\n",
       "      <th>Hair dryer_True</th>\n",
       "      <th>Iron_True</th>\n",
       "      <th>Laptop friendly workspace_True</th>\n",
       "      <th>Self Check-In_True</th>\n",
       "      <th>Keypad_True</th>\n",
       "      <th>Private entrance_True</th>\n",
       "      <th>Baby monitor_True</th>\n",
       "      <th>Bathtub_True</th>\n",
       "      <th>Baby bath_True</th>\n",
       "      <th>Changing table_True</th>\n",
       "      <th>Children’s books and toys_True</th>\n",
       "      <th>Window guards_True</th>\n",
       "      <th>Table corner guards_True</th>\n",
       "      <th>Fireplace guards_True</th>\n",
       "      <th>Babysitter recommendations_True</th>\n",
       "      <th>Crib_True</th>\n",
       "      <th>Room-darkening shades_True</th>\n",
       "      <th>Game console_True</th>\n",
       "      <th>Hot water_True</th>\n",
       "      <th>Bed linens_True</th>\n",
       "      <th>Extra pillows and blankets_True</th>\n",
       "      <th>Ethernet connection_True</th>\n",
       "      <th>Pocket wifi_True</th>\n",
       "      <th>Microwave_True</th>\n",
       "      <th>Coffee maker_True</th>\n",
       "      <th>Refrigerator_True</th>\n",
       "      <th>Dishwasher_True</th>\n",
       "      <th>Dishes and silverware_True</th>\n",
       "      <th>Cooking basics_True</th>\n",
       "      <th>Oven_True</th>\n",
       "      <th>Stove_True</th>\n",
       "      <th>EV charger_True</th>\n",
       "      <th>Single level home_True</th>\n",
       "      <th>BBQ grill_True</th>\n",
       "      <th>Patio or balcony_True</th>\n",
       "      <th>Garden or backyard_True</th>\n",
       "      <th>Beach essentials_True</th>\n",
       "      <th>Luggage dropoff allowed_True</th>\n",
       "      <th>Long term stays allowed_True</th>\n",
       "      <th>Wide hallway clearance_True</th>\n",
       "      <th>Step-free access_True</th>\n",
       "      <th>Wide doorway_True</th>\n",
       "      <th>Flat_True</th>\n",
       "      <th>smooth pathway to front door_True</th>\n",
       "      <th>Well-lit path to entrance_True</th>\n",
       "      <th>Disabled parking spot_True</th>\n",
       "      <th>Wide clearance to bed_True</th>\n",
       "      <th>Accessible-height bed_True</th>\n",
       "      <th>Fixed grab bars for shower &amp; toilet_True</th>\n",
       "      <th>Bathtub with shower chair_True</th>\n",
       "      <th>Roll-in shower with chair_True</th>\n",
       "      <th>Accessible-height toilet_True</th>\n",
       "      <th>Wide clearance to shower &amp; toilet_True</th>\n",
       "      <th>Wide entryway_True</th>\n",
       "      <th>Waterfront_True</th>\n",
       "      <th>Handheld shower head_True</th>\n",
       "      <th>thumbnail_url_str_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>33.788931</td>\n",
       "      <td>-118.154761</td>\n",
       "      <td>375</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33</td>\n",
       "      <td>-118</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.594059</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2809.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3054.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2809.0</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90804</td>\n",
       "      <td>0.555377</td>\n",
       "      <td>-0.482101</td>\n",
       "      <td>1.687346</td>\n",
       "      <td>-0.634382</td>\n",
       "      <td>-0.833205</td>\n",
       "      <td>1.729006</td>\n",
       "      <td>1.393625</td>\n",
       "      <td>-0.180486</td>\n",
       "      <td>-1.190409</td>\n",
       "      <td>-1.670391</td>\n",
       "      <td>-1.659013</td>\n",
       "      <td>-1.398199</td>\n",
       "      <td>-1.609670</td>\n",
       "      <td>-0.307101</td>\n",
       "      <td>-1.316664</td>\n",
       "      <td>-1.666098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>38.934810</td>\n",
       "      <td>-76.978190</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38</td>\n",
       "      <td>-76</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.917431</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>406</td>\n",
       "      <td>91.743119</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2856.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2858.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3056.0</td>\n",
       "      <td>1735.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>20018</td>\n",
       "      <td>-0.250963</td>\n",
       "      <td>0.298715</td>\n",
       "      <td>-0.301546</td>\n",
       "      <td>0.324262</td>\n",
       "      <td>0.286462</td>\n",
       "      <td>-0.716402</td>\n",
       "      <td>-0.452805</td>\n",
       "      <td>-0.180486</td>\n",
       "      <td>0.227622</td>\n",
       "      <td>0.639636</td>\n",
       "      <td>0.672490</td>\n",
       "      <td>-0.053060</td>\n",
       "      <td>0.781907</td>\n",
       "      <td>0.940666</td>\n",
       "      <td>-1.252478</td>\n",
       "      <td>0.655069</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>40.695118</td>\n",
       "      <td>-73.926240</td>\n",
       "      <td>82</td>\n",
       "      <td>27</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>-73</td>\n",
       "      <td>2241.0</td>\n",
       "      <td>0.653543</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>467</td>\n",
       "      <td>78.740157</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2767.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3191.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.250963</td>\n",
       "      <td>1.619787</td>\n",
       "      <td>1.687346</td>\n",
       "      <td>0.749492</td>\n",
       "      <td>0.912130</td>\n",
       "      <td>-0.716402</td>\n",
       "      <td>-0.452805</td>\n",
       "      <td>-0.180486</td>\n",
       "      <td>0.227622</td>\n",
       "      <td>1.391175</td>\n",
       "      <td>1.562229</td>\n",
       "      <td>0.696107</td>\n",
       "      <td>0.547844</td>\n",
       "      <td>-0.113166</td>\n",
       "      <td>-1.097310</td>\n",
       "      <td>0.655069</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>37.796728</td>\n",
       "      <td>-122.411906</td>\n",
       "      <td>385</td>\n",
       "      <td>38</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37</td>\n",
       "      <td>-122</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>0.688406</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>1000</td>\n",
       "      <td>72.463768</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3212.0</td>\n",
       "      <td>1579.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>94133</td>\n",
       "      <td>-0.250963</td>\n",
       "      <td>0.298715</td>\n",
       "      <td>-0.301546</td>\n",
       "      <td>0.996645</td>\n",
       "      <td>1.099904</td>\n",
       "      <td>-0.716402</td>\n",
       "      <td>-0.452805</td>\n",
       "      <td>-0.180486</td>\n",
       "      <td>0.227622</td>\n",
       "      <td>-0.000382</td>\n",
       "      <td>0.122423</td>\n",
       "      <td>-0.446329</td>\n",
       "      <td>0.430018</td>\n",
       "      <td>0.007585</td>\n",
       "      <td>0.782058</td>\n",
       "      <td>0.655069</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>40.785050</td>\n",
       "      <td>-73.974691</td>\n",
       "      <td>547</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>-73</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "      <td>95.238095</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2452.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2578.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3219.0</td>\n",
       "      <td>1572.0</td>\n",
       "      <td>767.0</td>\n",
       "      <td>10024</td>\n",
       "      <td>-0.250963</td>\n",
       "      <td>0.298715</td>\n",
       "      <td>-0.301546</td>\n",
       "      <td>0.080340</td>\n",
       "      <td>-0.049208</td>\n",
       "      <td>-0.716402</td>\n",
       "      <td>-0.452805</td>\n",
       "      <td>-0.180486</td>\n",
       "      <td>0.227622</td>\n",
       "      <td>-0.233947</td>\n",
       "      <td>0.122423</td>\n",
       "      <td>0.739536</td>\n",
       "      <td>0.842774</td>\n",
       "      <td>1.105758</td>\n",
       "      <td>0.782058</td>\n",
       "      <td>0.655069</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accommodates  bathrooms  bedrooms  beds  host_response_rate   latitude  \\\n",
       "0             6          2         1     4                   0  33.788931   \n",
       "1             2          1         1     1                 100  38.934810   \n",
       "2             2          2         1     1                 100  40.695118   \n",
       "3             2          1         1     1                 100  37.796728   \n",
       "4             2          1         1     1                 100  40.785050   \n",
       "\n",
       "    longitude neighbourhood  number_of_reviews  review_scores_rating  \\\n",
       "0 -118.154761           375                  1                  60.0   \n",
       "1  -76.978190            72                  9                 100.0   \n",
       "2  -73.926240            82                 27                  83.0   \n",
       "3 -122.411906           385                 38                  95.0   \n",
       "4  -73.974691           547                  5                 100.0   \n",
       "\n",
       "   thumbnail_url  bathrooms_par_1  bedrooms_par_1  beds_par_1  \\\n",
       "0            NaN         0.333333        0.166667    0.666667   \n",
       "1            1.0         0.500000        0.500000    0.500000   \n",
       "2            1.0         1.000000        0.500000    0.500000   \n",
       "3            NaN         0.500000        0.500000    0.500000   \n",
       "4            1.0         0.500000        0.500000    0.500000   \n",
       "\n",
       "   bed_par_bedrooms  latitude_int  longitude_int  review_score_total  \\\n",
       "0               4.0            33           -118                60.0   \n",
       "1               1.0            38            -76               900.0   \n",
       "2               1.0            40            -73              2241.0   \n",
       "3               1.0            37           -122              3610.0   \n",
       "4               1.0            40            -73               500.0   \n",
       "\n",
       "   review_score_weight  amenities_count  rare_amenities_count  \\\n",
       "0             0.594059                7                     6   \n",
       "1             0.917431               22                    24   \n",
       "2             0.653543               29                    32   \n",
       "3             0.688406               18                    18   \n",
       "4             0.952381               18                    16   \n",
       "\n",
       "   description_word_count  host_response_rate_weight  first_review_Year  \\\n",
       "0                     379                   0.000000             2016.0   \n",
       "1                     406                  91.743119             2016.0   \n",
       "2                     467                  78.740157             2016.0   \n",
       "3                    1000                  72.463768             2014.0   \n",
       "4                    1000                  95.238095             2015.0   \n",
       "\n",
       "   first_review_Month  first_review_Day  BusinessOld  host_since_Year  \\\n",
       "0                 7.0              27.0       2809.0           2016.0   \n",
       "1                 9.0              12.0       2856.0           2015.0   \n",
       "2                 6.0              15.0       2767.0           2016.0   \n",
       "3                 3.0              15.0       1944.0           2012.0   \n",
       "4                 8.0               5.0       2452.0           2015.0   \n",
       "\n",
       "   host_since_Month  host_since_Day  BusinessOld2  first_reviewOld  \\\n",
       "0               7.0            13.0        3054.0             14.0   \n",
       "1              12.0            30.0        2858.0            257.0   \n",
       "2               5.0            21.0        3001.0             25.0   \n",
       "3               6.0            19.0        1569.0            634.0   \n",
       "4               3.0            25.0        2578.0            133.0   \n",
       "\n",
       "   last_review_Year  last_review_Month  last_review_Day  BusinessOld3  \\\n",
       "0            2016.0                7.0             27.0        2809.0   \n",
       "1            2017.0                3.0             31.0        3056.0   \n",
       "2            2017.0                8.0             13.0        3191.0   \n",
       "3            2017.0                9.0              3.0        3212.0   \n",
       "4            2017.0                9.0             10.0        3219.0   \n",
       "\n",
       "   BusinessUpdate  BusinessPeriod  zipcode_int  Log_beds_par_1  \\\n",
       "0          1982.0             0.0        90804        0.555377   \n",
       "1          1735.0           200.0        20018       -0.250963   \n",
       "2          1600.0           424.0            0       -0.250963   \n",
       "3          1579.0          1268.0        94133       -0.250963   \n",
       "4          1572.0           767.0        10024       -0.250963   \n",
       "\n",
       "   Log_bathrooms_par_1  Log_bathrooms  Log_review_score_total  \\\n",
       "0            -0.482101       1.687346               -0.634382   \n",
       "1             0.298715      -0.301546                0.324262   \n",
       "2             1.619787       1.687346                0.749492   \n",
       "3             0.298715      -0.301546                0.996645   \n",
       "4             0.298715      -0.301546                0.080340   \n",
       "\n",
       "   Log_number_of_reviews  Log_beds  Log_accommodates  Log_bedrooms  \\\n",
       "0              -0.833205  1.729006          1.393625     -0.180486   \n",
       "1               0.286462 -0.716402         -0.452805     -0.180486   \n",
       "2               0.912130 -0.716402         -0.452805     -0.180486   \n",
       "3               1.099904 -0.716402         -0.452805     -0.180486   \n",
       "4              -0.049208 -0.716402         -0.452805     -0.180486   \n",
       "\n",
       "   Log_bedrooms_par_1  Log_rare_amenities_count  Log_amenities_count  \\\n",
       "0           -1.190409                 -1.670391            -1.659013   \n",
       "1            0.227622                  0.639636             0.672490   \n",
       "2            0.227622                  1.391175             1.562229   \n",
       "3            0.227622                 -0.000382             0.122423   \n",
       "4            0.227622                 -0.233947             0.122423   \n",
       "\n",
       "   Log_latitude  Log_host_response_rate_weight  Log_review_score_weight  \\\n",
       "0     -1.398199                      -1.609670                -0.307101   \n",
       "1     -0.053060                       0.781907                 0.940666   \n",
       "2      0.696107                       0.547844                -0.113166   \n",
       "3     -0.446329                       0.430018                 0.007585   \n",
       "4      0.739536                       0.842774                 1.105758   \n",
       "\n",
       "   Log_description_word_count  Log_host_response_rate  bed_type_Couch  \\\n",
       "0                   -1.316664               -1.666098               0   \n",
       "1                   -1.252478                0.655069               0   \n",
       "2                   -1.097310                0.655069               0   \n",
       "3                    0.782058                0.655069               0   \n",
       "4                    0.782058                0.655069               0   \n",
       "\n",
       "   bed_type_Futon  bed_type_Pull-out Sofa  bed_type_Real Bed  \\\n",
       "0               0                       0                  1   \n",
       "1               0                       0                  1   \n",
       "2               0                       0                  1   \n",
       "3               0                       0                  1   \n",
       "4               0                       0                  1   \n",
       "\n",
       "   cancellation_policy_moderate  cancellation_policy_strict  \\\n",
       "0                             0                           0   \n",
       "1                             0                           1   \n",
       "2                             0                           1   \n",
       "3                             0                           1   \n",
       "4                             0                           1   \n",
       "\n",
       "   cancellation_policy_super_strict_30  cancellation_policy_super_strict_60  \\\n",
       "0                                    0                                    0   \n",
       "1                                    0                                    0   \n",
       "2                                    0                                    0   \n",
       "3                                    0                                    0   \n",
       "4                                    0                                    0   \n",
       "\n",
       "   city_Chicago  city_DC  city_LA  city_NYC  city_SF  cleaning_fee_t  \\\n",
       "0             0        0        1         0        0               1   \n",
       "1             0        1        0         0        0               1   \n",
       "2             0        0        0         1        0               1   \n",
       "3             0        0        0         0        1               1   \n",
       "4             0        0        0         1        0               1   \n",
       "\n",
       "   host_has_profile_pic_f  host_has_profile_pic_t  host_identity_verified_f  \\\n",
       "0                       0                       1                         1   \n",
       "1                       0                       1                         0   \n",
       "2                       0                       1                         1   \n",
       "3                       0                       1                         0   \n",
       "4                       0                       1                         0   \n",
       "\n",
       "   host_identity_verified_t  instant_bookable_t  \\\n",
       "0                         0                   0   \n",
       "1                         1                   0   \n",
       "2                         0                   1   \n",
       "3                         1                   1   \n",
       "4                         1                   0   \n",
       "\n",
       "   property_type_Bed & Breakfast  property_type_Boat  \\\n",
       "0                              0                   0   \n",
       "1                              0                   0   \n",
       "2                              0                   0   \n",
       "3                              0                   0   \n",
       "4                              0                   0   \n",
       "\n",
       "   property_type_Boutique hotel  property_type_Bungalow  property_type_Cabin  \\\n",
       "0                             0                       0                    0   \n",
       "1                             0                       0                    0   \n",
       "2                             0                       0                    0   \n",
       "3                             0                       0                    0   \n",
       "4                             0                       0                    0   \n",
       "\n",
       "   property_type_Camper/RV  property_type_Casa particular  \\\n",
       "0                        0                              0   \n",
       "1                        0                              0   \n",
       "2                        0                              0   \n",
       "3                        0                              0   \n",
       "4                        0                              0   \n",
       "\n",
       "   property_type_Castle  property_type_Cave  property_type_Chalet  \\\n",
       "0                     0                   0                     0   \n",
       "1                     0                   0                     0   \n",
       "2                     0                   0                     0   \n",
       "3                     0                   0                     0   \n",
       "4                     0                   0                     0   \n",
       "\n",
       "   property_type_Condominium  property_type_Dorm  property_type_Earth House  \\\n",
       "0                          0                   0                          0   \n",
       "1                          0                   0                          0   \n",
       "2                          0                   0                          0   \n",
       "3                          0                   0                          0   \n",
       "4                          0                   0                          0   \n",
       "\n",
       "   property_type_Guest suite  property_type_Guesthouse  property_type_Hostel  \\\n",
       "0                          0                         0                     0   \n",
       "1                          0                         0                     0   \n",
       "2                          0                         0                     0   \n",
       "3                          0                         0                     0   \n",
       "4                          0                         0                     0   \n",
       "\n",
       "   property_type_House  property_type_Hut  property_type_In-law  \\\n",
       "0                    0                  0                     0   \n",
       "1                    1                  0                     0   \n",
       "2                    0                  0                     0   \n",
       "3                    0                  0                     0   \n",
       "4                    0                  0                     0   \n",
       "\n",
       "   property_type_Island  property_type_Loft  property_type_Other  \\\n",
       "0                     0                   0                    0   \n",
       "1                     0                   0                    0   \n",
       "2                     0                   0                    0   \n",
       "3                     0                   0                    0   \n",
       "4                     0                   0                    0   \n",
       "\n",
       "   property_type_Parking Space  property_type_Serviced apartment  \\\n",
       "0                            0                                 0   \n",
       "1                            0                                 0   \n",
       "2                            0                                 0   \n",
       "3                            0                                 0   \n",
       "4                            0                                 0   \n",
       "\n",
       "   property_type_Tent  property_type_Timeshare  property_type_Tipi  \\\n",
       "0                   0                        0                   0   \n",
       "1                   0                        0                   0   \n",
       "2                   0                        0                   0   \n",
       "3                   0                        0                   0   \n",
       "4                   0                        0                   0   \n",
       "\n",
       "   property_type_Townhouse  property_type_Train  property_type_Treehouse  \\\n",
       "0                        0                    0                        0   \n",
       "1                        0                    0                        0   \n",
       "2                        0                    0                        0   \n",
       "3                        0                    0                        0   \n",
       "4                        0                    0                        0   \n",
       "\n",
       "   property_type_Vacation home  property_type_Villa  property_type_Yurt  \\\n",
       "0                            0                    0                   0   \n",
       "1                            0                    0                   0   \n",
       "2                            0                    0                   0   \n",
       "3                            0                    0                   0   \n",
       "4                            0                    0                   0   \n",
       "\n",
       "   room_type_Private room  room_type_Shared room  TV_True  Cable TV_True  \\\n",
       "0                       1                      0        1              0   \n",
       "1                       1                      0        1              1   \n",
       "2                       1                      0        1              0   \n",
       "3                       1                      0        1              1   \n",
       "4                       0                      0        1              0   \n",
       "\n",
       "   Wireless Internet_True  Air conditioning_True  Kitchen_True  \\\n",
       "0                       1                      0             1   \n",
       "1                       1                      1             1   \n",
       "2                       1                      0             1   \n",
       "3                       1                      1             1   \n",
       "4                       1                      1             1   \n",
       "\n",
       "   Free parking on premises_True  Pets allowed_True  Breakfast_True  \\\n",
       "0                              1                  0               0   \n",
       "1                              1                  0               0   \n",
       "2                              0                  0               0   \n",
       "3                              0                  0               0   \n",
       "4                              0                  0               0   \n",
       "\n",
       "   Elevator_True  Hot tub_True  Indoor fireplace_True  Heating_True  \\\n",
       "0              0             0                      0             0   \n",
       "1              0             0                      0             1   \n",
       "2              0             0                      1             1   \n",
       "3              0             0                      0             1   \n",
       "4              1             0                      0             1   \n",
       "\n",
       "   Family/kid friendly_True  Suitable for events_True  Washer_True  \\\n",
       "0                         0                         0            1   \n",
       "1                         0                         0            1   \n",
       "2                         0                         0            1   \n",
       "3                         0                         0            1   \n",
       "4                         0                         0            1   \n",
       "\n",
       "   Dryer_True  Smoke detector_True  Carbon monoxide detector_True  \\\n",
       "0           1                    1                              0   \n",
       "1           1                    1                              1   \n",
       "2           1                    1                              1   \n",
       "3           1                    1                              1   \n",
       "4           1                    1                              1   \n",
       "\n",
       "   First aid kit_True  Safety card_True  Fire extinguisher_True  \\\n",
       "0                   0                 0                       0   \n",
       "1                   1                 0                       0   \n",
       "2                   1                 1                       1   \n",
       "3                   1                 1                       0   \n",
       "4                   0                 1                       1   \n",
       "\n",
       "   Essentials_True  Shampoo_True  Lock on bedroom door_True  Hangers_True  \\\n",
       "0                0             0                          0             0   \n",
       "1                1             1                          1             1   \n",
       "2                1             1                          1             1   \n",
       "3                1             1                          0             0   \n",
       "4                1             1                          0             1   \n",
       "\n",
       "   Hair dryer_True  Iron_True  Laptop friendly workspace_True  \\\n",
       "0                0          0                               0   \n",
       "1                0          1                               1   \n",
       "2                1          1                               1   \n",
       "3                0          0                               0   \n",
       "4                1          0                               0   \n",
       "\n",
       "   Self Check-In_True  Keypad_True  Private entrance_True  Baby monitor_True  \\\n",
       "0                   0            0                      0                  0   \n",
       "1                   0            0                      0                  0   \n",
       "2                   1            1                      0                  0   \n",
       "3                   1            1                      0                  0   \n",
       "4                   0            0                      0                  0   \n",
       "\n",
       "   Bathtub_True  Baby bath_True  Changing table_True  \\\n",
       "0             0               0                    0   \n",
       "1             0               0                    0   \n",
       "2             1               0                    0   \n",
       "3             0               0                    0   \n",
       "4             0               0                    0   \n",
       "\n",
       "   Children’s books and toys_True  Window guards_True  \\\n",
       "0                               0                   0   \n",
       "1                               0                   0   \n",
       "2                               0                   0   \n",
       "3                               0                   0   \n",
       "4                               0                   0   \n",
       "\n",
       "   Table corner guards_True  Fireplace guards_True  \\\n",
       "0                         0                      0   \n",
       "1                         0                      0   \n",
       "2                         0                      0   \n",
       "3                         0                      0   \n",
       "4                         0                      0   \n",
       "\n",
       "   Babysitter recommendations_True  Crib_True  Room-darkening shades_True  \\\n",
       "0                                0          0                           0   \n",
       "1                                0          0                           0   \n",
       "2                                0          0                           1   \n",
       "3                                0          0                           0   \n",
       "4                                0          0                           0   \n",
       "\n",
       "   Game console_True  Hot water_True  Bed linens_True  \\\n",
       "0                  0               0                0   \n",
       "1                  0               0                0   \n",
       "2                  0               0                0   \n",
       "3                  0               0                0   \n",
       "4                  0               0                0   \n",
       "\n",
       "   Extra pillows and blankets_True  Ethernet connection_True  \\\n",
       "0                                0                         0   \n",
       "1                                0                         0   \n",
       "2                                0                         0   \n",
       "3                                0                         0   \n",
       "4                                0                         0   \n",
       "\n",
       "   Pocket wifi_True  Microwave_True  Coffee maker_True  Refrigerator_True  \\\n",
       "0                 0               0                  0                  0   \n",
       "1                 0               0                  0                  0   \n",
       "2                 0               0                  0                  0   \n",
       "3                 0               0                  0                  0   \n",
       "4                 0               0                  0                  0   \n",
       "\n",
       "   Dishwasher_True  Dishes and silverware_True  Cooking basics_True  \\\n",
       "0                0                           0                    0   \n",
       "1                0                           0                    0   \n",
       "2                0                           0                    0   \n",
       "3                0                           0                    0   \n",
       "4                0                           0                    0   \n",
       "\n",
       "   Oven_True  Stove_True  EV charger_True  Single level home_True  \\\n",
       "0          0           0                0                       0   \n",
       "1          0           0                0                       0   \n",
       "2          0           0                0                       0   \n",
       "3          0           0                0                       0   \n",
       "4          0           0                0                       0   \n",
       "\n",
       "   BBQ grill_True  Patio or balcony_True  Garden or backyard_True  \\\n",
       "0               0                      0                        0   \n",
       "1               0                      0                        0   \n",
       "2               0                      0                        0   \n",
       "3               0                      0                        0   \n",
       "4               0                      0                        0   \n",
       "\n",
       "   Beach essentials_True  Luggage dropoff allowed_True  \\\n",
       "0                      0                             0   \n",
       "1                      0                             0   \n",
       "2                      0                             0   \n",
       "3                      0                             0   \n",
       "4                      0                             0   \n",
       "\n",
       "   Long term stays allowed_True  Wide hallway clearance_True  \\\n",
       "0                             0                            0   \n",
       "1                             0                            0   \n",
       "2                             0                            0   \n",
       "3                             0                            0   \n",
       "4                             0                            0   \n",
       "\n",
       "   Step-free access_True  Wide doorway_True  Flat_True  \\\n",
       "0                      0                  0          0   \n",
       "1                      0                  0          0   \n",
       "2                      0                  0          0   \n",
       "3                      0                  0          0   \n",
       "4                      0                  0          0   \n",
       "\n",
       "    smooth pathway to front door_True  Well-lit path to entrance_True  \\\n",
       "0                                   0                               0   \n",
       "1                                   0                               0   \n",
       "2                                   0                               0   \n",
       "3                                   0                               0   \n",
       "4                                   0                               0   \n",
       "\n",
       "   Disabled parking spot_True  Wide clearance to bed_True  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   Accessible-height bed_True  Fixed grab bars for shower & toilet_True  \\\n",
       "0                           0                                         0   \n",
       "1                           0                                         0   \n",
       "2                           0                                         0   \n",
       "3                           0                                         0   \n",
       "4                           0                                         0   \n",
       "\n",
       "   Bathtub with shower chair_True  Roll-in shower with chair_True  \\\n",
       "0                               0                               0   \n",
       "1                               0                               0   \n",
       "2                               0                               0   \n",
       "3                               0                               0   \n",
       "4                               0                               0   \n",
       "\n",
       "   Accessible-height toilet_True  Wide clearance to shower & toilet_True  \\\n",
       "0                              0                                       0   \n",
       "1                              0                                       0   \n",
       "2                              0                                       0   \n",
       "3                              0                                       0   \n",
       "4                              0                                       0   \n",
       "\n",
       "   Wide entryway_True  Waterfront_True  Handheld shower head_True  \\\n",
       "0                   0                0                          0   \n",
       "1                   0                0                          0   \n",
       "2                   0                0                          0   \n",
       "3                   0                0                          0   \n",
       "4                   0                0                          0   \n",
       "\n",
       "   thumbnail_url_str_nan  \n",
       "0                      1  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      1  \n",
       "4                      0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_addEDA_log_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee3a6fc-2379-4f9f-ab70-4fcae5ad9ef7",
   "metadata": {},
   "source": [
    "# 目的変数の処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e99b5e9d-be05-41f7-9f66-94b8769cb693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "歪度: 0.535099\n",
      "尖度: 0.662021\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_y_ac = train_y / train_X_addEDA_log_dummy[\"accommodates\"]\n",
    "#目的変数の対数log(x+1)をとる\n",
    "train_y_ac_log = np.log1p(train_y_ac) #②\n",
    "train_y_log = np.log1p(train_y)#③\n",
    "\n",
    "#分布を可視化\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.distplot(train_y_log)\n",
    "\n",
    "#歪度と尖度を計算\n",
    "print(\"歪度: %f\" % train_y_log.skew())\n",
    "print(\"尖度: %f\" % train_y_log.kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d99ea-6e93-4dca-9404-87d61d9a3871",
   "metadata": {},
   "source": [
    "# データセットを分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88e069f8-1ba6-4389-9671-3e46d821dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "presplit_train_X = train_X_addEDA_log_dummy\n",
    "presplit_train_y = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7b3ac6-154d-4347-b5e1-e62cce450bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#実際のテストサイズと同じサイズのテストデータを確保してこれでだいたいを測る\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(presplit_train_X, presplit_train_y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac65e0f0-1f91-4183-acba-5de645608037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_test) 37240\n",
      "len(train_y) 37240\n",
      "len(valid_X) 18343\n",
      "len(valid_y) 18343\n"
     ]
    }
   ],
   "source": [
    "print('len(X_test)', len(train_X))\n",
    "print('len(train_y)', len(train_y))\n",
    "print('len(valid_X)', len(valid_X))\n",
    "print('len(valid_y)', len(valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7747437c-9191-4398-9c7d-6dcfcd7d7695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "歪度: 4.240694\n",
      "尖度: 25.648410\n",
      "=============\n",
      "歪度: 4.310869\n",
      "尖度: 26.777676\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[30, 10])\n",
    "\n",
    "sns.distplot(train_y, ax=ax1)\n",
    "#歪度と尖度を計算\n",
    "print(\"歪度: %f\" % train_y.skew())\n",
    "print(\"尖度: %f\" % train_y.kurt())\n",
    "\n",
    "print('=============')\n",
    "\n",
    "sns.distplot(valid_y, ax=ax2)\n",
    "#歪度と尖度を計算\n",
    "print(\"歪度: %f\" % valid_y.skew())\n",
    "print(\"尖度: %f\" % valid_y.kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b62d8e4-67cf-4ded-9543-e843b8e1e7f4",
   "metadata": {},
   "source": [
    "# Submit用のモデル作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb40eba-c9c0-4402-b56b-14a2690cbcbf",
   "metadata": {},
   "source": [
    "## パラメータチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85592a89-aa5d-4080-a6a5-fa3490da4658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.integration.lightgbm as op_lgb\n",
    "from sklearn import datasets, model_selection\n",
    "\n",
    "dtrain_tuning = op_lgb.Dataset(train_X.values, label=train_y.values)\n",
    "dval_tuning = op_lgb.Dataset(valid_X.values, label=valid_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "756195fc-0149-47ea-8125-dd356833a7d5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-08 02:59:38,127]\u001b[0m A new study created in memory with name: no-name-a4ab41cb-4b64-42b8-95a0-827dd2eae89d\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|                   | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 104.383385:  14%|5   | 1/7 [00:12<01:15, 12.61s/it]\u001b[32m[I 2021-08-08 02:59:50,747]\u001b[0m Trial 0 finished with value: 104.38338524622672 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 104.38338524622672.\u001b[0m\n",
      "feature_fraction, val_score: 104.383385:  14%|5   | 1/7 [00:12<01:15, 12.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 104.383385:  29%|#1  | 2/7 [00:21<00:53, 10.66s/it]\u001b[32m[I 2021-08-08 03:00:00,033]\u001b[0m Trial 1 finished with value: 105.00616043404341 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 104.38338524622672.\u001b[0m\n",
      "feature_fraction, val_score: 104.383385:  29%|#1  | 2/7 [00:21<00:53, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 104.383385:  43%|#7  | 3/7 [00:31<00:39,  9.96s/it]\u001b[32m[I 2021-08-08 03:00:09,171]\u001b[0m Trial 2 finished with value: 104.92500046640377 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 104.38338524622672.\u001b[0m\n",
      "feature_fraction, val_score: 104.383385:  43%|#7  | 3/7 [00:31<00:39,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 104.383385:  57%|##2 | 4/7 [00:40<00:29,  9.95s/it]\u001b[32m[I 2021-08-08 03:00:19,108]\u001b[0m Trial 3 finished with value: 105.33039498175816 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 104.38338524622672.\u001b[0m\n",
      "feature_fraction, val_score: 104.383385:  57%|##2 | 4/7 [00:40<00:29,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 104.383385:  71%|##8 | 5/7 [00:52<00:20, 10.49s/it]\u001b[32m[I 2021-08-08 03:00:30,546]\u001b[0m Trial 4 finished with value: 104.86736428340244 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 104.38338524622672.\u001b[0m\n",
      "feature_fraction, val_score: 104.383385:  71%|##8 | 5/7 [00:52<00:20, 10.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 104.383385:  86%|###4| 6/7 [01:04<00:11, 11.07s/it]\u001b[32m[I 2021-08-08 03:00:42,756]\u001b[0m Trial 5 finished with value: 104.89192162505276 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 104.38338524622672.\u001b[0m\n",
      "feature_fraction, val_score: 104.383385:  86%|###4| 6/7 [01:04<00:11, 11.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 104.383385: 100%|####| 7/7 [01:15<00:00, 10.93s/it]\u001b[32m[I 2021-08-08 03:00:53,397]\u001b[0m Trial 6 finished with value: 105.37054642927045 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 104.38338524622672.\u001b[0m\n",
      "feature_fraction, val_score: 104.383385: 100%|####| 7/7 [01:15<00:00, 10.75s/it]\n",
      "num_leaves, val_score: 104.383385:   0%|                 | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 104.068519:   5%|4        | 1/20 [00:35<11:12, 35.38s/it]\u001b[32m[I 2021-08-08 03:01:28,777]\u001b[0m Trial 7 finished with value: 104.0685185169462 and parameters: {'num_leaves': 206}. Best is trial 7 with value: 104.0685185169462.\u001b[0m\n",
      "num_leaves, val_score: 104.068519:   5%|4        | 1/20 [00:35<11:12, 35.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 104.068519:  10%|9        | 2/20 [00:56<08:09, 27.22s/it]\u001b[32m[I 2021-08-08 03:01:50,290]\u001b[0m Trial 8 finished with value: 104.17775116736276 and parameters: {'num_leaves': 182}. Best is trial 7 with value: 104.0685185169462.\u001b[0m\n",
      "num_leaves, val_score: 104.068519:  10%|9        | 2/20 [00:56<08:09, 27.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 103.901419:  15%|#3       | 3/20 [01:16<06:41, 23.61s/it]\u001b[32m[I 2021-08-08 03:02:09,602]\u001b[0m Trial 9 finished with value: 103.90141866354993 and parameters: {'num_leaves': 124}. Best is trial 9 with value: 103.90141866354993.\u001b[0m\n",
      "num_leaves, val_score: 103.901419:  15%|#3       | 3/20 [01:16<06:41, 23.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 103.809346:  20%|#8       | 4/20 [01:38<06:09, 23.08s/it]\u001b[32m[I 2021-08-08 03:02:31,865]\u001b[0m Trial 10 finished with value: 103.80934607676204 and parameters: {'num_leaves': 87}. Best is trial 10 with value: 103.80934607676204.\u001b[0m\n",
      "num_leaves, val_score: 103.809346:  20%|#8       | 4/20 [01:38<06:09, 23.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 103.809346:  25%|##2      | 5/20 [02:03<05:58, 23.87s/it]\u001b[32m[I 2021-08-08 03:02:57,135]\u001b[0m Trial 11 finished with value: 104.12046394632645 and parameters: {'num_leaves': 211}. Best is trial 10 with value: 103.80934607676204.\u001b[0m\n",
      "num_leaves, val_score: 103.809346:  25%|##2      | 5/20 [02:03<05:58, 23.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 103.809346:  30%|##6      | 6/20 [02:25<05:22, 23.03s/it]\u001b[32m[I 2021-08-08 03:03:18,525]\u001b[0m Trial 12 finished with value: 104.34137838713099 and parameters: {'num_leaves': 203}. Best is trial 10 with value: 103.80934607676204.\u001b[0m\n",
      "num_leaves, val_score: 103.809346:  30%|##6      | 6/20 [02:25<05:22, 23.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 103.809346:  35%|###1     | 7/20 [02:44<04:43, 21.77s/it]\u001b[32m[I 2021-08-08 03:03:37,724]\u001b[0m Trial 13 finished with value: 103.85543596328054 and parameters: {'num_leaves': 139}. Best is trial 10 with value: 103.80934607676204.\u001b[0m\n",
      "num_leaves, val_score: 103.809346:  35%|###1     | 7/20 [02:44<04:43, 21.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 103.809346:  40%|###6     | 8/20 [02:57<03:48, 19.08s/it]\u001b[32m[I 2021-08-08 03:03:51,034]\u001b[0m Trial 14 finished with value: 104.00246480980508 and parameters: {'num_leaves': 114}. Best is trial 10 with value: 103.80934607676204.\u001b[0m\n",
      "num_leaves, val_score: 103.809346:  40%|###6     | 8/20 [02:57<03:48, 19.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 103.809346:  45%|####     | 9/20 [03:25<04:00, 21.88s/it]\u001b[32m[I 2021-08-08 03:04:19,074]\u001b[0m Trial 15 finished with value: 104.12697503300642 and parameters: {'num_leaves': 208}. Best is trial 10 with value: 103.80934607676204.\u001b[0m\n",
      "num_leaves, val_score: 103.809346:  45%|####     | 9/20 [03:25<04:00, 21.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 103.809346:  50%|####    | 10/20 [03:46<03:35, 21.56s/it]\u001b[32m[I 2021-08-08 03:04:39,911]\u001b[0m Trial 16 finished with value: 104.05243851970809 and parameters: {'num_leaves': 171}. Best is trial 10 with value: 103.80934607676204.\u001b[0m\n",
      "num_leaves, val_score: 103.809346:  50%|####    | 10/20 [03:46<03:35, 21.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 103.809346:  55%|####4   | 11/20 [04:00<02:53, 19.26s/it]\u001b[32m[I 2021-08-08 03:04:53,973]\u001b[0m Trial 17 finished with value: 104.19459167845233 and parameters: {'num_leaves': 33}. Best is trial 10 with value: 103.80934607676204.\u001b[0m\n",
      "num_leaves, val_score: 103.809346:  55%|####4   | 11/20 [04:00<02:53, 19.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 103.401910:  60%|####8   | 12/20 [04:22<02:40, 20.00s/it]\u001b[32m[I 2021-08-08 03:05:15,663]\u001b[0m Trial 18 finished with value: 103.40190986657618 and parameters: {'num_leaves': 73}. Best is trial 18 with value: 103.40190986657618.\u001b[0m\n",
      "num_leaves, val_score: 103.401910:  60%|####8   | 12/20 [04:22<02:40, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 103.401910:  65%|#####2  | 13/20 [04:40<02:15, 19.40s/it]\u001b[32m[I 2021-08-08 03:05:33,672]\u001b[0m Trial 19 finished with value: 103.82174403158895 and parameters: {'num_leaves': 59}. Best is trial 18 with value: 103.40190986657618.\u001b[0m\n",
      "num_leaves, val_score: 103.401910:  65%|#####2  | 13/20 [04:40<02:15, 19.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 103.401910:  70%|#####6  | 14/20 [04:56<01:50, 18.47s/it]\u001b[32m[I 2021-08-08 03:05:49,994]\u001b[0m Trial 20 finished with value: 103.8421055494147 and parameters: {'num_leaves': 76}. Best is trial 18 with value: 103.40190986657618.\u001b[0m\n",
      "num_leaves, val_score: 103.401910:  70%|#####6  | 14/20 [04:56<01:50, 18.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 103.401910:  75%|######  | 15/20 [05:06<01:19, 15.97s/it]\u001b[32m[I 2021-08-08 03:06:00,174]\u001b[0m Trial 21 finished with value: 106.07317220922772 and parameters: {'num_leaves': 12}. Best is trial 18 with value: 103.40190986657618.\u001b[0m\n",
      "num_leaves, val_score: 103.401910:  75%|######  | 15/20 [05:06<01:19, 15.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 103.401910:  80%|######4 | 16/20 [05:31<01:13, 18.50s/it]\u001b[32m[I 2021-08-08 03:06:24,543]\u001b[0m Trial 22 finished with value: 103.45427673475464 and parameters: {'num_leaves': 83}. Best is trial 18 with value: 103.40190986657618.\u001b[0m\n",
      "num_leaves, val_score: 103.401910:  80%|######4 | 16/20 [05:31<01:13, 18.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 103.401910:  85%|######8 | 17/20 [05:59<01:04, 21.54s/it]\u001b[32m[I 2021-08-08 03:06:53,162]\u001b[0m Trial 23 finished with value: 104.47599005229786 and parameters: {'num_leaves': 256}. Best is trial 18 with value: 103.40190986657618.\u001b[0m\n",
      "num_leaves, val_score: 103.401910:  85%|######8 | 17/20 [05:59<01:04, 21.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 103.401910:  90%|#######2| 18/20 [06:12<00:37, 19.00s/it]\u001b[32m[I 2021-08-08 03:07:06,234]\u001b[0m Trial 24 finished with value: 104.34603296462262 and parameters: {'num_leaves': 39}. Best is trial 18 with value: 103.40190986657618.\u001b[0m\n",
      "num_leaves, val_score: 103.401910:  90%|#######2| 18/20 [06:12<00:37, 19.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 103.401910:  95%|#######6| 19/20 [06:23<00:16, 16.45s/it]\u001b[32m[I 2021-08-08 03:07:16,756]\u001b[0m Trial 25 finished with value: 104.40457239709173 and parameters: {'num_leaves': 97}. Best is trial 18 with value: 103.40190986657618.\u001b[0m\n",
      "num_leaves, val_score: 103.401910:  95%|#######6| 19/20 [06:23<00:16, 16.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 103.401910: 100%|########| 20/20 [06:37<00:00, 15.77s/it]\u001b[32m[I 2021-08-08 03:07:30,937]\u001b[0m Trial 26 finished with value: 109.95702127869909 and parameters: {'num_leaves': 4}. Best is trial 18 with value: 103.40190986657618.\u001b[0m\n",
      "num_leaves, val_score: 103.401910: 100%|########| 20/20 [06:37<00:00, 19.88s/it]\n",
      "bagging, val_score: 103.401910:   0%|                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 103.401910:  10%|#2          | 1/10 [00:12<01:49, 12.13s/it]\u001b[32m[I 2021-08-08 03:07:43,071]\u001b[0m Trial 27 finished with value: 104.01691728299845 and parameters: {'bagging_fraction': 0.751860138186234, 'bagging_freq': 1}. Best is trial 27 with value: 104.01691728299845.\u001b[0m\n",
      "bagging, val_score: 103.401910:  10%|#2          | 1/10 [00:12<01:49, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 103.401910:  20%|##4         | 2/10 [00:22<01:27, 10.91s/it]\u001b[32m[I 2021-08-08 03:07:53,125]\u001b[0m Trial 28 finished with value: 104.5258396770218 and parameters: {'bagging_fraction': 0.7366439980628131, 'bagging_freq': 3}. Best is trial 27 with value: 104.01691728299845.\u001b[0m\n",
      "bagging, val_score: 103.401910:  20%|##4         | 2/10 [00:22<01:27, 10.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 103.401910:  30%|###6        | 3/10 [00:34<01:20, 11.47s/it]\u001b[32m[I 2021-08-08 03:08:05,255]\u001b[0m Trial 29 finished with value: 104.49464608467724 and parameters: {'bagging_fraction': 0.7534146647091787, 'bagging_freq': 6}. Best is trial 27 with value: 104.01691728299845.\u001b[0m\n",
      "bagging, val_score: 103.401910:  30%|###6        | 3/10 [00:34<01:20, 11.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 103.401910:  40%|####8       | 4/10 [00:52<01:24, 14.06s/it]\u001b[32m[I 2021-08-08 03:08:23,291]\u001b[0m Trial 30 finished with value: 103.92545244479616 and parameters: {'bagging_fraction': 0.7417329761205893, 'bagging_freq': 6}. Best is trial 30 with value: 103.92545244479616.\u001b[0m\n",
      "bagging, val_score: 103.401910:  40%|####8       | 4/10 [00:52<01:24, 14.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 103.401910:  50%|######      | 5/10 [01:01<01:01, 12.32s/it]\u001b[32m[I 2021-08-08 03:08:32,521]\u001b[0m Trial 31 finished with value: 105.18548648780406 and parameters: {'bagging_fraction': 0.4960471846197635, 'bagging_freq': 3}. Best is trial 30 with value: 103.92545244479616.\u001b[0m\n",
      "bagging, val_score: 103.401910:  50%|######      | 5/10 [01:01<01:01, 12.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 103.401910:  60%|#######2    | 6/10 [01:15<00:51, 12.76s/it]\u001b[32m[I 2021-08-08 03:08:46,145]\u001b[0m Trial 32 finished with value: 103.98558064485276 and parameters: {'bagging_fraction': 0.9989083660544278, 'bagging_freq': 4}. Best is trial 30 with value: 103.92545244479616.\u001b[0m\n",
      "bagging, val_score: 103.401910:  60%|#######2    | 6/10 [01:15<00:51, 12.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 103.401910:  70%|########3   | 7/10 [01:30<00:40, 13.63s/it]\u001b[32m[I 2021-08-08 03:09:01,556]\u001b[0m Trial 33 finished with value: 104.13750209420058 and parameters: {'bagging_fraction': 0.824059200031948, 'bagging_freq': 7}. Best is trial 30 with value: 103.92545244479616.\u001b[0m\n",
      "bagging, val_score: 103.401910:  70%|########3   | 7/10 [01:30<00:40, 13.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 103.401910:  80%|#########6  | 8/10 [01:41<00:25, 12.63s/it]\u001b[32m[I 2021-08-08 03:09:12,064]\u001b[0m Trial 34 finished with value: 104.88915531411739 and parameters: {'bagging_fraction': 0.5466637961129936, 'bagging_freq': 2}. Best is trial 30 with value: 103.92545244479616.\u001b[0m\n",
      "bagging, val_score: 103.401910:  80%|#########6  | 8/10 [01:41<00:25, 12.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 103.401910:  90%|##########8 | 9/10 [01:50<00:11, 11.58s/it]\u001b[32m[I 2021-08-08 03:09:21,316]\u001b[0m Trial 35 finished with value: 105.44698157146934 and parameters: {'bagging_fraction': 0.44517697533629635, 'bagging_freq': 1}. Best is trial 30 with value: 103.92545244479616.\u001b[0m\n",
      "bagging, val_score: 103.401910:  90%|##########8 | 9/10 [01:50<00:11, 11.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 103.401910: 100%|###########| 10/10 [01:59<00:00, 10.73s/it]\u001b[32m[I 2021-08-08 03:09:30,141]\u001b[0m Trial 36 finished with value: 105.05552610511447 and parameters: {'bagging_fraction': 0.5130309329323595, 'bagging_freq': 7}. Best is trial 30 with value: 103.92545244479616.\u001b[0m\n",
      "bagging, val_score: 103.401910: 100%|###########| 10/10 [01:59<00:00, 11.92s/it]\n",
      "feature_fraction_stage2, val_score: 103.401910:   0%|     | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 103.401910:  33%|3| 1/3 [00:17<00:35, 17.75s\u001b[32m[I 2021-08-08 03:09:47,894]\u001b[0m Trial 37 finished with value: 103.80765355574934 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 103.80765355574934.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 103.401910:  33%|3| 1/3 [00:17<00:35, 17.75s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 103.401910:  67%|6| 2/3 [00:37<00:19, 19.14s\u001b[32m[I 2021-08-08 03:10:08,003]\u001b[0m Trial 38 finished with value: 103.86141443780335 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 103.80765355574934.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 103.401910:  67%|6| 2/3 [00:37<00:19, 19.14s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 103.401910: 100%|#| 3/3 [00:53<00:00, 17.42s\u001b[32m[I 2021-08-08 03:10:23,386]\u001b[0m Trial 39 finished with value: 104.01598154333287 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 37 with value: 103.80765355574934.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 103.401910: 100%|#| 3/3 [00:53<00:00, 17.75s\n",
      "regularization_factors, val_score: 103.401910:   0%|     | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910:   5%| | 1/20 [00:25<07:57, 25.16s\u001b[32m[I 2021-08-08 03:10:48,550]\u001b[0m Trial 40 finished with value: 103.49403583103616 and parameters: {'lambda_l1': 5.646153852026822e-05, 'lambda_l2': 2.8995359729426077e-08}. Best is trial 40 with value: 103.49403583103616.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910:   5%| | 1/20 [00:25<07:57, 25.16s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910:  10%|1| 2/20 [00:46<06:49, 22.75s\u001b[32m[I 2021-08-08 03:11:09,611]\u001b[0m Trial 41 finished with value: 103.54208063099907 and parameters: {'lambda_l1': 4.7002479155144543e-07, 'lambda_l2': 0.0011226024299761967}. Best is trial 40 with value: 103.49403583103616.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910:  10%|1| 2/20 [00:46<06:49, 22.75s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910:  15%|1| 3/20 [01:00<05:20, 18.86s\u001b[32m[I 2021-08-08 03:11:23,852]\u001b[0m Trial 42 finished with value: 103.8351843699507 and parameters: {'lambda_l1': 6.142674745281191e-07, 'lambda_l2': 0.051062876583164496}. Best is trial 40 with value: 103.49403583103616.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910:  15%|1| 3/20 [01:00<05:20, 18.86s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910:  20%|2| 4/20 [01:19<05:05, 19.10s\u001b[32m[I 2021-08-08 03:11:43,326]\u001b[0m Trial 43 finished with value: 103.40329179614929 and parameters: {'lambda_l1': 5.416510920600852e-07, 'lambda_l2': 1.7523455374185662e-08}. Best is trial 43 with value: 103.40329179614929.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910:  20%|2| 4/20 [01:19<05:05, 19.10s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910:  25%|2| 5/20 [01:35<04:26, 17.75s\u001b[32m[I 2021-08-08 03:11:58,686]\u001b[0m Trial 44 finished with value: 103.56100262781347 and parameters: {'lambda_l1': 2.0746939740197e-08, 'lambda_l2': 1.3274154616086434e-06}. Best is trial 43 with value: 103.40329179614929.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910:  25%|2| 5/20 [01:35<04:26, 17.75s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910:  30%|3| 6/20 [01:50<03:57, 16.95s\u001b[32m[I 2021-08-08 03:12:14,081]\u001b[0m Trial 45 finished with value: 103.7740883602478 and parameters: {'lambda_l1': 1.5787503314747686, 'lambda_l2': 0.013288662277497405}. Best is trial 43 with value: 103.40329179614929.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910:  30%|3| 6/20 [01:50<03:57, 16.95s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910:  35%|3| 7/20 [02:13<04:06, 18.95s\u001b[32m[I 2021-08-08 03:12:37,139]\u001b[0m Trial 46 finished with value: 103.56869610110851 and parameters: {'lambda_l1': 1.5688375038037254e-07, 'lambda_l2': 4.960095163816138}. Best is trial 43 with value: 103.40329179614929.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910:  35%|3| 7/20 [02:13<04:06, 18.95s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910:  40%|4| 8/20 [02:27<03:27, 17.31s\u001b[32m[I 2021-08-08 03:12:50,954]\u001b[0m Trial 47 finished with value: 103.84239957790625 and parameters: {'lambda_l1': 8.707925481055795e-06, 'lambda_l2': 0.002057640621404746}. Best is trial 43 with value: 103.40329179614929.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910:  40%|4| 8/20 [02:27<03:27, 17.31s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910:  45%|4| 9/20 [02:46<03:15, 17.81s\u001b[32m[I 2021-08-08 03:13:09,847]\u001b[0m Trial 48 finished with value: 103.72916634594722 and parameters: {'lambda_l1': 7.866835603181297, 'lambda_l2': 8.894575747619461e-06}. Best is trial 43 with value: 103.40329179614929.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910:  45%|4| 9/20 [02:46<03:15, 17.81s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910:  50%|5| 10/20 [03:03<02:55, 17.55\u001b[32m[I 2021-08-08 03:13:26,816]\u001b[0m Trial 49 finished with value: 103.8481794147437 and parameters: {'lambda_l1': 2.3544178604084688e-06, 'lambda_l2': 0.044967979286863226}. Best is trial 43 with value: 103.40329179614929.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910:  50%|5| 10/20 [03:03<02:55, 17.55"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910:  55%|5| 11/20 [03:22<02:42, 18.07\u001b[32m[I 2021-08-08 03:13:46,076]\u001b[0m Trial 50 finished with value: 103.56286682315198 and parameters: {'lambda_l1': 0.004207530245147709, 'lambda_l2': 1.5681249564048696e-08}. Best is trial 43 with value: 103.40329179614929.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910:  55%|5| 11/20 [03:22<02:42, 18.07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910:  60%|6| 12/20 [03:43<02:31, 18.98\u001b[32m[I 2021-08-08 03:14:07,120]\u001b[0m Trial 51 finished with value: 103.46348345722872 and parameters: {'lambda_l1': 0.0004032757111938305, 'lambda_l2': 1.565543366856634e-08}. Best is trial 43 with value: 103.40329179614929.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910:  60%|6| 12/20 [03:43<02:31, 18.98"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910:  65%|6| 13/20 [03:57<02:01, 17.34\u001b[32m[I 2021-08-08 03:14:20,699]\u001b[0m Trial 52 finished with value: 103.84301931978361 and parameters: {'lambda_l1': 0.007811035294746235, 'lambda_l2': 3.4525912385241315e-07}. Best is trial 43 with value: 103.40329179614929.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910:  65%|6| 13/20 [03:57<02:01, 17.34"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910:  70%|7| 14/20 [04:16<01:47, 17.89\u001b[32m[I 2021-08-08 03:14:39,849]\u001b[0m Trial 53 finished with value: 103.66441119886375 and parameters: {'lambda_l1': 0.000947387341212531, 'lambda_l2': 2.402718916630841e-05}. Best is trial 43 with value: 103.40329179614929.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910:  70%|7| 14/20 [04:16<01:47, 17.89"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910:  75%|7| 15/20 [04:31<01:24, 16.93\u001b[32m[I 2021-08-08 03:14:54,556]\u001b[0m Trial 54 finished with value: 103.85820861542743 and parameters: {'lambda_l1': 0.0274721743186443, 'lambda_l2': 1.423961883071715e-08}. Best is trial 43 with value: 103.40329179614929.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910:  75%|7| 15/20 [04:31<01:24, 16.93"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910:  80%|8| 16/20 [04:46<01:06, 16.54\u001b[32m[I 2021-08-08 03:15:10,186]\u001b[0m Trial 55 finished with value: 103.53683797149918 and parameters: {'lambda_l1': 9.313945388877528e-05, 'lambda_l2': 4.664404465316837e-07}. Best is trial 43 with value: 103.40329179614929.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910:  80%|8| 16/20 [04:46<01:06, 16.54"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910:  85%|8| 17/20 [05:03<00:49, 16.47\u001b[32m[I 2021-08-08 03:15:26,502]\u001b[0m Trial 56 finished with value: 103.51891946510905 and parameters: {'lambda_l1': 0.20002595450393174, 'lambda_l2': 6.161082980396783e-08}. Best is trial 43 with value: 103.40329179614929.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910:  85%|8| 17/20 [05:03<00:49, 16.47"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910:  90%|9| 18/20 [05:17<00:31, 15.76\u001b[32m[I 2021-08-08 03:15:40,603]\u001b[0m Trial 57 finished with value: 103.62516575649973 and parameters: {'lambda_l1': 1.797829447151868e-05, 'lambda_l2': 6.941230667002113e-05}. Best is trial 43 with value: 103.40329179614929.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910:  90%|9| 18/20 [05:17<00:31, 15.76"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910:  95%|9| 19/20 [05:32<00:15, 15.66\u001b[32m[I 2021-08-08 03:15:56,024]\u001b[0m Trial 58 finished with value: 103.9430448349245 and parameters: {'lambda_l1': 2.1366625707622456e-08, 'lambda_l2': 7.208807074115297}. Best is trial 43 with value: 103.40329179614929.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910:  95%|9| 19/20 [05:32<00:15, 15.66"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 103.401910: 100%|#| 20/20 [05:49<00:00, 15.95\u001b[32m[I 2021-08-08 03:16:12,670]\u001b[0m Trial 59 finished with value: 103.49169037898552 and parameters: {'lambda_l1': 0.0004325466779566288, 'lambda_l2': 3.344577872043542e-06}. Best is trial 43 with value: 103.40329179614929.\u001b[0m\n",
      "regularization_factors, val_score: 103.401910: 100%|#| 20/20 [05:49<00:00, 17.46\n",
      "min_data_in_leaf, val_score: 103.401910:   0%|            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007000 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 103.401910:  20%|8   | 1/5 [00:15<01:01, 15.34s/it]\u001b[32m[I 2021-08-08 03:16:28,013]\u001b[0m Trial 60 finished with value: 103.51952319361624 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 103.51952319361624.\u001b[0m\n",
      "min_data_in_leaf, val_score: 103.401910:  20%|8   | 1/5 [00:15<01:01, 15.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 103.401910:  40%|#6  | 2/5 [00:31<00:48, 16.02s/it]\u001b[32m[I 2021-08-08 03:16:44,513]\u001b[0m Trial 61 finished with value: 104.14274415187032 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 103.51952319361624.\u001b[0m\n",
      "min_data_in_leaf, val_score: 103.401910:  40%|#6  | 2/5 [00:31<00:48, 16.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 103.401910:  60%|##4 | 3/5 [00:45<00:29, 14.91s/it]\u001b[32m[I 2021-08-08 03:16:58,103]\u001b[0m Trial 62 finished with value: 104.01808953254327 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 103.51952319361624.\u001b[0m\n",
      "min_data_in_leaf, val_score: 103.401910:  60%|##4 | 3/5 [00:45<00:29, 14.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 103.401910:  80%|###2| 4/5 [01:01<00:15, 15.19s/it]\u001b[32m[I 2021-08-08 03:17:13,716]\u001b[0m Trial 63 finished with value: 105.26532601007024 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 103.51952319361624.\u001b[0m\n",
      "min_data_in_leaf, val_score: 103.401910:  80%|###2| 4/5 [01:01<00:15, 15.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6620\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 160.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 103.401910: 100%|####| 5/5 [01:16<00:00, 15.35s/it]\u001b[32m[I 2021-08-08 03:17:29,346]\u001b[0m Trial 64 finished with value: 103.91961143663937 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 103.51952319361624.\u001b[0m\n",
      "min_data_in_leaf, val_score: 103.401910: 100%|####| 5/5 [01:16<00:00, 15.33s/it]\n"
     ]
    }
   ],
   "source": [
    "best_params, tuning_history = dict(), list()\n",
    "# ハイパーパラメータサーチ&モデル構築(回帰モデル用)\n",
    "tuning_params = {'objective': 'regression',\n",
    "          'metric': 'rmse',\n",
    "#         'boosting_type':'dart',\n",
    "            'boosting_type':'gbdt',\n",
    "          'num_boost_round': 5000, # 最大試行数\n",
    "          'random_seed':100,\n",
    "         'learning_rate': 0.01, # 学習率\n",
    "         }\n",
    "\n",
    "booster = op_lgb.train(tuning_params, \n",
    "                       dtrain_tuning, \n",
    "                       valid_sets=[dtrain_tuning, dval_tuning],\n",
    "                       verbose_eval=0,\n",
    "                       early_stopping_rounds=20,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c1c97df-e788-44fc-98f3-fd94d711e547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'objective': 'regression', 'metric': 'rmse', 'boosting_type': 'gbdt', 'random_seed': 100, 'learning_rate': 0.01, 'feature_pre_filter': False, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'num_leaves': 73, 'feature_fraction': 0.4, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 20, 'num_iterations': 5000, 'early_stopping_round': 20}\n",
      "Best Iteration: 2684\n",
      "Best Score: defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('rmse', 54.618376018938285)]), 'valid_1': OrderedDict([('rmse', 103.40190986657618)])})\n"
     ]
    }
   ],
   "source": [
    "print('Best Params:', booster.params)\n",
    "print('Best Iteration:', booster.best_iteration)\n",
    "print('Best Score:', booster.best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaea39df-760f-4016-93e4-a0473417ad28",
   "metadata": {},
   "source": [
    "# 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b22389e8-0119-4c09-af3b-19edc417baf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(train_X, train_y) #(DataFrame, Series)\n",
    "lgb_valid = lgb.Dataset(valid_X, valid_y, reference=lgb_train) #(DataFrame, Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de15fd5b-9559-403e-8188-60295c5735fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'regression', 'boosting_type': 'gbdt', 'metric': 'rmse', 'verbose': 1000, 'random_seed': 100, 'learning_rate': 0.01, 'feature_pre_filter': False, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'num_leaves': 73, 'feature_fraction': 0.4, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 20, 'num_iterations': 5000, 'early_stopping_round': 20}\n"
     ]
    }
   ],
   "source": [
    "lgbm_params = {\n",
    "    \"objective\":\"regression\",\n",
    "    #'boosting_type':'dart',\n",
    "    'boosting_type':'gbdt',\n",
    "    \"metric\":\"rmse\",\n",
    "   \"verbose\":1000,\n",
    "    \"random_seed\":0,\n",
    "    'learning_rate': 0.001,\n",
    "        }\n",
    "lgbm_params.update(booster.params)\n",
    "lgbm_params['num_leaves'] = int(lgbm_params['num_leaves'])\n",
    "lgbm_params['min_child_samples'] = int(lgbm_params['min_child_samples'])\n",
    "lgbm_params['bagging_freq'] = int(lgbm_params['bagging_freq'])\n",
    "\n",
    "print(lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c041b453-cc17-49cd-a6ab-bcbec05da74a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.952477\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.634051\n",
      "[LightGBM] [Debug] init for col-wise cost 0.007230 seconds, init for row-wise cost 0.015379 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 6809\n",
      "[LightGBM] [Info] Number of data points in the train set: 37240, number of used features: 190\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 160.051772\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1]\ttrain's rmse: 166.694\tvalid's rmse: 168.34\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[2]\ttrain's rmse: 165.93\tvalid's rmse: 167.579\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[3]\ttrain's rmse: 165.075\tvalid's rmse: 166.791\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[4]\ttrain's rmse: 164.231\tvalid's rmse: 165.98\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[5]\ttrain's rmse: 163.445\tvalid's rmse: 165.228\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[6]\ttrain's rmse: 162.617\tvalid's rmse: 164.455\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[7]\ttrain's rmse: 161.843\tvalid's rmse: 163.75\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 9\n",
      "[8]\ttrain's rmse: 161.029\tvalid's rmse: 163.011\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[9]\ttrain's rmse: 160.226\tvalid's rmse: 162.231\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[10]\ttrain's rmse: 159.42\tvalid's rmse: 161.468\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[11]\ttrain's rmse: 158.684\tvalid's rmse: 160.761\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 9\n",
      "[12]\ttrain's rmse: 157.946\tvalid's rmse: 160.075\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[13]\ttrain's rmse: 157.163\tvalid's rmse: 159.344\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[14]\ttrain's rmse: 156.424\tvalid's rmse: 158.63\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[15]\ttrain's rmse: 155.667\tvalid's rmse: 157.947\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[16]\ttrain's rmse: 154.974\tvalid's rmse: 157.288\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[17]\ttrain's rmse: 154.274\tvalid's rmse: 156.647\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[18]\ttrain's rmse: 153.601\tvalid's rmse: 156\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[19]\ttrain's rmse: 152.924\tvalid's rmse: 155.393\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[20]\ttrain's rmse: 152.233\tvalid's rmse: 154.746\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[21]\ttrain's rmse: 151.536\tvalid's rmse: 154.099\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[22]\ttrain's rmse: 150.858\tvalid's rmse: 153.477\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[23]\ttrain's rmse: 150.199\tvalid's rmse: 152.874\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[24]\ttrain's rmse: 149.62\tvalid's rmse: 152.331\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[25]\ttrain's rmse: 149.01\tvalid's rmse: 151.754\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[26]\ttrain's rmse: 148.374\tvalid's rmse: 151.161\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 9\n",
      "[27]\ttrain's rmse: 147.76\tvalid's rmse: 150.583\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[28]\ttrain's rmse: 147.145\tvalid's rmse: 149.989\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 9\n",
      "[29]\ttrain's rmse: 146.529\tvalid's rmse: 149.434\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[30]\ttrain's rmse: 145.959\tvalid's rmse: 148.897\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[31]\ttrain's rmse: 145.432\tvalid's rmse: 148.464\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[32]\ttrain's rmse: 144.797\tvalid's rmse: 147.907\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[33]\ttrain's rmse: 144.217\tvalid's rmse: 147.379\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[34]\ttrain's rmse: 143.642\tvalid's rmse: 146.889\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[35]\ttrain's rmse: 143.063\tvalid's rmse: 146.396\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[36]\ttrain's rmse: 142.555\tvalid's rmse: 145.937\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[37]\ttrain's rmse: 141.984\tvalid's rmse: 145.418\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[38]\ttrain's rmse: 141.417\tvalid's rmse: 144.919\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[39]\ttrain's rmse: 140.898\tvalid's rmse: 144.438\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[40]\ttrain's rmse: 140.353\tvalid's rmse: 143.923\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[41]\ttrain's rmse: 139.851\tvalid's rmse: 143.452\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[42]\ttrain's rmse: 139.309\tvalid's rmse: 142.986\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[43]\ttrain's rmse: 138.756\tvalid's rmse: 142.505\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[44]\ttrain's rmse: 138.291\tvalid's rmse: 142.092\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 9\n",
      "[45]\ttrain's rmse: 137.815\tvalid's rmse: 141.646\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[46]\ttrain's rmse: 137.286\tvalid's rmse: 141.17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 9\n",
      "[47]\ttrain's rmse: 136.822\tvalid's rmse: 140.744\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 9\n",
      "[48]\ttrain's rmse: 136.332\tvalid's rmse: 140.311\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[49]\ttrain's rmse: 135.806\tvalid's rmse: 139.835\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[50]\ttrain's rmse: 135.362\tvalid's rmse: 139.441\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 9\n",
      "[51]\ttrain's rmse: 134.904\tvalid's rmse: 139.01\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[52]\ttrain's rmse: 134.431\tvalid's rmse: 138.577\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[53]\ttrain's rmse: 133.992\tvalid's rmse: 138.193\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[54]\ttrain's rmse: 133.563\tvalid's rmse: 137.83\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 9\n",
      "[55]\ttrain's rmse: 133.088\tvalid's rmse: 137.437\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[56]\ttrain's rmse: 132.618\tvalid's rmse: 137.027\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[57]\ttrain's rmse: 132.177\tvalid's rmse: 136.622\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[58]\ttrain's rmse: 131.774\tvalid's rmse: 136.259\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[59]\ttrain's rmse: 131.325\tvalid's rmse: 135.902\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[60]\ttrain's rmse: 130.938\tvalid's rmse: 135.558\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 9\n",
      "[61]\ttrain's rmse: 130.512\tvalid's rmse: 135.186\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[62]\ttrain's rmse: 130.096\tvalid's rmse: 134.855\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[63]\ttrain's rmse: 129.718\tvalid's rmse: 134.519\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 9\n",
      "[64]\ttrain's rmse: 129.335\tvalid's rmse: 134.175\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[65]\ttrain's rmse: 128.931\tvalid's rmse: 133.836\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[66]\ttrain's rmse: 128.522\tvalid's rmse: 133.51\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[67]\ttrain's rmse: 128.115\tvalid's rmse: 133.188\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[68]\ttrain's rmse: 127.718\tvalid's rmse: 132.835\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[69]\ttrain's rmse: 127.333\tvalid's rmse: 132.491\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[70]\ttrain's rmse: 126.936\tvalid's rmse: 132.151\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[71]\ttrain's rmse: 126.541\tvalid's rmse: 131.818\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[72]\ttrain's rmse: 126.189\tvalid's rmse: 131.528\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 9\n",
      "[73]\ttrain's rmse: 125.786\tvalid's rmse: 131.216\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[74]\ttrain's rmse: 125.426\tvalid's rmse: 130.902\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[75]\ttrain's rmse: 125.061\tvalid's rmse: 130.614\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[76]\ttrain's rmse: 124.7\tvalid's rmse: 130.331\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[77]\ttrain's rmse: 124.371\tvalid's rmse: 130.086\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[78]\ttrain's rmse: 124.013\tvalid's rmse: 129.786\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[79]\ttrain's rmse: 123.671\tvalid's rmse: 129.523\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[80]\ttrain's rmse: 123.321\tvalid's rmse: 129.216\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[81]\ttrain's rmse: 122.997\tvalid's rmse: 128.93\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[82]\ttrain's rmse: 122.714\tvalid's rmse: 128.692\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[83]\ttrain's rmse: 122.421\tvalid's rmse: 128.456\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[84]\ttrain's rmse: 122.109\tvalid's rmse: 128.183\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[85]\ttrain's rmse: 121.811\tvalid's rmse: 127.941\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[86]\ttrain's rmse: 121.519\tvalid's rmse: 127.705\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[87]\ttrain's rmse: 121.197\tvalid's rmse: 127.462\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[88]\ttrain's rmse: 120.878\tvalid's rmse: 127.213\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[89]\ttrain's rmse: 120.55\tvalid's rmse: 126.964\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[90]\ttrain's rmse: 120.227\tvalid's rmse: 126.741\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[91]\ttrain's rmse: 119.932\tvalid's rmse: 126.494\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[92]\ttrain's rmse: 119.655\tvalid's rmse: 126.263\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[93]\ttrain's rmse: 119.333\tvalid's rmse: 126.027\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[94]\ttrain's rmse: 119.084\tvalid's rmse: 125.849\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[95]\ttrain's rmse: 118.803\tvalid's rmse: 125.629\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[96]\ttrain's rmse: 118.496\tvalid's rmse: 125.421\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[97]\ttrain's rmse: 118.232\tvalid's rmse: 125.201\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[98]\ttrain's rmse: 117.948\tvalid's rmse: 124.993\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[99]\ttrain's rmse: 117.65\tvalid's rmse: 124.739\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[100]\ttrain's rmse: 117.402\tvalid's rmse: 124.535\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[101]\ttrain's rmse: 117.135\tvalid's rmse: 124.353\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[102]\ttrain's rmse: 116.896\tvalid's rmse: 124.173\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[103]\ttrain's rmse: 116.641\tvalid's rmse: 123.988\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[104]\ttrain's rmse: 116.369\tvalid's rmse: 123.793\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[105]\ttrain's rmse: 116.098\tvalid's rmse: 123.606\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[106]\ttrain's rmse: 115.837\tvalid's rmse: 123.418\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[107]\ttrain's rmse: 115.558\tvalid's rmse: 123.21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[108]\ttrain's rmse: 115.312\tvalid's rmse: 123.032\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[109]\ttrain's rmse: 115.059\tvalid's rmse: 122.855\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[110]\ttrain's rmse: 114.807\tvalid's rmse: 122.652\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[111]\ttrain's rmse: 114.555\tvalid's rmse: 122.484\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[112]\ttrain's rmse: 114.307\tvalid's rmse: 122.308\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[113]\ttrain's rmse: 114.037\tvalid's rmse: 122.124\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[114]\ttrain's rmse: 113.807\tvalid's rmse: 121.942\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[115]\ttrain's rmse: 113.568\tvalid's rmse: 121.783\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[116]\ttrain's rmse: 113.332\tvalid's rmse: 121.626\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[117]\ttrain's rmse: 113.119\tvalid's rmse: 121.461\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[118]\ttrain's rmse: 112.934\tvalid's rmse: 121.336\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[119]\ttrain's rmse: 112.682\tvalid's rmse: 121.176\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[120]\ttrain's rmse: 112.494\tvalid's rmse: 121.036\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[121]\ttrain's rmse: 112.261\tvalid's rmse: 120.893\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[122]\ttrain's rmse: 112.038\tvalid's rmse: 120.755\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[123]\ttrain's rmse: 111.802\tvalid's rmse: 120.593\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[124]\ttrain's rmse: 111.592\tvalid's rmse: 120.447\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[125]\ttrain's rmse: 111.391\tvalid's rmse: 120.307\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[126]\ttrain's rmse: 111.191\tvalid's rmse: 120.169\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[127]\ttrain's rmse: 110.98\tvalid's rmse: 120.036\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[128]\ttrain's rmse: 110.764\tvalid's rmse: 119.9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[129]\ttrain's rmse: 110.55\tvalid's rmse: 119.743\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[130]\ttrain's rmse: 110.33\tvalid's rmse: 119.59\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[131]\ttrain's rmse: 110.131\tvalid's rmse: 119.475\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[132]\ttrain's rmse: 109.932\tvalid's rmse: 119.361\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[133]\ttrain's rmse: 109.758\tvalid's rmse: 119.232\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[134]\ttrain's rmse: 109.56\tvalid's rmse: 119.126\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[135]\ttrain's rmse: 109.378\tvalid's rmse: 119.022\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[136]\ttrain's rmse: 109.2\tvalid's rmse: 118.894\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[137]\ttrain's rmse: 109.018\tvalid's rmse: 118.78\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[138]\ttrain's rmse: 108.831\tvalid's rmse: 118.646\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[139]\ttrain's rmse: 108.649\tvalid's rmse: 118.538\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[140]\ttrain's rmse: 108.463\tvalid's rmse: 118.434\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[141]\ttrain's rmse: 108.298\tvalid's rmse: 118.326\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[142]\ttrain's rmse: 108.119\tvalid's rmse: 118.23\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[143]\ttrain's rmse: 107.928\tvalid's rmse: 118.114\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[144]\ttrain's rmse: 107.741\tvalid's rmse: 117.996\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[145]\ttrain's rmse: 107.567\tvalid's rmse: 117.894\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[146]\ttrain's rmse: 107.391\tvalid's rmse: 117.789\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[147]\ttrain's rmse: 107.222\tvalid's rmse: 117.676\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[148]\ttrain's rmse: 107.043\tvalid's rmse: 117.57\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[149]\ttrain's rmse: 106.874\tvalid's rmse: 117.449\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[150]\ttrain's rmse: 106.701\tvalid's rmse: 117.351\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[151]\ttrain's rmse: 106.534\tvalid's rmse: 117.24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[152]\ttrain's rmse: 106.377\tvalid's rmse: 117.118\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[153]\ttrain's rmse: 106.225\tvalid's rmse: 117.009\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[154]\ttrain's rmse: 106.041\tvalid's rmse: 116.881\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[155]\ttrain's rmse: 105.879\tvalid's rmse: 116.788\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[156]\ttrain's rmse: 105.722\tvalid's rmse: 116.702\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[157]\ttrain's rmse: 105.584\tvalid's rmse: 116.607\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[158]\ttrain's rmse: 105.417\tvalid's rmse: 116.504\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[159]\ttrain's rmse: 105.273\tvalid's rmse: 116.416\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[160]\ttrain's rmse: 105.098\tvalid's rmse: 116.308\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[161]\ttrain's rmse: 104.975\tvalid's rmse: 116.227\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[162]\ttrain's rmse: 104.817\tvalid's rmse: 116.121\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[163]\ttrain's rmse: 104.687\tvalid's rmse: 116.029\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[164]\ttrain's rmse: 104.535\tvalid's rmse: 115.931\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[165]\ttrain's rmse: 104.383\tvalid's rmse: 115.825\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[166]\ttrain's rmse: 104.262\tvalid's rmse: 115.742\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[167]\ttrain's rmse: 104.138\tvalid's rmse: 115.662\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[168]\ttrain's rmse: 103.988\tvalid's rmse: 115.572\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[169]\ttrain's rmse: 103.841\tvalid's rmse: 115.474\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[170]\ttrain's rmse: 103.712\tvalid's rmse: 115.398\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[171]\ttrain's rmse: 103.582\tvalid's rmse: 115.308\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[172]\ttrain's rmse: 103.455\tvalid's rmse: 115.221\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[173]\ttrain's rmse: 103.314\tvalid's rmse: 115.161\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[174]\ttrain's rmse: 103.178\tvalid's rmse: 115.084\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[175]\ttrain's rmse: 103.037\tvalid's rmse: 115.013\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[176]\ttrain's rmse: 102.928\tvalid's rmse: 114.946\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[177]\ttrain's rmse: 102.786\tvalid's rmse: 114.852\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[178]\ttrain's rmse: 102.649\tvalid's rmse: 114.769\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[179]\ttrain's rmse: 102.523\tvalid's rmse: 114.704\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[180]\ttrain's rmse: 102.395\tvalid's rmse: 114.635\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[181]\ttrain's rmse: 102.277\tvalid's rmse: 114.555\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[182]\ttrain's rmse: 102.145\tvalid's rmse: 114.472\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[183]\ttrain's rmse: 102.018\tvalid's rmse: 114.407\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[184]\ttrain's rmse: 101.874\tvalid's rmse: 114.322\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[185]\ttrain's rmse: 101.759\tvalid's rmse: 114.253\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[186]\ttrain's rmse: 101.631\tvalid's rmse: 114.189\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[187]\ttrain's rmse: 101.507\tvalid's rmse: 114.109\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[188]\ttrain's rmse: 101.395\tvalid's rmse: 114.031\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[189]\ttrain's rmse: 101.271\tvalid's rmse: 113.969\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[190]\ttrain's rmse: 101.144\tvalid's rmse: 113.905\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[191]\ttrain's rmse: 101.005\tvalid's rmse: 113.839\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[192]\ttrain's rmse: 100.89\tvalid's rmse: 113.782\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[193]\ttrain's rmse: 100.769\tvalid's rmse: 113.722\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[194]\ttrain's rmse: 100.656\tvalid's rmse: 113.651\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[195]\ttrain's rmse: 100.544\tvalid's rmse: 113.592\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[196]\ttrain's rmse: 100.424\tvalid's rmse: 113.527\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[197]\ttrain's rmse: 100.289\tvalid's rmse: 113.453\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[198]\ttrain's rmse: 100.182\tvalid's rmse: 113.381\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[199]\ttrain's rmse: 100.084\tvalid's rmse: 113.331\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[200]\ttrain's rmse: 99.9645\tvalid's rmse: 113.261\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[201]\ttrain's rmse: 99.8546\tvalid's rmse: 113.186\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[202]\ttrain's rmse: 99.7603\tvalid's rmse: 113.145\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[203]\ttrain's rmse: 99.6515\tvalid's rmse: 113.092\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[204]\ttrain's rmse: 99.5509\tvalid's rmse: 113.045\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[205]\ttrain's rmse: 99.4297\tvalid's rmse: 112.992\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[206]\ttrain's rmse: 99.3211\tvalid's rmse: 112.95\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[207]\ttrain's rmse: 99.2271\tvalid's rmse: 112.908\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[208]\ttrain's rmse: 99.1162\tvalid's rmse: 112.841\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[209]\ttrain's rmse: 99.0102\tvalid's rmse: 112.791\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[210]\ttrain's rmse: 98.9141\tvalid's rmse: 112.734\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[211]\ttrain's rmse: 98.7936\tvalid's rmse: 112.662\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[212]\ttrain's rmse: 98.6906\tvalid's rmse: 112.606\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[213]\ttrain's rmse: 98.604\tvalid's rmse: 112.567\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[214]\ttrain's rmse: 98.5177\tvalid's rmse: 112.53\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[215]\ttrain's rmse: 98.4221\tvalid's rmse: 112.487\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[216]\ttrain's rmse: 98.3025\tvalid's rmse: 112.432\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[217]\ttrain's rmse: 98.2027\tvalid's rmse: 112.386\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[218]\ttrain's rmse: 98.1054\tvalid's rmse: 112.35\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[219]\ttrain's rmse: 98.0023\tvalid's rmse: 112.304\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[220]\ttrain's rmse: 97.8975\tvalid's rmse: 112.262\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[221]\ttrain's rmse: 97.7997\tvalid's rmse: 112.218\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[222]\ttrain's rmse: 97.7101\tvalid's rmse: 112.169\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[223]\ttrain's rmse: 97.6115\tvalid's rmse: 112.123\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[224]\ttrain's rmse: 97.4994\tvalid's rmse: 112.068\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[225]\ttrain's rmse: 97.4043\tvalid's rmse: 112.018\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[226]\ttrain's rmse: 97.3025\tvalid's rmse: 111.977\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[227]\ttrain's rmse: 97.2087\tvalid's rmse: 111.933\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[228]\ttrain's rmse: 97.1254\tvalid's rmse: 111.904\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[229]\ttrain's rmse: 97.0352\tvalid's rmse: 111.858\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[230]\ttrain's rmse: 96.9474\tvalid's rmse: 111.813\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[231]\ttrain's rmse: 96.8477\tvalid's rmse: 111.758\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[232]\ttrain's rmse: 96.7635\tvalid's rmse: 111.71\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[233]\ttrain's rmse: 96.6783\tvalid's rmse: 111.66\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[234]\ttrain's rmse: 96.6026\tvalid's rmse: 111.623\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[235]\ttrain's rmse: 96.5112\tvalid's rmse: 111.584\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[236]\ttrain's rmse: 96.4075\tvalid's rmse: 111.541\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[237]\ttrain's rmse: 96.3173\tvalid's rmse: 111.498\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[238]\ttrain's rmse: 96.2258\tvalid's rmse: 111.461\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[239]\ttrain's rmse: 96.1314\tvalid's rmse: 111.423\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[240]\ttrain's rmse: 96.0445\tvalid's rmse: 111.391\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[241]\ttrain's rmse: 95.9629\tvalid's rmse: 111.343\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[242]\ttrain's rmse: 95.8732\tvalid's rmse: 111.293\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[243]\ttrain's rmse: 95.7853\tvalid's rmse: 111.262\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[244]\ttrain's rmse: 95.6981\tvalid's rmse: 111.22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[245]\ttrain's rmse: 95.6007\tvalid's rmse: 111.179\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[246]\ttrain's rmse: 95.5196\tvalid's rmse: 111.139\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[247]\ttrain's rmse: 95.4333\tvalid's rmse: 111.095\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[248]\ttrain's rmse: 95.3433\tvalid's rmse: 111.056\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[249]\ttrain's rmse: 95.2702\tvalid's rmse: 111.018\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[250]\ttrain's rmse: 95.2017\tvalid's rmse: 110.996\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[251]\ttrain's rmse: 95.1325\tvalid's rmse: 110.963\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[252]\ttrain's rmse: 95.0415\tvalid's rmse: 110.921\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[253]\ttrain's rmse: 94.9595\tvalid's rmse: 110.888\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[254]\ttrain's rmse: 94.8588\tvalid's rmse: 110.85\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[255]\ttrain's rmse: 94.7747\tvalid's rmse: 110.815\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[256]\ttrain's rmse: 94.6962\tvalid's rmse: 110.776\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[257]\ttrain's rmse: 94.6165\tvalid's rmse: 110.742\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[258]\ttrain's rmse: 94.5321\tvalid's rmse: 110.708\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[259]\ttrain's rmse: 94.4572\tvalid's rmse: 110.679\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[260]\ttrain's rmse: 94.3719\tvalid's rmse: 110.649\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[261]\ttrain's rmse: 94.2982\tvalid's rmse: 110.616\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[262]\ttrain's rmse: 94.2233\tvalid's rmse: 110.578\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[263]\ttrain's rmse: 94.1435\tvalid's rmse: 110.552\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[264]\ttrain's rmse: 94.0561\tvalid's rmse: 110.513\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[265]\ttrain's rmse: 93.9819\tvalid's rmse: 110.479\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[266]\ttrain's rmse: 93.9061\tvalid's rmse: 110.445\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[267]\ttrain's rmse: 93.8339\tvalid's rmse: 110.41\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[268]\ttrain's rmse: 93.7522\tvalid's rmse: 110.375\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[269]\ttrain's rmse: 93.6689\tvalid's rmse: 110.345\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[270]\ttrain's rmse: 93.5835\tvalid's rmse: 110.316\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[271]\ttrain's rmse: 93.5042\tvalid's rmse: 110.292\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[272]\ttrain's rmse: 93.4357\tvalid's rmse: 110.265\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[273]\ttrain's rmse: 93.3555\tvalid's rmse: 110.223\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[274]\ttrain's rmse: 93.2968\tvalid's rmse: 110.196\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[275]\ttrain's rmse: 93.2164\tvalid's rmse: 110.171\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[276]\ttrain's rmse: 93.1327\tvalid's rmse: 110.146\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[277]\ttrain's rmse: 93.0574\tvalid's rmse: 110.119\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[278]\ttrain's rmse: 92.9915\tvalid's rmse: 110.093\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[279]\ttrain's rmse: 92.9314\tvalid's rmse: 110.072\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[280]\ttrain's rmse: 92.8643\tvalid's rmse: 110.044\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[281]\ttrain's rmse: 92.7998\tvalid's rmse: 110.017\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[282]\ttrain's rmse: 92.7267\tvalid's rmse: 109.986\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[283]\ttrain's rmse: 92.6534\tvalid's rmse: 109.962\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[284]\ttrain's rmse: 92.5771\tvalid's rmse: 109.934\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[285]\ttrain's rmse: 92.5154\tvalid's rmse: 109.913\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[286]\ttrain's rmse: 92.457\tvalid's rmse: 109.892\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[287]\ttrain's rmse: 92.3874\tvalid's rmse: 109.863\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[288]\ttrain's rmse: 92.3228\tvalid's rmse: 109.838\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[289]\ttrain's rmse: 92.2582\tvalid's rmse: 109.821\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[290]\ttrain's rmse: 92.1909\tvalid's rmse: 109.795\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[291]\ttrain's rmse: 92.1212\tvalid's rmse: 109.769\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[292]\ttrain's rmse: 92.0499\tvalid's rmse: 109.749\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[293]\ttrain's rmse: 91.9833\tvalid's rmse: 109.723\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[294]\ttrain's rmse: 91.9284\tvalid's rmse: 109.709\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[295]\ttrain's rmse: 91.864\tvalid's rmse: 109.684\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[296]\ttrain's rmse: 91.7968\tvalid's rmse: 109.656\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[297]\ttrain's rmse: 91.7269\tvalid's rmse: 109.634\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[298]\ttrain's rmse: 91.6569\tvalid's rmse: 109.616\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[299]\ttrain's rmse: 91.5939\tvalid's rmse: 109.599\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[300]\ttrain's rmse: 91.5409\tvalid's rmse: 109.578\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[301]\ttrain's rmse: 91.4648\tvalid's rmse: 109.551\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[302]\ttrain's rmse: 91.4002\tvalid's rmse: 109.53\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[303]\ttrain's rmse: 91.3363\tvalid's rmse: 109.51\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[304]\ttrain's rmse: 91.2716\tvalid's rmse: 109.49\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[305]\ttrain's rmse: 91.2046\tvalid's rmse: 109.468\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[306]\ttrain's rmse: 91.1303\tvalid's rmse: 109.447\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[307]\ttrain's rmse: 91.069\tvalid's rmse: 109.434\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[308]\ttrain's rmse: 91.0109\tvalid's rmse: 109.417\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[309]\ttrain's rmse: 90.9506\tvalid's rmse: 109.395\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[310]\ttrain's rmse: 90.8861\tvalid's rmse: 109.366\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[311]\ttrain's rmse: 90.8279\tvalid's rmse: 109.346\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[312]\ttrain's rmse: 90.7663\tvalid's rmse: 109.334\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[313]\ttrain's rmse: 90.6966\tvalid's rmse: 109.313\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[314]\ttrain's rmse: 90.6375\tvalid's rmse: 109.297\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[315]\ttrain's rmse: 90.5763\tvalid's rmse: 109.272\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[316]\ttrain's rmse: 90.5197\tvalid's rmse: 109.24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[317]\ttrain's rmse: 90.4573\tvalid's rmse: 109.232\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[318]\ttrain's rmse: 90.3915\tvalid's rmse: 109.215\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[319]\ttrain's rmse: 90.3328\tvalid's rmse: 109.194\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[320]\ttrain's rmse: 90.2733\tvalid's rmse: 109.168\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[321]\ttrain's rmse: 90.2219\tvalid's rmse: 109.152\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[322]\ttrain's rmse: 90.1569\tvalid's rmse: 109.142\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[323]\ttrain's rmse: 90.1041\tvalid's rmse: 109.12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[324]\ttrain's rmse: 90.0536\tvalid's rmse: 109.104\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[325]\ttrain's rmse: 89.9947\tvalid's rmse: 109.08\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[326]\ttrain's rmse: 89.9377\tvalid's rmse: 109.059\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[327]\ttrain's rmse: 89.8848\tvalid's rmse: 109.039\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[328]\ttrain's rmse: 89.8351\tvalid's rmse: 109.022\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[329]\ttrain's rmse: 89.7798\tvalid's rmse: 109.008\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[330]\ttrain's rmse: 89.7262\tvalid's rmse: 108.991\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[331]\ttrain's rmse: 89.6724\tvalid's rmse: 108.977\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[332]\ttrain's rmse: 89.6234\tvalid's rmse: 108.961\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[333]\ttrain's rmse: 89.5561\tvalid's rmse: 108.94\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[334]\ttrain's rmse: 89.4932\tvalid's rmse: 108.916\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[335]\ttrain's rmse: 89.4369\tvalid's rmse: 108.902\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[336]\ttrain's rmse: 89.3808\tvalid's rmse: 108.889\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[337]\ttrain's rmse: 89.3318\tvalid's rmse: 108.866\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[338]\ttrain's rmse: 89.279\tvalid's rmse: 108.846\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[339]\ttrain's rmse: 89.224\tvalid's rmse: 108.827\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[340]\ttrain's rmse: 89.1779\tvalid's rmse: 108.813\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[341]\ttrain's rmse: 89.1233\tvalid's rmse: 108.791\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[342]\ttrain's rmse: 89.0649\tvalid's rmse: 108.769\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[343]\ttrain's rmse: 89.0117\tvalid's rmse: 108.751\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[344]\ttrain's rmse: 88.9587\tvalid's rmse: 108.74\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[345]\ttrain's rmse: 88.8986\tvalid's rmse: 108.728\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[346]\ttrain's rmse: 88.8539\tvalid's rmse: 108.709\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[347]\ttrain's rmse: 88.7989\tvalid's rmse: 108.701\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[348]\ttrain's rmse: 88.7494\tvalid's rmse: 108.675\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[349]\ttrain's rmse: 88.7017\tvalid's rmse: 108.658\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[350]\ttrain's rmse: 88.6512\tvalid's rmse: 108.639\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[351]\ttrain's rmse: 88.6043\tvalid's rmse: 108.624\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[352]\ttrain's rmse: 88.5545\tvalid's rmse: 108.613\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[353]\ttrain's rmse: 88.4912\tvalid's rmse: 108.595\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[354]\ttrain's rmse: 88.4417\tvalid's rmse: 108.577\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[355]\ttrain's rmse: 88.3867\tvalid's rmse: 108.566\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[356]\ttrain's rmse: 88.3343\tvalid's rmse: 108.547\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[357]\ttrain's rmse: 88.29\tvalid's rmse: 108.53\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[358]\ttrain's rmse: 88.2401\tvalid's rmse: 108.518\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[359]\ttrain's rmse: 88.186\tvalid's rmse: 108.504\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[360]\ttrain's rmse: 88.1436\tvalid's rmse: 108.487\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[361]\ttrain's rmse: 88.0931\tvalid's rmse: 108.467\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[362]\ttrain's rmse: 88.0564\tvalid's rmse: 108.453\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[363]\ttrain's rmse: 88.0072\tvalid's rmse: 108.444\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[364]\ttrain's rmse: 87.9603\tvalid's rmse: 108.427\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[365]\ttrain's rmse: 87.9078\tvalid's rmse: 108.406\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[366]\ttrain's rmse: 87.8507\tvalid's rmse: 108.389\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[367]\ttrain's rmse: 87.8084\tvalid's rmse: 108.379\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[368]\ttrain's rmse: 87.7619\tvalid's rmse: 108.363\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[369]\ttrain's rmse: 87.7141\tvalid's rmse: 108.349\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[370]\ttrain's rmse: 87.6669\tvalid's rmse: 108.339\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[371]\ttrain's rmse: 87.6189\tvalid's rmse: 108.334\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[372]\ttrain's rmse: 87.5636\tvalid's rmse: 108.328\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[373]\ttrain's rmse: 87.5142\tvalid's rmse: 108.317\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[374]\ttrain's rmse: 87.4736\tvalid's rmse: 108.311\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[375]\ttrain's rmse: 87.4341\tvalid's rmse: 108.302\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[376]\ttrain's rmse: 87.3885\tvalid's rmse: 108.288\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[377]\ttrain's rmse: 87.3439\tvalid's rmse: 108.278\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[378]\ttrain's rmse: 87.2954\tvalid's rmse: 108.265\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[379]\ttrain's rmse: 87.2494\tvalid's rmse: 108.251\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[380]\ttrain's rmse: 87.198\tvalid's rmse: 108.239\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[381]\ttrain's rmse: 87.1549\tvalid's rmse: 108.229\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[382]\ttrain's rmse: 87.1088\tvalid's rmse: 108.225\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[383]\ttrain's rmse: 87.0641\tvalid's rmse: 108.211\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[384]\ttrain's rmse: 87.0218\tvalid's rmse: 108.198\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[385]\ttrain's rmse: 86.9743\tvalid's rmse: 108.182\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[386]\ttrain's rmse: 86.9353\tvalid's rmse: 108.177\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[387]\ttrain's rmse: 86.8875\tvalid's rmse: 108.166\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[388]\ttrain's rmse: 86.848\tvalid's rmse: 108.156\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[389]\ttrain's rmse: 86.8012\tvalid's rmse: 108.144\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[390]\ttrain's rmse: 86.7598\tvalid's rmse: 108.133\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[391]\ttrain's rmse: 86.7126\tvalid's rmse: 108.119\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[392]\ttrain's rmse: 86.6563\tvalid's rmse: 108.103\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[393]\ttrain's rmse: 86.6045\tvalid's rmse: 108.091\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[394]\ttrain's rmse: 86.5623\tvalid's rmse: 108.085\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[395]\ttrain's rmse: 86.5108\tvalid's rmse: 108.081\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[396]\ttrain's rmse: 86.4693\tvalid's rmse: 108.072\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[397]\ttrain's rmse: 86.4276\tvalid's rmse: 108.057\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[398]\ttrain's rmse: 86.3906\tvalid's rmse: 108.047\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[399]\ttrain's rmse: 86.3445\tvalid's rmse: 108.034\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[400]\ttrain's rmse: 86.304\tvalid's rmse: 108.019\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[401]\ttrain's rmse: 86.2596\tvalid's rmse: 108.006\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[402]\ttrain's rmse: 86.2173\tvalid's rmse: 107.992\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[403]\ttrain's rmse: 86.1683\tvalid's rmse: 107.976\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[404]\ttrain's rmse: 86.1234\tvalid's rmse: 107.964\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[405]\ttrain's rmse: 86.0801\tvalid's rmse: 107.951\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[406]\ttrain's rmse: 86.0384\tvalid's rmse: 107.94\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[407]\ttrain's rmse: 85.991\tvalid's rmse: 107.935\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[408]\ttrain's rmse: 85.9492\tvalid's rmse: 107.928\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[409]\ttrain's rmse: 85.9009\tvalid's rmse: 107.921\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[410]\ttrain's rmse: 85.8672\tvalid's rmse: 107.916\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[411]\ttrain's rmse: 85.8205\tvalid's rmse: 107.906\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[412]\ttrain's rmse: 85.7771\tvalid's rmse: 107.9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[413]\ttrain's rmse: 85.7328\tvalid's rmse: 107.893\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[414]\ttrain's rmse: 85.6855\tvalid's rmse: 107.886\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[415]\ttrain's rmse: 85.6392\tvalid's rmse: 107.882\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[416]\ttrain's rmse: 85.5988\tvalid's rmse: 107.869\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[417]\ttrain's rmse: 85.5627\tvalid's rmse: 107.86\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[418]\ttrain's rmse: 85.5201\tvalid's rmse: 107.85\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[419]\ttrain's rmse: 85.4778\tvalid's rmse: 107.833\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[420]\ttrain's rmse: 85.4341\tvalid's rmse: 107.83\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[421]\ttrain's rmse: 85.3866\tvalid's rmse: 107.821\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[422]\ttrain's rmse: 85.344\tvalid's rmse: 107.812\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[423]\ttrain's rmse: 85.3113\tvalid's rmse: 107.807\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[424]\ttrain's rmse: 85.261\tvalid's rmse: 107.798\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[425]\ttrain's rmse: 85.223\tvalid's rmse: 107.783\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[426]\ttrain's rmse: 85.1789\tvalid's rmse: 107.778\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[427]\ttrain's rmse: 85.1409\tvalid's rmse: 107.774\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[428]\ttrain's rmse: 85.105\tvalid's rmse: 107.764\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[429]\ttrain's rmse: 85.0597\tvalid's rmse: 107.75\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[430]\ttrain's rmse: 85.0167\tvalid's rmse: 107.737\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[431]\ttrain's rmse: 84.9756\tvalid's rmse: 107.725\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[432]\ttrain's rmse: 84.9345\tvalid's rmse: 107.718\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[433]\ttrain's rmse: 84.8983\tvalid's rmse: 107.709\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[434]\ttrain's rmse: 84.8573\tvalid's rmse: 107.7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[435]\ttrain's rmse: 84.8137\tvalid's rmse: 107.694\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[436]\ttrain's rmse: 84.7732\tvalid's rmse: 107.692\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[437]\ttrain's rmse: 84.7337\tvalid's rmse: 107.682\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[438]\ttrain's rmse: 84.7008\tvalid's rmse: 107.67\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[439]\ttrain's rmse: 84.6632\tvalid's rmse: 107.659\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[440]\ttrain's rmse: 84.6287\tvalid's rmse: 107.655\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[441]\ttrain's rmse: 84.5893\tvalid's rmse: 107.646\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[442]\ttrain's rmse: 84.5482\tvalid's rmse: 107.633\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[443]\ttrain's rmse: 84.5094\tvalid's rmse: 107.628\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[444]\ttrain's rmse: 84.4765\tvalid's rmse: 107.622\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[445]\ttrain's rmse: 84.4416\tvalid's rmse: 107.61\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[446]\ttrain's rmse: 84.4014\tvalid's rmse: 107.594\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[447]\ttrain's rmse: 84.3613\tvalid's rmse: 107.585\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[448]\ttrain's rmse: 84.3195\tvalid's rmse: 107.584\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[449]\ttrain's rmse: 84.2803\tvalid's rmse: 107.571\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[450]\ttrain's rmse: 84.2416\tvalid's rmse: 107.562\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[451]\ttrain's rmse: 84.1959\tvalid's rmse: 107.554\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[452]\ttrain's rmse: 84.157\tvalid's rmse: 107.541\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[453]\ttrain's rmse: 84.1189\tvalid's rmse: 107.53\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[454]\ttrain's rmse: 84.0738\tvalid's rmse: 107.515\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[455]\ttrain's rmse: 84.0408\tvalid's rmse: 107.508\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[456]\ttrain's rmse: 84.0078\tvalid's rmse: 107.5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[457]\ttrain's rmse: 83.9684\tvalid's rmse: 107.493\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[458]\ttrain's rmse: 83.933\tvalid's rmse: 107.484\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[459]\ttrain's rmse: 83.8903\tvalid's rmse: 107.478\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 28\n",
      "[460]\ttrain's rmse: 83.8554\tvalid's rmse: 107.465\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[461]\ttrain's rmse: 83.817\tvalid's rmse: 107.46\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[462]\ttrain's rmse: 83.7776\tvalid's rmse: 107.444\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[463]\ttrain's rmse: 83.7437\tvalid's rmse: 107.434\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[464]\ttrain's rmse: 83.7021\tvalid's rmse: 107.427\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[465]\ttrain's rmse: 83.6656\tvalid's rmse: 107.421\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[466]\ttrain's rmse: 83.6277\tvalid's rmse: 107.414\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[467]\ttrain's rmse: 83.5815\tvalid's rmse: 107.404\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[468]\ttrain's rmse: 83.5409\tvalid's rmse: 107.398\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[469]\ttrain's rmse: 83.5046\tvalid's rmse: 107.381\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[470]\ttrain's rmse: 83.47\tvalid's rmse: 107.374\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[471]\ttrain's rmse: 83.4313\tvalid's rmse: 107.37\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[472]\ttrain's rmse: 83.3922\tvalid's rmse: 107.358\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[473]\ttrain's rmse: 83.3594\tvalid's rmse: 107.345\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[474]\ttrain's rmse: 83.3284\tvalid's rmse: 107.337\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[475]\ttrain's rmse: 83.2902\tvalid's rmse: 107.329\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[476]\ttrain's rmse: 83.2502\tvalid's rmse: 107.313\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[477]\ttrain's rmse: 83.2121\tvalid's rmse: 107.308\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[478]\ttrain's rmse: 83.1741\tvalid's rmse: 107.299\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[479]\ttrain's rmse: 83.1432\tvalid's rmse: 107.288\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[480]\ttrain's rmse: 83.1033\tvalid's rmse: 107.284\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 23\n",
      "[481]\ttrain's rmse: 83.0643\tvalid's rmse: 107.28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[482]\ttrain's rmse: 83.037\tvalid's rmse: 107.272\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[483]\ttrain's rmse: 82.9991\tvalid's rmse: 107.268\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[484]\ttrain's rmse: 82.9743\tvalid's rmse: 107.264\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[485]\ttrain's rmse: 82.9382\tvalid's rmse: 107.262\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[486]\ttrain's rmse: 82.9009\tvalid's rmse: 107.26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[487]\ttrain's rmse: 82.8708\tvalid's rmse: 107.26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[488]\ttrain's rmse: 82.8355\tvalid's rmse: 107.254\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[489]\ttrain's rmse: 82.8006\tvalid's rmse: 107.25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[490]\ttrain's rmse: 82.7642\tvalid's rmse: 107.247\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[491]\ttrain's rmse: 82.7307\tvalid's rmse: 107.24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[492]\ttrain's rmse: 82.6963\tvalid's rmse: 107.233\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[493]\ttrain's rmse: 82.6622\tvalid's rmse: 107.224\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[494]\ttrain's rmse: 82.6328\tvalid's rmse: 107.223\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[495]\ttrain's rmse: 82.5996\tvalid's rmse: 107.218\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[496]\ttrain's rmse: 82.5639\tvalid's rmse: 107.206\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[497]\ttrain's rmse: 82.5275\tvalid's rmse: 107.198\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[498]\ttrain's rmse: 82.497\tvalid's rmse: 107.192\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[499]\ttrain's rmse: 82.461\tvalid's rmse: 107.191\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[500]\ttrain's rmse: 82.4301\tvalid's rmse: 107.183\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[501]\ttrain's rmse: 82.3951\tvalid's rmse: 107.173\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[502]\ttrain's rmse: 82.3593\tvalid's rmse: 107.166\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[503]\ttrain's rmse: 82.3253\tvalid's rmse: 107.16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[504]\ttrain's rmse: 82.2849\tvalid's rmse: 107.158\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 23\n",
      "[505]\ttrain's rmse: 82.2449\tvalid's rmse: 107.148\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[506]\ttrain's rmse: 82.2125\tvalid's rmse: 107.148\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[507]\ttrain's rmse: 82.1828\tvalid's rmse: 107.147\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[508]\ttrain's rmse: 82.1452\tvalid's rmse: 107.139\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[509]\ttrain's rmse: 82.1077\tvalid's rmse: 107.129\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[510]\ttrain's rmse: 82.0687\tvalid's rmse: 107.12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[511]\ttrain's rmse: 82.0358\tvalid's rmse: 107.114\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[512]\ttrain's rmse: 82.0056\tvalid's rmse: 107.114\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[513]\ttrain's rmse: 81.9729\tvalid's rmse: 107.112\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[514]\ttrain's rmse: 81.9406\tvalid's rmse: 107.109\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[515]\ttrain's rmse: 81.9041\tvalid's rmse: 107.104\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[516]\ttrain's rmse: 81.8687\tvalid's rmse: 107.096\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[517]\ttrain's rmse: 81.8362\tvalid's rmse: 107.093\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[518]\ttrain's rmse: 81.8051\tvalid's rmse: 107.082\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[519]\ttrain's rmse: 81.7769\tvalid's rmse: 107.076\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[520]\ttrain's rmse: 81.747\tvalid's rmse: 107.071\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[521]\ttrain's rmse: 81.7159\tvalid's rmse: 107.068\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[522]\ttrain's rmse: 81.6874\tvalid's rmse: 107.065\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[523]\ttrain's rmse: 81.6584\tvalid's rmse: 107.056\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[524]\ttrain's rmse: 81.6257\tvalid's rmse: 107.049\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[525]\ttrain's rmse: 81.5894\tvalid's rmse: 107.041\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[526]\ttrain's rmse: 81.5607\tvalid's rmse: 107.032\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[527]\ttrain's rmse: 81.5317\tvalid's rmse: 107.025\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[528]\ttrain's rmse: 81.4992\tvalid's rmse: 107.021\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[529]\ttrain's rmse: 81.4709\tvalid's rmse: 107.016\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[530]\ttrain's rmse: 81.4373\tvalid's rmse: 107.01\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[531]\ttrain's rmse: 81.4036\tvalid's rmse: 107\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[532]\ttrain's rmse: 81.371\tvalid's rmse: 106.995\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[533]\ttrain's rmse: 81.3393\tvalid's rmse: 106.988\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[534]\ttrain's rmse: 81.305\tvalid's rmse: 106.98\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[535]\ttrain's rmse: 81.2767\tvalid's rmse: 106.975\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[536]\ttrain's rmse: 81.2448\tvalid's rmse: 106.966\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[537]\ttrain's rmse: 81.2163\tvalid's rmse: 106.96\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[538]\ttrain's rmse: 81.1782\tvalid's rmse: 106.961\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[539]\ttrain's rmse: 81.1469\tvalid's rmse: 106.956\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[540]\ttrain's rmse: 81.1246\tvalid's rmse: 106.95\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[541]\ttrain's rmse: 81.0846\tvalid's rmse: 106.944\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[542]\ttrain's rmse: 81.0514\tvalid's rmse: 106.936\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[543]\ttrain's rmse: 81.0165\tvalid's rmse: 106.931\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[544]\ttrain's rmse: 80.9831\tvalid's rmse: 106.919\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[545]\ttrain's rmse: 80.9481\tvalid's rmse: 106.909\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[546]\ttrain's rmse: 80.9206\tvalid's rmse: 106.902\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[547]\ttrain's rmse: 80.8885\tvalid's rmse: 106.894\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 24\n",
      "[548]\ttrain's rmse: 80.8547\tvalid's rmse: 106.892\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[549]\ttrain's rmse: 80.8208\tvalid's rmse: 106.884\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[550]\ttrain's rmse: 80.7855\tvalid's rmse: 106.873\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[551]\ttrain's rmse: 80.7539\tvalid's rmse: 106.865\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[552]\ttrain's rmse: 80.7224\tvalid's rmse: 106.859\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[553]\ttrain's rmse: 80.6948\tvalid's rmse: 106.849\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[554]\ttrain's rmse: 80.6718\tvalid's rmse: 106.845\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[555]\ttrain's rmse: 80.6451\tvalid's rmse: 106.84\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[556]\ttrain's rmse: 80.616\tvalid's rmse: 106.836\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[557]\ttrain's rmse: 80.5853\tvalid's rmse: 106.829\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[558]\ttrain's rmse: 80.5587\tvalid's rmse: 106.823\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[559]\ttrain's rmse: 80.5303\tvalid's rmse: 106.815\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[560]\ttrain's rmse: 80.4976\tvalid's rmse: 106.808\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[561]\ttrain's rmse: 80.4669\tvalid's rmse: 106.809\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[562]\ttrain's rmse: 80.4407\tvalid's rmse: 106.806\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[563]\ttrain's rmse: 80.4098\tvalid's rmse: 106.806\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[564]\ttrain's rmse: 80.3783\tvalid's rmse: 106.796\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[565]\ttrain's rmse: 80.3514\tvalid's rmse: 106.792\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[566]\ttrain's rmse: 80.3212\tvalid's rmse: 106.79\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[567]\ttrain's rmse: 80.2945\tvalid's rmse: 106.785\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[568]\ttrain's rmse: 80.2635\tvalid's rmse: 106.777\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[569]\ttrain's rmse: 80.2258\tvalid's rmse: 106.769\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[570]\ttrain's rmse: 80.194\tvalid's rmse: 106.769\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[571]\ttrain's rmse: 80.1682\tvalid's rmse: 106.762\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[572]\ttrain's rmse: 80.1335\tvalid's rmse: 106.755\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[573]\ttrain's rmse: 80.1114\tvalid's rmse: 106.747\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[574]\ttrain's rmse: 80.0721\tvalid's rmse: 106.747\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[575]\ttrain's rmse: 80.048\tvalid's rmse: 106.744\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[576]\ttrain's rmse: 80.0149\tvalid's rmse: 106.739\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[577]\ttrain's rmse: 79.982\tvalid's rmse: 106.732\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[578]\ttrain's rmse: 79.9496\tvalid's rmse: 106.725\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[579]\ttrain's rmse: 79.9177\tvalid's rmse: 106.726\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[580]\ttrain's rmse: 79.8768\tvalid's rmse: 106.722\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[581]\ttrain's rmse: 79.8447\tvalid's rmse: 106.716\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[582]\ttrain's rmse: 79.8161\tvalid's rmse: 106.712\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[583]\ttrain's rmse: 79.7937\tvalid's rmse: 106.708\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[584]\ttrain's rmse: 79.762\tvalid's rmse: 106.707\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[585]\ttrain's rmse: 79.7347\tvalid's rmse: 106.703\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[586]\ttrain's rmse: 79.7101\tvalid's rmse: 106.705\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[587]\ttrain's rmse: 79.6866\tvalid's rmse: 106.703\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[588]\ttrain's rmse: 79.6536\tvalid's rmse: 106.702\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[589]\ttrain's rmse: 79.6227\tvalid's rmse: 106.695\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[590]\ttrain's rmse: 79.5943\tvalid's rmse: 106.692\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[591]\ttrain's rmse: 79.5634\tvalid's rmse: 106.691\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[592]\ttrain's rmse: 79.534\tvalid's rmse: 106.692\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[593]\ttrain's rmse: 79.5043\tvalid's rmse: 106.686\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[594]\ttrain's rmse: 79.4729\tvalid's rmse: 106.678\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[595]\ttrain's rmse: 79.4407\tvalid's rmse: 106.67\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[596]\ttrain's rmse: 79.4099\tvalid's rmse: 106.662\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[597]\ttrain's rmse: 79.3833\tvalid's rmse: 106.662\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[598]\ttrain's rmse: 79.3529\tvalid's rmse: 106.66\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[599]\ttrain's rmse: 79.3232\tvalid's rmse: 106.658\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[600]\ttrain's rmse: 79.2908\tvalid's rmse: 106.655\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[601]\ttrain's rmse: 79.2629\tvalid's rmse: 106.648\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[602]\ttrain's rmse: 79.2361\tvalid's rmse: 106.644\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 26\n",
      "[603]\ttrain's rmse: 79.2083\tvalid's rmse: 106.635\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[604]\ttrain's rmse: 79.1764\tvalid's rmse: 106.628\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[605]\ttrain's rmse: 79.1479\tvalid's rmse: 106.622\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[606]\ttrain's rmse: 79.1208\tvalid's rmse: 106.618\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[607]\ttrain's rmse: 79.096\tvalid's rmse: 106.614\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[608]\ttrain's rmse: 79.0641\tvalid's rmse: 106.6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[609]\ttrain's rmse: 79.0269\tvalid's rmse: 106.597\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[610]\ttrain's rmse: 78.9975\tvalid's rmse: 106.593\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[611]\ttrain's rmse: 78.9797\tvalid's rmse: 106.591\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[612]\ttrain's rmse: 78.9487\tvalid's rmse: 106.579\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[613]\ttrain's rmse: 78.9153\tvalid's rmse: 106.571\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[614]\ttrain's rmse: 78.8905\tvalid's rmse: 106.562\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[615]\ttrain's rmse: 78.8541\tvalid's rmse: 106.559\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[616]\ttrain's rmse: 78.8261\tvalid's rmse: 106.557\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[617]\ttrain's rmse: 78.7933\tvalid's rmse: 106.554\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[618]\ttrain's rmse: 78.7705\tvalid's rmse: 106.552\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[619]\ttrain's rmse: 78.7378\tvalid's rmse: 106.544\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[620]\ttrain's rmse: 78.7144\tvalid's rmse: 106.532\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[621]\ttrain's rmse: 78.6833\tvalid's rmse: 106.529\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[622]\ttrain's rmse: 78.6571\tvalid's rmse: 106.522\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[623]\ttrain's rmse: 78.6296\tvalid's rmse: 106.519\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[624]\ttrain's rmse: 78.6045\tvalid's rmse: 106.509\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[625]\ttrain's rmse: 78.5716\tvalid's rmse: 106.51\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[626]\ttrain's rmse: 78.5472\tvalid's rmse: 106.506\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[627]\ttrain's rmse: 78.5201\tvalid's rmse: 106.503\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[628]\ttrain's rmse: 78.4914\tvalid's rmse: 106.497\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[629]\ttrain's rmse: 78.4651\tvalid's rmse: 106.492\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[630]\ttrain's rmse: 78.4415\tvalid's rmse: 106.493\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[631]\ttrain's rmse: 78.4169\tvalid's rmse: 106.491\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[632]\ttrain's rmse: 78.3865\tvalid's rmse: 106.487\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[633]\ttrain's rmse: 78.3604\tvalid's rmse: 106.482\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[634]\ttrain's rmse: 78.3371\tvalid's rmse: 106.481\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[635]\ttrain's rmse: 78.3065\tvalid's rmse: 106.475\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[636]\ttrain's rmse: 78.2776\tvalid's rmse: 106.468\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[637]\ttrain's rmse: 78.2501\tvalid's rmse: 106.463\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[638]\ttrain's rmse: 78.2235\tvalid's rmse: 106.461\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[639]\ttrain's rmse: 78.1937\tvalid's rmse: 106.454\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[640]\ttrain's rmse: 78.1654\tvalid's rmse: 106.451\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[641]\ttrain's rmse: 78.138\tvalid's rmse: 106.449\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[642]\ttrain's rmse: 78.1043\tvalid's rmse: 106.438\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[643]\ttrain's rmse: 78.0671\tvalid's rmse: 106.436\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[644]\ttrain's rmse: 78.0339\tvalid's rmse: 106.43\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[645]\ttrain's rmse: 77.9975\tvalid's rmse: 106.427\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[646]\ttrain's rmse: 77.9686\tvalid's rmse: 106.422\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[647]\ttrain's rmse: 77.9402\tvalid's rmse: 106.415\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[648]\ttrain's rmse: 77.9129\tvalid's rmse: 106.416\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[649]\ttrain's rmse: 77.8833\tvalid's rmse: 106.409\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[650]\ttrain's rmse: 77.8572\tvalid's rmse: 106.408\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[651]\ttrain's rmse: 77.8288\tvalid's rmse: 106.405\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[652]\ttrain's rmse: 77.8021\tvalid's rmse: 106.402\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[653]\ttrain's rmse: 77.775\tvalid's rmse: 106.398\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[654]\ttrain's rmse: 77.7496\tvalid's rmse: 106.396\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[655]\ttrain's rmse: 77.7274\tvalid's rmse: 106.394\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[656]\ttrain's rmse: 77.7028\tvalid's rmse: 106.392\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[657]\ttrain's rmse: 77.6835\tvalid's rmse: 106.389\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[658]\ttrain's rmse: 77.6638\tvalid's rmse: 106.385\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[659]\ttrain's rmse: 77.6267\tvalid's rmse: 106.384\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[660]\ttrain's rmse: 77.5985\tvalid's rmse: 106.38\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[661]\ttrain's rmse: 77.5646\tvalid's rmse: 106.381\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[662]\ttrain's rmse: 77.5423\tvalid's rmse: 106.375\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[663]\ttrain's rmse: 77.5132\tvalid's rmse: 106.372\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[664]\ttrain's rmse: 77.4817\tvalid's rmse: 106.371\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[665]\ttrain's rmse: 77.4516\tvalid's rmse: 106.369\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[666]\ttrain's rmse: 77.4309\tvalid's rmse: 106.367\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[667]\ttrain's rmse: 77.4081\tvalid's rmse: 106.362\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[668]\ttrain's rmse: 77.3798\tvalid's rmse: 106.362\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[669]\ttrain's rmse: 77.3548\tvalid's rmse: 106.358\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[670]\ttrain's rmse: 77.3275\tvalid's rmse: 106.354\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[671]\ttrain's rmse: 77.2999\tvalid's rmse: 106.35\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 24\n",
      "[672]\ttrain's rmse: 77.2743\tvalid's rmse: 106.348\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[673]\ttrain's rmse: 77.2468\tvalid's rmse: 106.345\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[674]\ttrain's rmse: 77.2218\tvalid's rmse: 106.338\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[675]\ttrain's rmse: 77.2026\tvalid's rmse: 106.334\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[676]\ttrain's rmse: 77.1771\tvalid's rmse: 106.331\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[677]\ttrain's rmse: 77.1478\tvalid's rmse: 106.331\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[678]\ttrain's rmse: 77.1206\tvalid's rmse: 106.33\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[679]\ttrain's rmse: 77.0882\tvalid's rmse: 106.322\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[680]\ttrain's rmse: 77.0577\tvalid's rmse: 106.322\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[681]\ttrain's rmse: 77.0292\tvalid's rmse: 106.317\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[682]\ttrain's rmse: 77.0047\tvalid's rmse: 106.314\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[683]\ttrain's rmse: 76.9755\tvalid's rmse: 106.315\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[684]\ttrain's rmse: 76.9537\tvalid's rmse: 106.31\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[685]\ttrain's rmse: 76.9335\tvalid's rmse: 106.312\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[686]\ttrain's rmse: 76.9102\tvalid's rmse: 106.309\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[687]\ttrain's rmse: 76.883\tvalid's rmse: 106.307\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[688]\ttrain's rmse: 76.8547\tvalid's rmse: 106.304\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[689]\ttrain's rmse: 76.8234\tvalid's rmse: 106.3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[690]\ttrain's rmse: 76.8011\tvalid's rmse: 106.295\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[691]\ttrain's rmse: 76.7771\tvalid's rmse: 106.289\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[692]\ttrain's rmse: 76.7521\tvalid's rmse: 106.287\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[693]\ttrain's rmse: 76.72\tvalid's rmse: 106.285\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[694]\ttrain's rmse: 76.7011\tvalid's rmse: 106.279\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[695]\ttrain's rmse: 76.6687\tvalid's rmse: 106.272\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[696]\ttrain's rmse: 76.6454\tvalid's rmse: 106.267\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[697]\ttrain's rmse: 76.6238\tvalid's rmse: 106.264\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[698]\ttrain's rmse: 76.5981\tvalid's rmse: 106.258\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[699]\ttrain's rmse: 76.5752\tvalid's rmse: 106.255\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[700]\ttrain's rmse: 76.5497\tvalid's rmse: 106.254\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[701]\ttrain's rmse: 76.5225\tvalid's rmse: 106.249\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[702]\ttrain's rmse: 76.4979\tvalid's rmse: 106.248\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[703]\ttrain's rmse: 76.4735\tvalid's rmse: 106.244\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[704]\ttrain's rmse: 76.4485\tvalid's rmse: 106.244\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[705]\ttrain's rmse: 76.4153\tvalid's rmse: 106.241\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[706]\ttrain's rmse: 76.3841\tvalid's rmse: 106.238\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[707]\ttrain's rmse: 76.3564\tvalid's rmse: 106.233\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[708]\ttrain's rmse: 76.3324\tvalid's rmse: 106.229\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[709]\ttrain's rmse: 76.3108\tvalid's rmse: 106.228\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[710]\ttrain's rmse: 76.2875\tvalid's rmse: 106.224\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[711]\ttrain's rmse: 76.2598\tvalid's rmse: 106.221\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[712]\ttrain's rmse: 76.237\tvalid's rmse: 106.216\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[713]\ttrain's rmse: 76.2098\tvalid's rmse: 106.21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[714]\ttrain's rmse: 76.1851\tvalid's rmse: 106.209\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[715]\ttrain's rmse: 76.1614\tvalid's rmse: 106.201\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[716]\ttrain's rmse: 76.1344\tvalid's rmse: 106.2\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[717]\ttrain's rmse: 76.1109\tvalid's rmse: 106.197\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[718]\ttrain's rmse: 76.0818\tvalid's rmse: 106.193\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[719]\ttrain's rmse: 76.053\tvalid's rmse: 106.19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[720]\ttrain's rmse: 76.0214\tvalid's rmse: 106.183\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[721]\ttrain's rmse: 75.9989\tvalid's rmse: 106.177\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[722]\ttrain's rmse: 75.9719\tvalid's rmse: 106.178\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[723]\ttrain's rmse: 75.9451\tvalid's rmse: 106.174\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[724]\ttrain's rmse: 75.9253\tvalid's rmse: 106.169\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[725]\ttrain's rmse: 75.8952\tvalid's rmse: 106.164\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[726]\ttrain's rmse: 75.8699\tvalid's rmse: 106.16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[727]\ttrain's rmse: 75.8494\tvalid's rmse: 106.157\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[728]\ttrain's rmse: 75.8241\tvalid's rmse: 106.154\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[729]\ttrain's rmse: 75.8032\tvalid's rmse: 106.15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[730]\ttrain's rmse: 75.7746\tvalid's rmse: 106.147\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[731]\ttrain's rmse: 75.746\tvalid's rmse: 106.141\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[732]\ttrain's rmse: 75.7242\tvalid's rmse: 106.14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[733]\ttrain's rmse: 75.698\tvalid's rmse: 106.135\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[734]\ttrain's rmse: 75.6753\tvalid's rmse: 106.134\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[735]\ttrain's rmse: 75.6521\tvalid's rmse: 106.131\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[736]\ttrain's rmse: 75.6282\tvalid's rmse: 106.131\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[737]\ttrain's rmse: 75.6103\tvalid's rmse: 106.128\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[738]\ttrain's rmse: 75.5835\tvalid's rmse: 106.128\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[739]\ttrain's rmse: 75.5643\tvalid's rmse: 106.125\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[740]\ttrain's rmse: 75.5388\tvalid's rmse: 106.125\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[741]\ttrain's rmse: 75.5135\tvalid's rmse: 106.125\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[742]\ttrain's rmse: 75.4936\tvalid's rmse: 106.122\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[743]\ttrain's rmse: 75.4711\tvalid's rmse: 106.12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[744]\ttrain's rmse: 75.4377\tvalid's rmse: 106.112\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[745]\ttrain's rmse: 75.416\tvalid's rmse: 106.111\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[746]\ttrain's rmse: 75.3888\tvalid's rmse: 106.104\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[747]\ttrain's rmse: 75.3689\tvalid's rmse: 106.105\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[748]\ttrain's rmse: 75.3431\tvalid's rmse: 106.104\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[749]\ttrain's rmse: 75.3179\tvalid's rmse: 106.098\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[750]\ttrain's rmse: 75.2946\tvalid's rmse: 106.097\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[751]\ttrain's rmse: 75.2748\tvalid's rmse: 106.096\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[752]\ttrain's rmse: 75.2545\tvalid's rmse: 106.093\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[753]\ttrain's rmse: 75.2356\tvalid's rmse: 106.09\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[754]\ttrain's rmse: 75.2061\tvalid's rmse: 106.085\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[755]\ttrain's rmse: 75.1826\tvalid's rmse: 106.082\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[756]\ttrain's rmse: 75.156\tvalid's rmse: 106.078\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[757]\ttrain's rmse: 75.1336\tvalid's rmse: 106.078\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[758]\ttrain's rmse: 75.1128\tvalid's rmse: 106.079\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[759]\ttrain's rmse: 75.0863\tvalid's rmse: 106.079\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[760]\ttrain's rmse: 75.0616\tvalid's rmse: 106.078\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[761]\ttrain's rmse: 75.0327\tvalid's rmse: 106.07\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[762]\ttrain's rmse: 75.0083\tvalid's rmse: 106.07\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[763]\ttrain's rmse: 74.9861\tvalid's rmse: 106.07\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[764]\ttrain's rmse: 74.9679\tvalid's rmse: 106.068\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[765]\ttrain's rmse: 74.9404\tvalid's rmse: 106.067\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[766]\ttrain's rmse: 74.9162\tvalid's rmse: 106.066\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[767]\ttrain's rmse: 74.8991\tvalid's rmse: 106.063\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[768]\ttrain's rmse: 74.8689\tvalid's rmse: 106.059\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[769]\ttrain's rmse: 74.8417\tvalid's rmse: 106.057\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[770]\ttrain's rmse: 74.8239\tvalid's rmse: 106.051\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[771]\ttrain's rmse: 74.8052\tvalid's rmse: 106.051\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[772]\ttrain's rmse: 74.7831\tvalid's rmse: 106.048\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[773]\ttrain's rmse: 74.7587\tvalid's rmse: 106.041\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[774]\ttrain's rmse: 74.7374\tvalid's rmse: 106.037\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[775]\ttrain's rmse: 74.7116\tvalid's rmse: 106.032\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[776]\ttrain's rmse: 74.6878\tvalid's rmse: 106.031\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[777]\ttrain's rmse: 74.6636\tvalid's rmse: 106.026\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[778]\ttrain's rmse: 74.6429\tvalid's rmse: 106.022\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[779]\ttrain's rmse: 74.6218\tvalid's rmse: 106.025\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[780]\ttrain's rmse: 74.6032\tvalid's rmse: 106.022\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[781]\ttrain's rmse: 74.5812\tvalid's rmse: 106.019\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[782]\ttrain's rmse: 74.5517\tvalid's rmse: 106.02\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[783]\ttrain's rmse: 74.5257\tvalid's rmse: 106.016\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[784]\ttrain's rmse: 74.5022\tvalid's rmse: 106.016\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[785]\ttrain's rmse: 74.4809\tvalid's rmse: 106.008\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[786]\ttrain's rmse: 74.4601\tvalid's rmse: 106.003\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[787]\ttrain's rmse: 74.4347\tvalid's rmse: 106\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[788]\ttrain's rmse: 74.402\tvalid's rmse: 105.997\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[789]\ttrain's rmse: 74.3809\tvalid's rmse: 105.999\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[790]\ttrain's rmse: 74.3532\tvalid's rmse: 105.999\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[791]\ttrain's rmse: 74.3301\tvalid's rmse: 105.993\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[792]\ttrain's rmse: 74.3022\tvalid's rmse: 105.991\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[793]\ttrain's rmse: 74.2815\tvalid's rmse: 105.989\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[794]\ttrain's rmse: 74.2565\tvalid's rmse: 105.989\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[795]\ttrain's rmse: 74.2422\tvalid's rmse: 105.985\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[796]\ttrain's rmse: 74.2187\tvalid's rmse: 105.981\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[797]\ttrain's rmse: 74.1936\tvalid's rmse: 105.976\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[798]\ttrain's rmse: 74.1654\tvalid's rmse: 105.971\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[799]\ttrain's rmse: 74.1449\tvalid's rmse: 105.966\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[800]\ttrain's rmse: 74.1207\tvalid's rmse: 105.969\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[801]\ttrain's rmse: 74.0949\tvalid's rmse: 105.968\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[802]\ttrain's rmse: 74.0653\tvalid's rmse: 105.963\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[803]\ttrain's rmse: 74.0462\tvalid's rmse: 105.961\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[804]\ttrain's rmse: 74.0265\tvalid's rmse: 105.96\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[805]\ttrain's rmse: 73.9996\tvalid's rmse: 105.957\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[806]\ttrain's rmse: 73.9751\tvalid's rmse: 105.957\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[807]\ttrain's rmse: 73.9445\tvalid's rmse: 105.957\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[808]\ttrain's rmse: 73.9215\tvalid's rmse: 105.95\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[809]\ttrain's rmse: 73.8944\tvalid's rmse: 105.951\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[810]\ttrain's rmse: 73.8734\tvalid's rmse: 105.948\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[811]\ttrain's rmse: 73.854\tvalid's rmse: 105.946\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[812]\ttrain's rmse: 73.8356\tvalid's rmse: 105.944\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[813]\ttrain's rmse: 73.8131\tvalid's rmse: 105.943\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[814]\ttrain's rmse: 73.7939\tvalid's rmse: 105.94\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[815]\ttrain's rmse: 73.7713\tvalid's rmse: 105.937\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[816]\ttrain's rmse: 73.7426\tvalid's rmse: 105.933\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[817]\ttrain's rmse: 73.7185\tvalid's rmse: 105.934\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[818]\ttrain's rmse: 73.6991\tvalid's rmse: 105.932\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[819]\ttrain's rmse: 73.6731\tvalid's rmse: 105.932\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[820]\ttrain's rmse: 73.6479\tvalid's rmse: 105.931\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[821]\ttrain's rmse: 73.627\tvalid's rmse: 105.931\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[822]\ttrain's rmse: 73.6023\tvalid's rmse: 105.928\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[823]\ttrain's rmse: 73.5793\tvalid's rmse: 105.928\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[824]\ttrain's rmse: 73.5572\tvalid's rmse: 105.926\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[825]\ttrain's rmse: 73.5354\tvalid's rmse: 105.922\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[826]\ttrain's rmse: 73.517\tvalid's rmse: 105.92\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[827]\ttrain's rmse: 73.4902\tvalid's rmse: 105.918\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[828]\ttrain's rmse: 73.4691\tvalid's rmse: 105.916\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[829]\ttrain's rmse: 73.4534\tvalid's rmse: 105.912\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[830]\ttrain's rmse: 73.427\tvalid's rmse: 105.908\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[831]\ttrain's rmse: 73.4006\tvalid's rmse: 105.903\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[832]\ttrain's rmse: 73.3817\tvalid's rmse: 105.901\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[833]\ttrain's rmse: 73.3609\tvalid's rmse: 105.899\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[834]\ttrain's rmse: 73.3334\tvalid's rmse: 105.897\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[835]\ttrain's rmse: 73.3145\tvalid's rmse: 105.896\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[836]\ttrain's rmse: 73.2891\tvalid's rmse: 105.893\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[837]\ttrain's rmse: 73.2704\tvalid's rmse: 105.89\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[838]\ttrain's rmse: 73.2442\tvalid's rmse: 105.887\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[839]\ttrain's rmse: 73.2192\tvalid's rmse: 105.888\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[840]\ttrain's rmse: 73.1979\tvalid's rmse: 105.888\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[841]\ttrain's rmse: 73.1712\tvalid's rmse: 105.884\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[842]\ttrain's rmse: 73.1489\tvalid's rmse: 105.883\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[843]\ttrain's rmse: 73.1282\tvalid's rmse: 105.883\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[844]\ttrain's rmse: 73.107\tvalid's rmse: 105.881\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[845]\ttrain's rmse: 73.0895\tvalid's rmse: 105.879\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[846]\ttrain's rmse: 73.0668\tvalid's rmse: 105.873\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[847]\ttrain's rmse: 73.0495\tvalid's rmse: 105.871\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 26\n",
      "[848]\ttrain's rmse: 73.0318\tvalid's rmse: 105.869\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[849]\ttrain's rmse: 73.0096\tvalid's rmse: 105.867\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[850]\ttrain's rmse: 72.9882\tvalid's rmse: 105.865\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[851]\ttrain's rmse: 72.9717\tvalid's rmse: 105.863\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[852]\ttrain's rmse: 72.9497\tvalid's rmse: 105.86\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[853]\ttrain's rmse: 72.9278\tvalid's rmse: 105.856\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[854]\ttrain's rmse: 72.9088\tvalid's rmse: 105.854\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[855]\ttrain's rmse: 72.8873\tvalid's rmse: 105.853\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[856]\ttrain's rmse: 72.8688\tvalid's rmse: 105.851\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[857]\ttrain's rmse: 72.8503\tvalid's rmse: 105.846\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[858]\ttrain's rmse: 72.8256\tvalid's rmse: 105.842\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[859]\ttrain's rmse: 72.7982\tvalid's rmse: 105.838\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[860]\ttrain's rmse: 72.7741\tvalid's rmse: 105.835\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[861]\ttrain's rmse: 72.7547\tvalid's rmse: 105.834\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[862]\ttrain's rmse: 72.7341\tvalid's rmse: 105.831\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[863]\ttrain's rmse: 72.7064\tvalid's rmse: 105.828\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[864]\ttrain's rmse: 72.6885\tvalid's rmse: 105.829\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 24\n",
      "[865]\ttrain's rmse: 72.6695\tvalid's rmse: 105.825\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[866]\ttrain's rmse: 72.6506\tvalid's rmse: 105.826\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[867]\ttrain's rmse: 72.6299\tvalid's rmse: 105.822\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[868]\ttrain's rmse: 72.6101\tvalid's rmse: 105.823\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[869]\ttrain's rmse: 72.5826\tvalid's rmse: 105.822\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[870]\ttrain's rmse: 72.559\tvalid's rmse: 105.823\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[871]\ttrain's rmse: 72.5376\tvalid's rmse: 105.821\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[872]\ttrain's rmse: 72.5193\tvalid's rmse: 105.817\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[873]\ttrain's rmse: 72.5008\tvalid's rmse: 105.814\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[874]\ttrain's rmse: 72.483\tvalid's rmse: 105.813\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[875]\ttrain's rmse: 72.4646\tvalid's rmse: 105.808\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[876]\ttrain's rmse: 72.4424\tvalid's rmse: 105.808\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[877]\ttrain's rmse: 72.4155\tvalid's rmse: 105.804\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[878]\ttrain's rmse: 72.3938\tvalid's rmse: 105.805\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[879]\ttrain's rmse: 72.3758\tvalid's rmse: 105.805\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[880]\ttrain's rmse: 72.3606\tvalid's rmse: 105.802\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[881]\ttrain's rmse: 72.3432\tvalid's rmse: 105.799\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[882]\ttrain's rmse: 72.3248\tvalid's rmse: 105.796\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[883]\ttrain's rmse: 72.3055\tvalid's rmse: 105.791\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[884]\ttrain's rmse: 72.2836\tvalid's rmse: 105.786\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[885]\ttrain's rmse: 72.2659\tvalid's rmse: 105.784\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[886]\ttrain's rmse: 72.2443\tvalid's rmse: 105.784\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 28\n",
      "[887]\ttrain's rmse: 72.2215\tvalid's rmse: 105.779\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[888]\ttrain's rmse: 72.2004\tvalid's rmse: 105.777\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[889]\ttrain's rmse: 72.1824\tvalid's rmse: 105.775\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[890]\ttrain's rmse: 72.1628\tvalid's rmse: 105.773\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[891]\ttrain's rmse: 72.1447\tvalid's rmse: 105.775\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[892]\ttrain's rmse: 72.1188\tvalid's rmse: 105.77\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[893]\ttrain's rmse: 72.0994\tvalid's rmse: 105.769\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[894]\ttrain's rmse: 72.0723\tvalid's rmse: 105.764\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[895]\ttrain's rmse: 72.052\tvalid's rmse: 105.763\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[896]\ttrain's rmse: 72.0367\tvalid's rmse: 105.759\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[897]\ttrain's rmse: 72.0182\tvalid's rmse: 105.758\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[898]\ttrain's rmse: 72\tvalid's rmse: 105.759\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[899]\ttrain's rmse: 71.9714\tvalid's rmse: 105.757\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[900]\ttrain's rmse: 71.9485\tvalid's rmse: 105.757\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[901]\ttrain's rmse: 71.9255\tvalid's rmse: 105.755\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[902]\ttrain's rmse: 71.9091\tvalid's rmse: 105.752\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[903]\ttrain's rmse: 71.8886\tvalid's rmse: 105.752\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[904]\ttrain's rmse: 71.8726\tvalid's rmse: 105.752\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[905]\ttrain's rmse: 71.8552\tvalid's rmse: 105.749\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[906]\ttrain's rmse: 71.8375\tvalid's rmse: 105.743\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[907]\ttrain's rmse: 71.8193\tvalid's rmse: 105.737\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[908]\ttrain's rmse: 71.8005\tvalid's rmse: 105.736\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[909]\ttrain's rmse: 71.7758\tvalid's rmse: 105.731\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[910]\ttrain's rmse: 71.7529\tvalid's rmse: 105.735\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[911]\ttrain's rmse: 71.7305\tvalid's rmse: 105.734\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[912]\ttrain's rmse: 71.7087\tvalid's rmse: 105.733\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[913]\ttrain's rmse: 71.6858\tvalid's rmse: 105.73\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[914]\ttrain's rmse: 71.666\tvalid's rmse: 105.723\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[915]\ttrain's rmse: 71.6451\tvalid's rmse: 105.719\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[916]\ttrain's rmse: 71.6256\tvalid's rmse: 105.719\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[917]\ttrain's rmse: 71.6037\tvalid's rmse: 105.718\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[918]\ttrain's rmse: 71.5812\tvalid's rmse: 105.715\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[919]\ttrain's rmse: 71.5556\tvalid's rmse: 105.715\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[920]\ttrain's rmse: 71.5371\tvalid's rmse: 105.712\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[921]\ttrain's rmse: 71.5161\tvalid's rmse: 105.71\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[922]\ttrain's rmse: 71.4947\tvalid's rmse: 105.701\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[923]\ttrain's rmse: 71.476\tvalid's rmse: 105.699\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[924]\ttrain's rmse: 71.4565\tvalid's rmse: 105.697\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[925]\ttrain's rmse: 71.4393\tvalid's rmse: 105.697\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[926]\ttrain's rmse: 71.4127\tvalid's rmse: 105.694\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[927]\ttrain's rmse: 71.3877\tvalid's rmse: 105.693\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[928]\ttrain's rmse: 71.3655\tvalid's rmse: 105.692\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[929]\ttrain's rmse: 71.3458\tvalid's rmse: 105.691\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[930]\ttrain's rmse: 71.3278\tvalid's rmse: 105.691\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[931]\ttrain's rmse: 71.3029\tvalid's rmse: 105.691\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[932]\ttrain's rmse: 71.2828\tvalid's rmse: 105.687\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[933]\ttrain's rmse: 71.2679\tvalid's rmse: 105.684\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[934]\ttrain's rmse: 71.2462\tvalid's rmse: 105.681\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[935]\ttrain's rmse: 71.2268\tvalid's rmse: 105.678\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[936]\ttrain's rmse: 71.205\tvalid's rmse: 105.676\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[937]\ttrain's rmse: 71.1823\tvalid's rmse: 105.677\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[938]\ttrain's rmse: 71.1693\tvalid's rmse: 105.675\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[939]\ttrain's rmse: 71.1486\tvalid's rmse: 105.675\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[940]\ttrain's rmse: 71.1253\tvalid's rmse: 105.672\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[941]\ttrain's rmse: 71.1038\tvalid's rmse: 105.671\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[942]\ttrain's rmse: 71.0843\tvalid's rmse: 105.669\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[943]\ttrain's rmse: 71.0666\tvalid's rmse: 105.669\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[944]\ttrain's rmse: 71.0429\tvalid's rmse: 105.666\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[945]\ttrain's rmse: 71.0267\tvalid's rmse: 105.664\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[946]\ttrain's rmse: 71.0097\tvalid's rmse: 105.665\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[947]\ttrain's rmse: 70.9878\tvalid's rmse: 105.661\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[948]\ttrain's rmse: 70.9757\tvalid's rmse: 105.658\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[949]\ttrain's rmse: 70.9571\tvalid's rmse: 105.652\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[950]\ttrain's rmse: 70.9389\tvalid's rmse: 105.652\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[951]\ttrain's rmse: 70.9219\tvalid's rmse: 105.649\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[952]\ttrain's rmse: 70.9091\tvalid's rmse: 105.647\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[953]\ttrain's rmse: 70.8921\tvalid's rmse: 105.646\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[954]\ttrain's rmse: 70.8694\tvalid's rmse: 105.647\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[955]\ttrain's rmse: 70.853\tvalid's rmse: 105.646\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[956]\ttrain's rmse: 70.8355\tvalid's rmse: 105.646\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[957]\ttrain's rmse: 70.8125\tvalid's rmse: 105.64\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[958]\ttrain's rmse: 70.7951\tvalid's rmse: 105.637\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[959]\ttrain's rmse: 70.7714\tvalid's rmse: 105.635\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[960]\ttrain's rmse: 70.7447\tvalid's rmse: 105.634\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[961]\ttrain's rmse: 70.7243\tvalid's rmse: 105.633\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[962]\ttrain's rmse: 70.7055\tvalid's rmse: 105.634\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[963]\ttrain's rmse: 70.6877\tvalid's rmse: 105.633\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[964]\ttrain's rmse: 70.6639\tvalid's rmse: 105.633\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[965]\ttrain's rmse: 70.6452\tvalid's rmse: 105.632\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[966]\ttrain's rmse: 70.6268\tvalid's rmse: 105.632\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[967]\ttrain's rmse: 70.6008\tvalid's rmse: 105.631\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[968]\ttrain's rmse: 70.5811\tvalid's rmse: 105.628\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[969]\ttrain's rmse: 70.5589\tvalid's rmse: 105.626\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[970]\ttrain's rmse: 70.5405\tvalid's rmse: 105.627\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[971]\ttrain's rmse: 70.5211\tvalid's rmse: 105.625\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[972]\ttrain's rmse: 70.5048\tvalid's rmse: 105.624\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[973]\ttrain's rmse: 70.4875\tvalid's rmse: 105.623\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[974]\ttrain's rmse: 70.4702\tvalid's rmse: 105.619\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[975]\ttrain's rmse: 70.4564\tvalid's rmse: 105.617\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[976]\ttrain's rmse: 70.4305\tvalid's rmse: 105.614\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[977]\ttrain's rmse: 70.4183\tvalid's rmse: 105.616\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[978]\ttrain's rmse: 70.3985\tvalid's rmse: 105.618\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[979]\ttrain's rmse: 70.3735\tvalid's rmse: 105.62\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[980]\ttrain's rmse: 70.3492\tvalid's rmse: 105.622\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[981]\ttrain's rmse: 70.3319\tvalid's rmse: 105.619\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[982]\ttrain's rmse: 70.3161\tvalid's rmse: 105.616\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[983]\ttrain's rmse: 70.2958\tvalid's rmse: 105.616\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[984]\ttrain's rmse: 70.2805\tvalid's rmse: 105.617\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[985]\ttrain's rmse: 70.2657\tvalid's rmse: 105.616\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[986]\ttrain's rmse: 70.2463\tvalid's rmse: 105.615\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[987]\ttrain's rmse: 70.2173\tvalid's rmse: 105.613\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[988]\ttrain's rmse: 70.2018\tvalid's rmse: 105.613\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[989]\ttrain's rmse: 70.1827\tvalid's rmse: 105.613\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[990]\ttrain's rmse: 70.161\tvalid's rmse: 105.609\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[991]\ttrain's rmse: 70.1413\tvalid's rmse: 105.607\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[992]\ttrain's rmse: 70.1234\tvalid's rmse: 105.607\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[993]\ttrain's rmse: 70.1064\tvalid's rmse: 105.607\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[994]\ttrain's rmse: 70.0914\tvalid's rmse: 105.606\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[995]\ttrain's rmse: 70.0731\tvalid's rmse: 105.606\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[996]\ttrain's rmse: 70.0564\tvalid's rmse: 105.602\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[997]\ttrain's rmse: 70.0416\tvalid's rmse: 105.599\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[998]\ttrain's rmse: 70.0151\tvalid's rmse: 105.602\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[999]\ttrain's rmse: 69.995\tvalid's rmse: 105.601\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1000]\ttrain's rmse: 69.9801\tvalid's rmse: 105.597\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1001]\ttrain's rmse: 69.9585\tvalid's rmse: 105.597\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1002]\ttrain's rmse: 69.9456\tvalid's rmse: 105.595\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1003]\ttrain's rmse: 69.9226\tvalid's rmse: 105.592\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1004]\ttrain's rmse: 69.8972\tvalid's rmse: 105.589\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1005]\ttrain's rmse: 69.8769\tvalid's rmse: 105.586\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1006]\ttrain's rmse: 69.8561\tvalid's rmse: 105.584\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1007]\ttrain's rmse: 69.838\tvalid's rmse: 105.581\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1008]\ttrain's rmse: 69.8222\tvalid's rmse: 105.579\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1009]\ttrain's rmse: 69.805\tvalid's rmse: 105.577\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1010]\ttrain's rmse: 69.7878\tvalid's rmse: 105.576\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1011]\ttrain's rmse: 69.7717\tvalid's rmse: 105.573\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1012]\ttrain's rmse: 69.7487\tvalid's rmse: 105.575\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1013]\ttrain's rmse: 69.7265\tvalid's rmse: 105.573\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 23\n",
      "[1014]\ttrain's rmse: 69.7105\tvalid's rmse: 105.573\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1015]\ttrain's rmse: 69.6897\tvalid's rmse: 105.571\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1016]\ttrain's rmse: 69.6708\tvalid's rmse: 105.569\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1017]\ttrain's rmse: 69.6467\tvalid's rmse: 105.569\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1018]\ttrain's rmse: 69.628\tvalid's rmse: 105.568\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1019]\ttrain's rmse: 69.6116\tvalid's rmse: 105.566\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1020]\ttrain's rmse: 69.5959\tvalid's rmse: 105.565\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1021]\ttrain's rmse: 69.5832\tvalid's rmse: 105.565\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1022]\ttrain's rmse: 69.5647\tvalid's rmse: 105.566\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1023]\ttrain's rmse: 69.5417\tvalid's rmse: 105.561\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1024]\ttrain's rmse: 69.5202\tvalid's rmse: 105.558\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1025]\ttrain's rmse: 69.5003\tvalid's rmse: 105.556\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1026]\ttrain's rmse: 69.4761\tvalid's rmse: 105.555\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1027]\ttrain's rmse: 69.4597\tvalid's rmse: 105.553\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1028]\ttrain's rmse: 69.4426\tvalid's rmse: 105.554\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1029]\ttrain's rmse: 69.4238\tvalid's rmse: 105.549\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1030]\ttrain's rmse: 69.4038\tvalid's rmse: 105.548\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1031]\ttrain's rmse: 69.3883\tvalid's rmse: 105.548\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1032]\ttrain's rmse: 69.3691\tvalid's rmse: 105.549\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1033]\ttrain's rmse: 69.3523\tvalid's rmse: 105.547\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1034]\ttrain's rmse: 69.3375\tvalid's rmse: 105.548\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1035]\ttrain's rmse: 69.3178\tvalid's rmse: 105.544\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[1036]\ttrain's rmse: 69.3028\tvalid's rmse: 105.541\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1037]\ttrain's rmse: 69.2759\tvalid's rmse: 105.543\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1038]\ttrain's rmse: 69.2629\tvalid's rmse: 105.541\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1039]\ttrain's rmse: 69.2462\tvalid's rmse: 105.54\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1040]\ttrain's rmse: 69.2307\tvalid's rmse: 105.539\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1041]\ttrain's rmse: 69.2122\tvalid's rmse: 105.538\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1042]\ttrain's rmse: 69.1941\tvalid's rmse: 105.535\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1043]\ttrain's rmse: 69.1757\tvalid's rmse: 105.534\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1044]\ttrain's rmse: 69.159\tvalid's rmse: 105.534\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1045]\ttrain's rmse: 69.1444\tvalid's rmse: 105.53\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1046]\ttrain's rmse: 69.1238\tvalid's rmse: 105.528\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1047]\ttrain's rmse: 69.108\tvalid's rmse: 105.525\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 24\n",
      "[1048]\ttrain's rmse: 69.0961\tvalid's rmse: 105.521\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1049]\ttrain's rmse: 69.0791\tvalid's rmse: 105.522\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1050]\ttrain's rmse: 69.0592\tvalid's rmse: 105.523\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1051]\ttrain's rmse: 69.0343\tvalid's rmse: 105.522\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1052]\ttrain's rmse: 69.0208\tvalid's rmse: 105.52\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1053]\ttrain's rmse: 69.0041\tvalid's rmse: 105.52\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1054]\ttrain's rmse: 68.9855\tvalid's rmse: 105.519\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1055]\ttrain's rmse: 68.9738\tvalid's rmse: 105.517\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1056]\ttrain's rmse: 68.9499\tvalid's rmse: 105.515\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1057]\ttrain's rmse: 68.931\tvalid's rmse: 105.515\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1058]\ttrain's rmse: 68.915\tvalid's rmse: 105.509\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1059]\ttrain's rmse: 68.8947\tvalid's rmse: 105.507\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1060]\ttrain's rmse: 68.8707\tvalid's rmse: 105.507\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1061]\ttrain's rmse: 68.8526\tvalid's rmse: 105.503\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1062]\ttrain's rmse: 68.8347\tvalid's rmse: 105.503\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1063]\ttrain's rmse: 68.8205\tvalid's rmse: 105.498\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1064]\ttrain's rmse: 68.8045\tvalid's rmse: 105.496\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1065]\ttrain's rmse: 68.7879\tvalid's rmse: 105.496\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1066]\ttrain's rmse: 68.7693\tvalid's rmse: 105.495\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1067]\ttrain's rmse: 68.753\tvalid's rmse: 105.496\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1068]\ttrain's rmse: 68.7354\tvalid's rmse: 105.497\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1069]\ttrain's rmse: 68.7211\tvalid's rmse: 105.493\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1070]\ttrain's rmse: 68.7073\tvalid's rmse: 105.489\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1071]\ttrain's rmse: 68.6922\tvalid's rmse: 105.487\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1072]\ttrain's rmse: 68.6762\tvalid's rmse: 105.486\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1073]\ttrain's rmse: 68.6582\tvalid's rmse: 105.483\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1074]\ttrain's rmse: 68.6416\tvalid's rmse: 105.483\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1075]\ttrain's rmse: 68.625\tvalid's rmse: 105.483\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1076]\ttrain's rmse: 68.6144\tvalid's rmse: 105.48\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1077]\ttrain's rmse: 68.5912\tvalid's rmse: 105.479\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1078]\ttrain's rmse: 68.5747\tvalid's rmse: 105.479\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1079]\ttrain's rmse: 68.5532\tvalid's rmse: 105.475\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1080]\ttrain's rmse: 68.5383\tvalid's rmse: 105.471\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1081]\ttrain's rmse: 68.5238\tvalid's rmse: 105.47\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1082]\ttrain's rmse: 68.5042\tvalid's rmse: 105.469\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1083]\ttrain's rmse: 68.4896\tvalid's rmse: 105.47\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1084]\ttrain's rmse: 68.4733\tvalid's rmse: 105.47\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1085]\ttrain's rmse: 68.4527\tvalid's rmse: 105.469\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1086]\ttrain's rmse: 68.4334\tvalid's rmse: 105.469\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1087]\ttrain's rmse: 68.4194\tvalid's rmse: 105.468\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1088]\ttrain's rmse: 68.4012\tvalid's rmse: 105.468\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1089]\ttrain's rmse: 68.3858\tvalid's rmse: 105.467\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1090]\ttrain's rmse: 68.3678\tvalid's rmse: 105.466\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1091]\ttrain's rmse: 68.3481\tvalid's rmse: 105.467\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1092]\ttrain's rmse: 68.3335\tvalid's rmse: 105.463\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1093]\ttrain's rmse: 68.3162\tvalid's rmse: 105.461\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1094]\ttrain's rmse: 68.2929\tvalid's rmse: 105.457\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1095]\ttrain's rmse: 68.2775\tvalid's rmse: 105.453\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1096]\ttrain's rmse: 68.2622\tvalid's rmse: 105.452\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1097]\ttrain's rmse: 68.2488\tvalid's rmse: 105.449\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1098]\ttrain's rmse: 68.23\tvalid's rmse: 105.448\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1099]\ttrain's rmse: 68.2125\tvalid's rmse: 105.448\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1100]\ttrain's rmse: 68.1985\tvalid's rmse: 105.447\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1101]\ttrain's rmse: 68.184\tvalid's rmse: 105.444\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1102]\ttrain's rmse: 68.1688\tvalid's rmse: 105.444\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1103]\ttrain's rmse: 68.15\tvalid's rmse: 105.441\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1104]\ttrain's rmse: 68.133\tvalid's rmse: 105.443\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1105]\ttrain's rmse: 68.1177\tvalid's rmse: 105.442\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1106]\ttrain's rmse: 68.1031\tvalid's rmse: 105.441\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1107]\ttrain's rmse: 68.0891\tvalid's rmse: 105.44\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1108]\ttrain's rmse: 68.0727\tvalid's rmse: 105.441\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1109]\ttrain's rmse: 68.0444\tvalid's rmse: 105.436\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1110]\ttrain's rmse: 68.0238\tvalid's rmse: 105.437\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1111]\ttrain's rmse: 68.0084\tvalid's rmse: 105.437\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1112]\ttrain's rmse: 67.993\tvalid's rmse: 105.436\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1113]\ttrain's rmse: 67.9764\tvalid's rmse: 105.436\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 25\n",
      "[1114]\ttrain's rmse: 67.9551\tvalid's rmse: 105.434\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1115]\ttrain's rmse: 67.9306\tvalid's rmse: 105.427\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1116]\ttrain's rmse: 67.9095\tvalid's rmse: 105.426\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1117]\ttrain's rmse: 67.8943\tvalid's rmse: 105.426\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1118]\ttrain's rmse: 67.879\tvalid's rmse: 105.427\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[1119]\ttrain's rmse: 67.8638\tvalid's rmse: 105.429\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1120]\ttrain's rmse: 67.8459\tvalid's rmse: 105.426\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1121]\ttrain's rmse: 67.8282\tvalid's rmse: 105.426\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1122]\ttrain's rmse: 67.8163\tvalid's rmse: 105.425\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1123]\ttrain's rmse: 67.7956\tvalid's rmse: 105.419\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1124]\ttrain's rmse: 67.7782\tvalid's rmse: 105.42\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1125]\ttrain's rmse: 67.7536\tvalid's rmse: 105.418\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[1126]\ttrain's rmse: 67.7309\tvalid's rmse: 105.414\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1127]\ttrain's rmse: 67.719\tvalid's rmse: 105.412\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1128]\ttrain's rmse: 67.7009\tvalid's rmse: 105.411\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1129]\ttrain's rmse: 67.6799\tvalid's rmse: 105.411\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1130]\ttrain's rmse: 67.6617\tvalid's rmse: 105.408\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1131]\ttrain's rmse: 67.6479\tvalid's rmse: 105.407\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1132]\ttrain's rmse: 67.6273\tvalid's rmse: 105.405\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1133]\ttrain's rmse: 67.6166\tvalid's rmse: 105.405\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1134]\ttrain's rmse: 67.596\tvalid's rmse: 105.401\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1135]\ttrain's rmse: 67.5803\tvalid's rmse: 105.4\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1136]\ttrain's rmse: 67.5662\tvalid's rmse: 105.4\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1137]\ttrain's rmse: 67.5517\tvalid's rmse: 105.396\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[1138]\ttrain's rmse: 67.5362\tvalid's rmse: 105.395\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1139]\ttrain's rmse: 67.5209\tvalid's rmse: 105.393\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1140]\ttrain's rmse: 67.5037\tvalid's rmse: 105.394\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1141]\ttrain's rmse: 67.4883\tvalid's rmse: 105.394\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1142]\ttrain's rmse: 67.4654\tvalid's rmse: 105.39\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1143]\ttrain's rmse: 67.4508\tvalid's rmse: 105.389\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1144]\ttrain's rmse: 67.4361\tvalid's rmse: 105.389\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1145]\ttrain's rmse: 67.416\tvalid's rmse: 105.387\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1146]\ttrain's rmse: 67.4009\tvalid's rmse: 105.383\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1147]\ttrain's rmse: 67.3863\tvalid's rmse: 105.38\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1148]\ttrain's rmse: 67.3712\tvalid's rmse: 105.38\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1149]\ttrain's rmse: 67.3526\tvalid's rmse: 105.379\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1150]\ttrain's rmse: 67.329\tvalid's rmse: 105.373\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1151]\ttrain's rmse: 67.3151\tvalid's rmse: 105.37\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1152]\ttrain's rmse: 67.2986\tvalid's rmse: 105.367\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1153]\ttrain's rmse: 67.281\tvalid's rmse: 105.364\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1154]\ttrain's rmse: 67.264\tvalid's rmse: 105.363\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1155]\ttrain's rmse: 67.2416\tvalid's rmse: 105.354\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[1156]\ttrain's rmse: 67.2284\tvalid's rmse: 105.355\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1157]\ttrain's rmse: 67.2157\tvalid's rmse: 105.353\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1158]\ttrain's rmse: 67.1981\tvalid's rmse: 105.352\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1159]\ttrain's rmse: 67.1804\tvalid's rmse: 105.351\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1160]\ttrain's rmse: 67.1684\tvalid's rmse: 105.351\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1161]\ttrain's rmse: 67.1494\tvalid's rmse: 105.348\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1162]\ttrain's rmse: 67.1288\tvalid's rmse: 105.347\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1163]\ttrain's rmse: 67.1163\tvalid's rmse: 105.346\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1164]\ttrain's rmse: 67.1012\tvalid's rmse: 105.342\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1165]\ttrain's rmse: 67.0795\tvalid's rmse: 105.342\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1166]\ttrain's rmse: 67.0586\tvalid's rmse: 105.338\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1167]\ttrain's rmse: 67.0417\tvalid's rmse: 105.339\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1168]\ttrain's rmse: 67.024\tvalid's rmse: 105.338\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1169]\ttrain's rmse: 67.0131\tvalid's rmse: 105.335\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1170]\ttrain's rmse: 66.9945\tvalid's rmse: 105.336\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1171]\ttrain's rmse: 66.9814\tvalid's rmse: 105.334\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1172]\ttrain's rmse: 66.9629\tvalid's rmse: 105.333\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1173]\ttrain's rmse: 66.9492\tvalid's rmse: 105.331\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1174]\ttrain's rmse: 66.9252\tvalid's rmse: 105.333\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1175]\ttrain's rmse: 66.9105\tvalid's rmse: 105.334\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1176]\ttrain's rmse: 66.8927\tvalid's rmse: 105.334\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1177]\ttrain's rmse: 66.8785\tvalid's rmse: 105.331\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1178]\ttrain's rmse: 66.8627\tvalid's rmse: 105.331\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1179]\ttrain's rmse: 66.8446\tvalid's rmse: 105.327\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1180]\ttrain's rmse: 66.8246\tvalid's rmse: 105.324\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1181]\ttrain's rmse: 66.8086\tvalid's rmse: 105.323\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1182]\ttrain's rmse: 66.7931\tvalid's rmse: 105.322\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1183]\ttrain's rmse: 66.7752\tvalid's rmse: 105.32\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1184]\ttrain's rmse: 66.7577\tvalid's rmse: 105.319\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1185]\ttrain's rmse: 66.7393\tvalid's rmse: 105.317\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1186]\ttrain's rmse: 66.7247\tvalid's rmse: 105.315\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 23\n",
      "[1187]\ttrain's rmse: 66.7069\tvalid's rmse: 105.315\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1188]\ttrain's rmse: 66.6975\tvalid's rmse: 105.314\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1189]\ttrain's rmse: 66.6815\tvalid's rmse: 105.314\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1190]\ttrain's rmse: 66.6646\tvalid's rmse: 105.311\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1191]\ttrain's rmse: 66.645\tvalid's rmse: 105.31\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1192]\ttrain's rmse: 66.6269\tvalid's rmse: 105.309\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1193]\ttrain's rmse: 66.6111\tvalid's rmse: 105.306\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1194]\ttrain's rmse: 66.5942\tvalid's rmse: 105.304\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1195]\ttrain's rmse: 66.5749\tvalid's rmse: 105.301\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1196]\ttrain's rmse: 66.5564\tvalid's rmse: 105.3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1197]\ttrain's rmse: 66.5376\tvalid's rmse: 105.297\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 24\n",
      "[1198]\ttrain's rmse: 66.5181\tvalid's rmse: 105.294\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1199]\ttrain's rmse: 66.5039\tvalid's rmse: 105.296\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1200]\ttrain's rmse: 66.4893\tvalid's rmse: 105.296\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1201]\ttrain's rmse: 66.4714\tvalid's rmse: 105.297\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1202]\ttrain's rmse: 66.4554\tvalid's rmse: 105.296\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1203]\ttrain's rmse: 66.4389\tvalid's rmse: 105.297\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1204]\ttrain's rmse: 66.4258\tvalid's rmse: 105.297\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1205]\ttrain's rmse: 66.4129\tvalid's rmse: 105.295\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1206]\ttrain's rmse: 66.3971\tvalid's rmse: 105.292\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1207]\ttrain's rmse: 66.3747\tvalid's rmse: 105.287\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1208]\ttrain's rmse: 66.3598\tvalid's rmse: 105.281\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1209]\ttrain's rmse: 66.3456\tvalid's rmse: 105.281\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1210]\ttrain's rmse: 66.3235\tvalid's rmse: 105.282\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1211]\ttrain's rmse: 66.3113\tvalid's rmse: 105.279\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1212]\ttrain's rmse: 66.2933\tvalid's rmse: 105.28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1213]\ttrain's rmse: 66.2824\tvalid's rmse: 105.277\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1214]\ttrain's rmse: 66.2712\tvalid's rmse: 105.276\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1215]\ttrain's rmse: 66.254\tvalid's rmse: 105.275\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1216]\ttrain's rmse: 66.2364\tvalid's rmse: 105.278\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1217]\ttrain's rmse: 66.2267\tvalid's rmse: 105.277\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1218]\ttrain's rmse: 66.2115\tvalid's rmse: 105.278\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1219]\ttrain's rmse: 66.1947\tvalid's rmse: 105.275\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1220]\ttrain's rmse: 66.1782\tvalid's rmse: 105.274\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1221]\ttrain's rmse: 66.1583\tvalid's rmse: 105.274\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1222]\ttrain's rmse: 66.142\tvalid's rmse: 105.268\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1223]\ttrain's rmse: 66.1279\tvalid's rmse: 105.264\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1224]\ttrain's rmse: 66.1158\tvalid's rmse: 105.266\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1225]\ttrain's rmse: 66.1022\tvalid's rmse: 105.265\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1226]\ttrain's rmse: 66.0878\tvalid's rmse: 105.263\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1227]\ttrain's rmse: 66.0733\tvalid's rmse: 105.262\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1228]\ttrain's rmse: 66.0613\tvalid's rmse: 105.263\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 23\n",
      "[1229]\ttrain's rmse: 66.0409\tvalid's rmse: 105.258\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1230]\ttrain's rmse: 66.0221\tvalid's rmse: 105.254\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1231]\ttrain's rmse: 66.0065\tvalid's rmse: 105.253\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1232]\ttrain's rmse: 65.991\tvalid's rmse: 105.253\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1233]\ttrain's rmse: 65.9745\tvalid's rmse: 105.252\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1234]\ttrain's rmse: 65.9612\tvalid's rmse: 105.248\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1235]\ttrain's rmse: 65.9509\tvalid's rmse: 105.25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1236]\ttrain's rmse: 65.9353\tvalid's rmse: 105.249\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1237]\ttrain's rmse: 65.9107\tvalid's rmse: 105.246\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1238]\ttrain's rmse: 65.8981\tvalid's rmse: 105.246\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1239]\ttrain's rmse: 65.8801\tvalid's rmse: 105.244\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1240]\ttrain's rmse: 65.8674\tvalid's rmse: 105.244\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1241]\ttrain's rmse: 65.8534\tvalid's rmse: 105.241\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1242]\ttrain's rmse: 65.8356\tvalid's rmse: 105.24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1243]\ttrain's rmse: 65.8226\tvalid's rmse: 105.239\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1244]\ttrain's rmse: 65.8049\tvalid's rmse: 105.238\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1245]\ttrain's rmse: 65.79\tvalid's rmse: 105.236\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1246]\ttrain's rmse: 65.7807\tvalid's rmse: 105.234\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 23\n",
      "[1247]\ttrain's rmse: 65.7621\tvalid's rmse: 105.233\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1248]\ttrain's rmse: 65.7444\tvalid's rmse: 105.233\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1249]\ttrain's rmse: 65.7344\tvalid's rmse: 105.233\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1250]\ttrain's rmse: 65.7172\tvalid's rmse: 105.229\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1251]\ttrain's rmse: 65.6956\tvalid's rmse: 105.229\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1252]\ttrain's rmse: 65.6722\tvalid's rmse: 105.226\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1253]\ttrain's rmse: 65.6563\tvalid's rmse: 105.225\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1254]\ttrain's rmse: 65.6419\tvalid's rmse: 105.221\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1255]\ttrain's rmse: 65.6288\tvalid's rmse: 105.221\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1256]\ttrain's rmse: 65.6093\tvalid's rmse: 105.221\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1257]\ttrain's rmse: 65.5903\tvalid's rmse: 105.221\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1258]\ttrain's rmse: 65.5705\tvalid's rmse: 105.219\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1259]\ttrain's rmse: 65.5521\tvalid's rmse: 105.217\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1260]\ttrain's rmse: 65.5322\tvalid's rmse: 105.215\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1261]\ttrain's rmse: 65.5137\tvalid's rmse: 105.214\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1262]\ttrain's rmse: 65.5001\tvalid's rmse: 105.214\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1263]\ttrain's rmse: 65.4819\tvalid's rmse: 105.215\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1264]\ttrain's rmse: 65.4677\tvalid's rmse: 105.214\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1265]\ttrain's rmse: 65.4533\tvalid's rmse: 105.213\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1266]\ttrain's rmse: 65.4372\tvalid's rmse: 105.211\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1267]\ttrain's rmse: 65.4207\tvalid's rmse: 105.21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1268]\ttrain's rmse: 65.4035\tvalid's rmse: 105.208\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1269]\ttrain's rmse: 65.3904\tvalid's rmse: 105.203\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1270]\ttrain's rmse: 65.3808\tvalid's rmse: 105.204\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1271]\ttrain's rmse: 65.3598\tvalid's rmse: 105.202\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1272]\ttrain's rmse: 65.3465\tvalid's rmse: 105.202\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[1273]\ttrain's rmse: 65.3318\tvalid's rmse: 105.199\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1274]\ttrain's rmse: 65.3186\tvalid's rmse: 105.197\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1275]\ttrain's rmse: 65.3026\tvalid's rmse: 105.194\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1276]\ttrain's rmse: 65.287\tvalid's rmse: 105.195\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1277]\ttrain's rmse: 65.2737\tvalid's rmse: 105.196\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1278]\ttrain's rmse: 65.2616\tvalid's rmse: 105.195\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1279]\ttrain's rmse: 65.2469\tvalid's rmse: 105.192\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1280]\ttrain's rmse: 65.2366\tvalid's rmse: 105.19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1281]\ttrain's rmse: 65.2215\tvalid's rmse: 105.19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1282]\ttrain's rmse: 65.2073\tvalid's rmse: 105.189\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1283]\ttrain's rmse: 65.195\tvalid's rmse: 105.188\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1284]\ttrain's rmse: 65.1802\tvalid's rmse: 105.188\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1285]\ttrain's rmse: 65.1617\tvalid's rmse: 105.186\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1286]\ttrain's rmse: 65.1462\tvalid's rmse: 105.184\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1287]\ttrain's rmse: 65.1339\tvalid's rmse: 105.186\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1288]\ttrain's rmse: 65.1222\tvalid's rmse: 105.182\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1289]\ttrain's rmse: 65.1089\tvalid's rmse: 105.18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1290]\ttrain's rmse: 65.0938\tvalid's rmse: 105.179\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1291]\ttrain's rmse: 65.0813\tvalid's rmse: 105.179\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1292]\ttrain's rmse: 65.0635\tvalid's rmse: 105.177\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1293]\ttrain's rmse: 65.0456\tvalid's rmse: 105.174\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1294]\ttrain's rmse: 65.0306\tvalid's rmse: 105.171\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1295]\ttrain's rmse: 65.0197\tvalid's rmse: 105.168\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1296]\ttrain's rmse: 65.0008\tvalid's rmse: 105.165\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1297]\ttrain's rmse: 64.9867\tvalid's rmse: 105.163\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1298]\ttrain's rmse: 64.9705\tvalid's rmse: 105.163\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1299]\ttrain's rmse: 64.9574\tvalid's rmse: 105.162\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1300]\ttrain's rmse: 64.9447\tvalid's rmse: 105.162\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1301]\ttrain's rmse: 64.932\tvalid's rmse: 105.161\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1302]\ttrain's rmse: 64.9144\tvalid's rmse: 105.157\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1303]\ttrain's rmse: 64.9013\tvalid's rmse: 105.157\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1304]\ttrain's rmse: 64.8866\tvalid's rmse: 105.161\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1305]\ttrain's rmse: 64.8733\tvalid's rmse: 105.159\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1306]\ttrain's rmse: 64.8595\tvalid's rmse: 105.158\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1307]\ttrain's rmse: 64.8487\tvalid's rmse: 105.156\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1308]\ttrain's rmse: 64.8299\tvalid's rmse: 105.155\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1309]\ttrain's rmse: 64.8176\tvalid's rmse: 105.152\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1310]\ttrain's rmse: 64.803\tvalid's rmse: 105.15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1311]\ttrain's rmse: 64.7922\tvalid's rmse: 105.15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1312]\ttrain's rmse: 64.7774\tvalid's rmse: 105.15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1313]\ttrain's rmse: 64.764\tvalid's rmse: 105.149\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1314]\ttrain's rmse: 64.7488\tvalid's rmse: 105.145\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1315]\ttrain's rmse: 64.7359\tvalid's rmse: 105.142\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1316]\ttrain's rmse: 64.7183\tvalid's rmse: 105.142\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1317]\ttrain's rmse: 64.7066\tvalid's rmse: 105.142\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 25\n",
      "[1318]\ttrain's rmse: 64.6923\tvalid's rmse: 105.141\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1319]\ttrain's rmse: 64.682\tvalid's rmse: 105.141\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1320]\ttrain's rmse: 64.6662\tvalid's rmse: 105.138\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1321]\ttrain's rmse: 64.6586\tvalid's rmse: 105.138\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1322]\ttrain's rmse: 64.6457\tvalid's rmse: 105.136\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1323]\ttrain's rmse: 64.6308\tvalid's rmse: 105.135\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1324]\ttrain's rmse: 64.6181\tvalid's rmse: 105.135\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1325]\ttrain's rmse: 64.6018\tvalid's rmse: 105.134\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1326]\ttrain's rmse: 64.5886\tvalid's rmse: 105.132\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1327]\ttrain's rmse: 64.5758\tvalid's rmse: 105.129\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1328]\ttrain's rmse: 64.5598\tvalid's rmse: 105.126\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1329]\ttrain's rmse: 64.5433\tvalid's rmse: 105.127\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1330]\ttrain's rmse: 64.5316\tvalid's rmse: 105.127\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1331]\ttrain's rmse: 64.5196\tvalid's rmse: 105.125\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1332]\ttrain's rmse: 64.5002\tvalid's rmse: 105.125\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1333]\ttrain's rmse: 64.4866\tvalid's rmse: 105.124\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1334]\ttrain's rmse: 64.4792\tvalid's rmse: 105.125\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1335]\ttrain's rmse: 64.4633\tvalid's rmse: 105.124\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1336]\ttrain's rmse: 64.4506\tvalid's rmse: 105.123\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1337]\ttrain's rmse: 64.4349\tvalid's rmse: 105.12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1338]\ttrain's rmse: 64.4218\tvalid's rmse: 105.118\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1339]\ttrain's rmse: 64.401\tvalid's rmse: 105.116\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1340]\ttrain's rmse: 64.3875\tvalid's rmse: 105.116\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1341]\ttrain's rmse: 64.3716\tvalid's rmse: 105.115\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1342]\ttrain's rmse: 64.361\tvalid's rmse: 105.114\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1343]\ttrain's rmse: 64.3465\tvalid's rmse: 105.114\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1344]\ttrain's rmse: 64.3292\tvalid's rmse: 105.113\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1345]\ttrain's rmse: 64.3185\tvalid's rmse: 105.112\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1346]\ttrain's rmse: 64.3065\tvalid's rmse: 105.11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1347]\ttrain's rmse: 64.2941\tvalid's rmse: 105.11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1348]\ttrain's rmse: 64.2809\tvalid's rmse: 105.109\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1349]\ttrain's rmse: 64.2637\tvalid's rmse: 105.11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1350]\ttrain's rmse: 64.2456\tvalid's rmse: 105.104\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1351]\ttrain's rmse: 64.2321\tvalid's rmse: 105.104\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1352]\ttrain's rmse: 64.2233\tvalid's rmse: 105.105\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1353]\ttrain's rmse: 64.2134\tvalid's rmse: 105.104\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1354]\ttrain's rmse: 64.1957\tvalid's rmse: 105.103\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1355]\ttrain's rmse: 64.1823\tvalid's rmse: 105.102\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1356]\ttrain's rmse: 64.1726\tvalid's rmse: 105.1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1357]\ttrain's rmse: 64.1607\tvalid's rmse: 105.099\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1358]\ttrain's rmse: 64.1513\tvalid's rmse: 105.099\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1359]\ttrain's rmse: 64.1365\tvalid's rmse: 105.099\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1360]\ttrain's rmse: 64.1184\tvalid's rmse: 105.097\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1361]\ttrain's rmse: 64.1061\tvalid's rmse: 105.098\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1362]\ttrain's rmse: 64.0946\tvalid's rmse: 105.096\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1363]\ttrain's rmse: 64.0817\tvalid's rmse: 105.094\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1364]\ttrain's rmse: 64.063\tvalid's rmse: 105.092\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1365]\ttrain's rmse: 64.0518\tvalid's rmse: 105.092\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1366]\ttrain's rmse: 64.036\tvalid's rmse: 105.09\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1367]\ttrain's rmse: 64.0273\tvalid's rmse: 105.09\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1368]\ttrain's rmse: 64.0138\tvalid's rmse: 105.089\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1369]\ttrain's rmse: 64.0033\tvalid's rmse: 105.09\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1370]\ttrain's rmse: 63.9869\tvalid's rmse: 105.089\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1371]\ttrain's rmse: 63.9738\tvalid's rmse: 105.09\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1372]\ttrain's rmse: 63.959\tvalid's rmse: 105.087\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1373]\ttrain's rmse: 63.9458\tvalid's rmse: 105.084\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1374]\ttrain's rmse: 63.9344\tvalid's rmse: 105.083\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1375]\ttrain's rmse: 63.9239\tvalid's rmse: 105.084\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1376]\ttrain's rmse: 63.9139\tvalid's rmse: 105.083\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1377]\ttrain's rmse: 63.8957\tvalid's rmse: 105.082\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1378]\ttrain's rmse: 63.8792\tvalid's rmse: 105.081\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1379]\ttrain's rmse: 63.8608\tvalid's rmse: 105.078\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1380]\ttrain's rmse: 63.8455\tvalid's rmse: 105.076\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1381]\ttrain's rmse: 63.8299\tvalid's rmse: 105.078\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1382]\ttrain's rmse: 63.8152\tvalid's rmse: 105.077\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1383]\ttrain's rmse: 63.8051\tvalid's rmse: 105.075\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1384]\ttrain's rmse: 63.7945\tvalid's rmse: 105.073\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1385]\ttrain's rmse: 63.7851\tvalid's rmse: 105.072\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1386]\ttrain's rmse: 63.7775\tvalid's rmse: 105.072\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1387]\ttrain's rmse: 63.7671\tvalid's rmse: 105.074\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1388]\ttrain's rmse: 63.7552\tvalid's rmse: 105.074\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1389]\ttrain's rmse: 63.7405\tvalid's rmse: 105.073\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1390]\ttrain's rmse: 63.7269\tvalid's rmse: 105.073\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1391]\ttrain's rmse: 63.7092\tvalid's rmse: 105.071\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1392]\ttrain's rmse: 63.6966\tvalid's rmse: 105.07\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1393]\ttrain's rmse: 63.6843\tvalid's rmse: 105.069\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1394]\ttrain's rmse: 63.6645\tvalid's rmse: 105.068\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1395]\ttrain's rmse: 63.655\tvalid's rmse: 105.069\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1396]\ttrain's rmse: 63.6384\tvalid's rmse: 105.068\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1397]\ttrain's rmse: 63.6295\tvalid's rmse: 105.067\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1398]\ttrain's rmse: 63.6115\tvalid's rmse: 105.065\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1399]\ttrain's rmse: 63.5998\tvalid's rmse: 105.065\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1400]\ttrain's rmse: 63.5885\tvalid's rmse: 105.065\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1401]\ttrain's rmse: 63.5762\tvalid's rmse: 105.064\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1402]\ttrain's rmse: 63.5625\tvalid's rmse: 105.062\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1403]\ttrain's rmse: 63.552\tvalid's rmse: 105.063\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1404]\ttrain's rmse: 63.5397\tvalid's rmse: 105.062\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1405]\ttrain's rmse: 63.5297\tvalid's rmse: 105.062\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 23\n",
      "[1406]\ttrain's rmse: 63.5183\tvalid's rmse: 105.061\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1407]\ttrain's rmse: 63.5032\tvalid's rmse: 105.06\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1408]\ttrain's rmse: 63.4947\tvalid's rmse: 105.06\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1409]\ttrain's rmse: 63.4846\tvalid's rmse: 105.058\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1410]\ttrain's rmse: 63.4712\tvalid's rmse: 105.057\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1411]\ttrain's rmse: 63.4577\tvalid's rmse: 105.056\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1412]\ttrain's rmse: 63.4462\tvalid's rmse: 105.054\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1413]\ttrain's rmse: 63.4369\tvalid's rmse: 105.052\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1414]\ttrain's rmse: 63.4301\tvalid's rmse: 105.051\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1415]\ttrain's rmse: 63.4146\tvalid's rmse: 105.048\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1416]\ttrain's rmse: 63.4045\tvalid's rmse: 105.046\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1417]\ttrain's rmse: 63.3923\tvalid's rmse: 105.047\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1418]\ttrain's rmse: 63.3794\tvalid's rmse: 105.046\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[1419]\ttrain's rmse: 63.3658\tvalid's rmse: 105.044\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1420]\ttrain's rmse: 63.3544\tvalid's rmse: 105.046\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1421]\ttrain's rmse: 63.3447\tvalid's rmse: 105.045\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1422]\ttrain's rmse: 63.3236\tvalid's rmse: 105.045\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1423]\ttrain's rmse: 63.3131\tvalid's rmse: 105.044\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1424]\ttrain's rmse: 63.3018\tvalid's rmse: 105.042\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1425]\ttrain's rmse: 63.2895\tvalid's rmse: 105.041\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1426]\ttrain's rmse: 63.2772\tvalid's rmse: 105.04\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1427]\ttrain's rmse: 63.267\tvalid's rmse: 105.04\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1428]\ttrain's rmse: 63.2531\tvalid's rmse: 105.04\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1429]\ttrain's rmse: 63.2364\tvalid's rmse: 105.038\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1430]\ttrain's rmse: 63.2251\tvalid's rmse: 105.037\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1431]\ttrain's rmse: 63.211\tvalid's rmse: 105.037\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1432]\ttrain's rmse: 63.2009\tvalid's rmse: 105.035\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1433]\ttrain's rmse: 63.182\tvalid's rmse: 105.033\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1434]\ttrain's rmse: 63.1702\tvalid's rmse: 105.032\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1435]\ttrain's rmse: 63.1616\tvalid's rmse: 105.032\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1436]\ttrain's rmse: 63.1462\tvalid's rmse: 105.032\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1437]\ttrain's rmse: 63.1337\tvalid's rmse: 105.03\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1438]\ttrain's rmse: 63.1205\tvalid's rmse: 105.03\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1439]\ttrain's rmse: 63.1082\tvalid's rmse: 105.03\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1440]\ttrain's rmse: 63.0963\tvalid's rmse: 105.027\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1441]\ttrain's rmse: 63.0836\tvalid's rmse: 105.026\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1442]\ttrain's rmse: 63.0743\tvalid's rmse: 105.024\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1443]\ttrain's rmse: 63.0622\tvalid's rmse: 105.022\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 25\n",
      "[1444]\ttrain's rmse: 63.0492\tvalid's rmse: 105.022\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1445]\ttrain's rmse: 63.035\tvalid's rmse: 105.023\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1446]\ttrain's rmse: 63.0185\tvalid's rmse: 105.024\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1447]\ttrain's rmse: 63.0027\tvalid's rmse: 105.025\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1448]\ttrain's rmse: 62.985\tvalid's rmse: 105.024\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1449]\ttrain's rmse: 62.9719\tvalid's rmse: 105.021\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1450]\ttrain's rmse: 62.9598\tvalid's rmse: 105.019\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[1451]\ttrain's rmse: 62.9532\tvalid's rmse: 105.018\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1452]\ttrain's rmse: 62.9421\tvalid's rmse: 105.016\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1453]\ttrain's rmse: 62.9333\tvalid's rmse: 105.015\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1454]\ttrain's rmse: 62.9166\tvalid's rmse: 105.011\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1455]\ttrain's rmse: 62.9025\tvalid's rmse: 105.009\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1456]\ttrain's rmse: 62.8918\tvalid's rmse: 105.008\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1457]\ttrain's rmse: 62.884\tvalid's rmse: 105.007\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1458]\ttrain's rmse: 62.8682\tvalid's rmse: 105.004\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1459]\ttrain's rmse: 62.855\tvalid's rmse: 105.003\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1460]\ttrain's rmse: 62.8447\tvalid's rmse: 105\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1461]\ttrain's rmse: 62.8344\tvalid's rmse: 105\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1462]\ttrain's rmse: 62.8215\tvalid's rmse: 105\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1463]\ttrain's rmse: 62.8076\tvalid's rmse: 104.997\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1464]\ttrain's rmse: 62.7955\tvalid's rmse: 104.996\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1465]\ttrain's rmse: 62.7839\tvalid's rmse: 104.996\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1466]\ttrain's rmse: 62.7707\tvalid's rmse: 104.995\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1467]\ttrain's rmse: 62.7569\tvalid's rmse: 104.994\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1468]\ttrain's rmse: 62.7473\tvalid's rmse: 104.992\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1469]\ttrain's rmse: 62.7317\tvalid's rmse: 104.99\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1470]\ttrain's rmse: 62.721\tvalid's rmse: 104.99\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1471]\ttrain's rmse: 62.7098\tvalid's rmse: 104.99\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1472]\ttrain's rmse: 62.7016\tvalid's rmse: 104.989\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1473]\ttrain's rmse: 62.6896\tvalid's rmse: 104.989\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1474]\ttrain's rmse: 62.6771\tvalid's rmse: 104.989\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1475]\ttrain's rmse: 62.6633\tvalid's rmse: 104.989\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1476]\ttrain's rmse: 62.6534\tvalid's rmse: 104.988\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1477]\ttrain's rmse: 62.6347\tvalid's rmse: 104.988\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1478]\ttrain's rmse: 62.6215\tvalid's rmse: 104.987\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1479]\ttrain's rmse: 62.6068\tvalid's rmse: 104.988\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1480]\ttrain's rmse: 62.5959\tvalid's rmse: 104.987\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1481]\ttrain's rmse: 62.5836\tvalid's rmse: 104.985\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1482]\ttrain's rmse: 62.5704\tvalid's rmse: 104.985\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1483]\ttrain's rmse: 62.5578\tvalid's rmse: 104.985\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1484]\ttrain's rmse: 62.5394\tvalid's rmse: 104.983\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1485]\ttrain's rmse: 62.53\tvalid's rmse: 104.982\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1486]\ttrain's rmse: 62.5204\tvalid's rmse: 104.984\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1487]\ttrain's rmse: 62.5068\tvalid's rmse: 104.981\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1488]\ttrain's rmse: 62.4946\tvalid's rmse: 104.978\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1489]\ttrain's rmse: 62.4785\tvalid's rmse: 104.977\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1490]\ttrain's rmse: 62.4672\tvalid's rmse: 104.976\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1491]\ttrain's rmse: 62.4559\tvalid's rmse: 104.972\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1492]\ttrain's rmse: 62.4409\tvalid's rmse: 104.973\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1493]\ttrain's rmse: 62.4246\tvalid's rmse: 104.973\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1494]\ttrain's rmse: 62.4137\tvalid's rmse: 104.971\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1495]\ttrain's rmse: 62.3972\tvalid's rmse: 104.971\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1496]\ttrain's rmse: 62.3892\tvalid's rmse: 104.969\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1497]\ttrain's rmse: 62.3735\tvalid's rmse: 104.968\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1498]\ttrain's rmse: 62.3566\tvalid's rmse: 104.966\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1499]\ttrain's rmse: 62.3422\tvalid's rmse: 104.967\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1500]\ttrain's rmse: 62.3333\tvalid's rmse: 104.966\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1501]\ttrain's rmse: 62.3183\tvalid's rmse: 104.967\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1502]\ttrain's rmse: 62.3052\tvalid's rmse: 104.968\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1503]\ttrain's rmse: 62.2871\tvalid's rmse: 104.966\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1504]\ttrain's rmse: 62.2755\tvalid's rmse: 104.965\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1505]\ttrain's rmse: 62.2632\tvalid's rmse: 104.963\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1506]\ttrain's rmse: 62.2497\tvalid's rmse: 104.961\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1507]\ttrain's rmse: 62.2361\tvalid's rmse: 104.962\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1508]\ttrain's rmse: 62.2236\tvalid's rmse: 104.964\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1509]\ttrain's rmse: 62.213\tvalid's rmse: 104.966\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1510]\ttrain's rmse: 62.2045\tvalid's rmse: 104.965\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1511]\ttrain's rmse: 62.1901\tvalid's rmse: 104.965\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[1512]\ttrain's rmse: 62.1756\tvalid's rmse: 104.962\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1513]\ttrain's rmse: 62.1649\tvalid's rmse: 104.961\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1514]\ttrain's rmse: 62.1534\tvalid's rmse: 104.959\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1515]\ttrain's rmse: 62.1436\tvalid's rmse: 104.958\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1516]\ttrain's rmse: 62.13\tvalid's rmse: 104.96\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1517]\ttrain's rmse: 62.1183\tvalid's rmse: 104.959\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1518]\ttrain's rmse: 62.1051\tvalid's rmse: 104.959\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1519]\ttrain's rmse: 62.094\tvalid's rmse: 104.958\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1520]\ttrain's rmse: 62.0843\tvalid's rmse: 104.959\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1521]\ttrain's rmse: 62.0711\tvalid's rmse: 104.957\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1522]\ttrain's rmse: 62.06\tvalid's rmse: 104.955\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1523]\ttrain's rmse: 62.0504\tvalid's rmse: 104.954\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1524]\ttrain's rmse: 62.039\tvalid's rmse: 104.954\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1525]\ttrain's rmse: 62.0277\tvalid's rmse: 104.956\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1526]\ttrain's rmse: 62.0127\tvalid's rmse: 104.955\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1527]\ttrain's rmse: 61.9948\tvalid's rmse: 104.956\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1528]\ttrain's rmse: 61.9777\tvalid's rmse: 104.955\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1529]\ttrain's rmse: 61.9684\tvalid's rmse: 104.955\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1530]\ttrain's rmse: 61.9524\tvalid's rmse: 104.955\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1531]\ttrain's rmse: 61.9418\tvalid's rmse: 104.955\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1532]\ttrain's rmse: 61.9329\tvalid's rmse: 104.955\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1533]\ttrain's rmse: 61.9238\tvalid's rmse: 104.953\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1534]\ttrain's rmse: 61.9109\tvalid's rmse: 104.953\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1535]\ttrain's rmse: 61.8962\tvalid's rmse: 104.954\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1536]\ttrain's rmse: 61.8841\tvalid's rmse: 104.952\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1537]\ttrain's rmse: 61.8703\tvalid's rmse: 104.949\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1538]\ttrain's rmse: 61.8576\tvalid's rmse: 104.948\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1539]\ttrain's rmse: 61.8393\tvalid's rmse: 104.945\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1540]\ttrain's rmse: 61.8311\tvalid's rmse: 104.944\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1541]\ttrain's rmse: 61.8176\tvalid's rmse: 104.946\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1542]\ttrain's rmse: 61.8011\tvalid's rmse: 104.942\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1543]\ttrain's rmse: 61.7868\tvalid's rmse: 104.941\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1544]\ttrain's rmse: 61.7746\tvalid's rmse: 104.94\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1545]\ttrain's rmse: 61.7648\tvalid's rmse: 104.94\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1546]\ttrain's rmse: 61.7522\tvalid's rmse: 104.939\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1547]\ttrain's rmse: 61.7395\tvalid's rmse: 104.937\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1548]\ttrain's rmse: 61.7286\tvalid's rmse: 104.937\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1549]\ttrain's rmse: 61.717\tvalid's rmse: 104.939\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1550]\ttrain's rmse: 61.7\tvalid's rmse: 104.938\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1551]\ttrain's rmse: 61.6944\tvalid's rmse: 104.937\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1552]\ttrain's rmse: 61.6786\tvalid's rmse: 104.934\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1553]\ttrain's rmse: 61.6704\tvalid's rmse: 104.932\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1554]\ttrain's rmse: 61.6571\tvalid's rmse: 104.931\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1555]\ttrain's rmse: 61.6481\tvalid's rmse: 104.931\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1556]\ttrain's rmse: 61.6383\tvalid's rmse: 104.931\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1557]\ttrain's rmse: 61.6235\tvalid's rmse: 104.93\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1558]\ttrain's rmse: 61.6105\tvalid's rmse: 104.928\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1559]\ttrain's rmse: 61.6039\tvalid's rmse: 104.929\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1560]\ttrain's rmse: 61.595\tvalid's rmse: 104.927\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1561]\ttrain's rmse: 61.584\tvalid's rmse: 104.927\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1562]\ttrain's rmse: 61.5708\tvalid's rmse: 104.924\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1563]\ttrain's rmse: 61.5575\tvalid's rmse: 104.925\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1564]\ttrain's rmse: 61.5468\tvalid's rmse: 104.924\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1565]\ttrain's rmse: 61.5332\tvalid's rmse: 104.926\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1566]\ttrain's rmse: 61.5165\tvalid's rmse: 104.924\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1567]\ttrain's rmse: 61.5024\tvalid's rmse: 104.922\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1568]\ttrain's rmse: 61.4812\tvalid's rmse: 104.922\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1569]\ttrain's rmse: 61.464\tvalid's rmse: 104.922\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1570]\ttrain's rmse: 61.456\tvalid's rmse: 104.919\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1571]\ttrain's rmse: 61.4479\tvalid's rmse: 104.919\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1572]\ttrain's rmse: 61.439\tvalid's rmse: 104.917\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1573]\ttrain's rmse: 61.426\tvalid's rmse: 104.917\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1574]\ttrain's rmse: 61.4147\tvalid's rmse: 104.916\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1575]\ttrain's rmse: 61.4039\tvalid's rmse: 104.916\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1576]\ttrain's rmse: 61.3969\tvalid's rmse: 104.917\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1577]\ttrain's rmse: 61.3876\tvalid's rmse: 104.914\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1578]\ttrain's rmse: 61.3744\tvalid's rmse: 104.914\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1579]\ttrain's rmse: 61.3643\tvalid's rmse: 104.914\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1580]\ttrain's rmse: 61.3546\tvalid's rmse: 104.914\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1581]\ttrain's rmse: 61.3394\tvalid's rmse: 104.913\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1582]\ttrain's rmse: 61.3268\tvalid's rmse: 104.91\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1583]\ttrain's rmse: 61.3134\tvalid's rmse: 104.909\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1584]\ttrain's rmse: 61.3039\tvalid's rmse: 104.909\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1585]\ttrain's rmse: 61.294\tvalid's rmse: 104.907\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1586]\ttrain's rmse: 61.2821\tvalid's rmse: 104.906\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1587]\ttrain's rmse: 61.2716\tvalid's rmse: 104.906\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1588]\ttrain's rmse: 61.2624\tvalid's rmse: 104.905\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1589]\ttrain's rmse: 61.2501\tvalid's rmse: 104.904\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 23\n",
      "[1590]\ttrain's rmse: 61.2395\tvalid's rmse: 104.906\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1591]\ttrain's rmse: 61.2279\tvalid's rmse: 104.904\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1592]\ttrain's rmse: 61.2148\tvalid's rmse: 104.902\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1593]\ttrain's rmse: 61.2043\tvalid's rmse: 104.902\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1594]\ttrain's rmse: 61.1916\tvalid's rmse: 104.9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1595]\ttrain's rmse: 61.175\tvalid's rmse: 104.901\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1596]\ttrain's rmse: 61.1635\tvalid's rmse: 104.9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1597]\ttrain's rmse: 61.1575\tvalid's rmse: 104.9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1598]\ttrain's rmse: 61.1476\tvalid's rmse: 104.9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1599]\ttrain's rmse: 61.1367\tvalid's rmse: 104.898\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1600]\ttrain's rmse: 61.1208\tvalid's rmse: 104.897\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1601]\ttrain's rmse: 61.1105\tvalid's rmse: 104.897\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1602]\ttrain's rmse: 61.1004\tvalid's rmse: 104.897\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1603]\ttrain's rmse: 61.0889\tvalid's rmse: 104.897\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1604]\ttrain's rmse: 61.0785\tvalid's rmse: 104.896\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1605]\ttrain's rmse: 61.0641\tvalid's rmse: 104.896\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1606]\ttrain's rmse: 61.0532\tvalid's rmse: 104.896\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1607]\ttrain's rmse: 61.0438\tvalid's rmse: 104.893\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1608]\ttrain's rmse: 61.0285\tvalid's rmse: 104.893\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1609]\ttrain's rmse: 61.0151\tvalid's rmse: 104.892\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1610]\ttrain's rmse: 61.0068\tvalid's rmse: 104.893\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1611]\ttrain's rmse: 60.9952\tvalid's rmse: 104.892\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1612]\ttrain's rmse: 60.9844\tvalid's rmse: 104.89\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1613]\ttrain's rmse: 60.9736\tvalid's rmse: 104.889\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1614]\ttrain's rmse: 60.9651\tvalid's rmse: 104.892\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1615]\ttrain's rmse: 60.9491\tvalid's rmse: 104.893\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1616]\ttrain's rmse: 60.9354\tvalid's rmse: 104.892\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1617]\ttrain's rmse: 60.9252\tvalid's rmse: 104.891\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1618]\ttrain's rmse: 60.9102\tvalid's rmse: 104.89\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1619]\ttrain's rmse: 60.8938\tvalid's rmse: 104.889\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1620]\ttrain's rmse: 60.8828\tvalid's rmse: 104.889\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1621]\ttrain's rmse: 60.8682\tvalid's rmse: 104.886\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1622]\ttrain's rmse: 60.8559\tvalid's rmse: 104.886\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1623]\ttrain's rmse: 60.8464\tvalid's rmse: 104.884\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1624]\ttrain's rmse: 60.8377\tvalid's rmse: 104.884\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1625]\ttrain's rmse: 60.8243\tvalid's rmse: 104.885\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1626]\ttrain's rmse: 60.8132\tvalid's rmse: 104.885\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1627]\ttrain's rmse: 60.8011\tvalid's rmse: 104.884\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1628]\ttrain's rmse: 60.7865\tvalid's rmse: 104.885\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1629]\ttrain's rmse: 60.7722\tvalid's rmse: 104.883\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1630]\ttrain's rmse: 60.7598\tvalid's rmse: 104.884\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1631]\ttrain's rmse: 60.7464\tvalid's rmse: 104.886\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1632]\ttrain's rmse: 60.7331\tvalid's rmse: 104.885\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1633]\ttrain's rmse: 60.723\tvalid's rmse: 104.885\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 23\n",
      "[1634]\ttrain's rmse: 60.7167\tvalid's rmse: 104.883\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1635]\ttrain's rmse: 60.707\tvalid's rmse: 104.882\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1636]\ttrain's rmse: 60.6984\tvalid's rmse: 104.881\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1637]\ttrain's rmse: 60.6884\tvalid's rmse: 104.881\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1638]\ttrain's rmse: 60.6796\tvalid's rmse: 104.881\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1639]\ttrain's rmse: 60.6659\tvalid's rmse: 104.88\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1640]\ttrain's rmse: 60.6553\tvalid's rmse: 104.88\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1641]\ttrain's rmse: 60.643\tvalid's rmse: 104.882\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1642]\ttrain's rmse: 60.6309\tvalid's rmse: 104.884\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1643]\ttrain's rmse: 60.6155\tvalid's rmse: 104.884\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1644]\ttrain's rmse: 60.5979\tvalid's rmse: 104.881\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1645]\ttrain's rmse: 60.588\tvalid's rmse: 104.881\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1646]\ttrain's rmse: 60.5773\tvalid's rmse: 104.881\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1647]\ttrain's rmse: 60.5686\tvalid's rmse: 104.879\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1648]\ttrain's rmse: 60.5566\tvalid's rmse: 104.876\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1649]\ttrain's rmse: 60.5466\tvalid's rmse: 104.876\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1650]\ttrain's rmse: 60.5348\tvalid's rmse: 104.874\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1651]\ttrain's rmse: 60.5214\tvalid's rmse: 104.872\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1652]\ttrain's rmse: 60.5096\tvalid's rmse: 104.871\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1653]\ttrain's rmse: 60.4928\tvalid's rmse: 104.868\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1654]\ttrain's rmse: 60.4781\tvalid's rmse: 104.869\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1655]\ttrain's rmse: 60.4657\tvalid's rmse: 104.871\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1656]\ttrain's rmse: 60.4548\tvalid's rmse: 104.872\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1657]\ttrain's rmse: 60.4493\tvalid's rmse: 104.871\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1658]\ttrain's rmse: 60.4338\tvalid's rmse: 104.871\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1659]\ttrain's rmse: 60.4249\tvalid's rmse: 104.87\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[1660]\ttrain's rmse: 60.4166\tvalid's rmse: 104.869\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1661]\ttrain's rmse: 60.4057\tvalid's rmse: 104.867\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1662]\ttrain's rmse: 60.3947\tvalid's rmse: 104.865\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1663]\ttrain's rmse: 60.3831\tvalid's rmse: 104.863\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 24\n",
      "[1664]\ttrain's rmse: 60.3705\tvalid's rmse: 104.863\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1665]\ttrain's rmse: 60.3585\tvalid's rmse: 104.863\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1666]\ttrain's rmse: 60.3482\tvalid's rmse: 104.862\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1667]\ttrain's rmse: 60.3381\tvalid's rmse: 104.861\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1668]\ttrain's rmse: 60.3287\tvalid's rmse: 104.862\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1669]\ttrain's rmse: 60.3181\tvalid's rmse: 104.862\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1670]\ttrain's rmse: 60.307\tvalid's rmse: 104.859\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1671]\ttrain's rmse: 60.2921\tvalid's rmse: 104.859\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1672]\ttrain's rmse: 60.2853\tvalid's rmse: 104.858\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1673]\ttrain's rmse: 60.2763\tvalid's rmse: 104.859\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1674]\ttrain's rmse: 60.2659\tvalid's rmse: 104.858\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1675]\ttrain's rmse: 60.2553\tvalid's rmse: 104.857\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1676]\ttrain's rmse: 60.2479\tvalid's rmse: 104.858\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1677]\ttrain's rmse: 60.2359\tvalid's rmse: 104.856\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1678]\ttrain's rmse: 60.2258\tvalid's rmse: 104.858\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1679]\ttrain's rmse: 60.2157\tvalid's rmse: 104.856\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1680]\ttrain's rmse: 60.2084\tvalid's rmse: 104.855\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1681]\ttrain's rmse: 60.1972\tvalid's rmse: 104.856\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1682]\ttrain's rmse: 60.1903\tvalid's rmse: 104.855\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1683]\ttrain's rmse: 60.1788\tvalid's rmse: 104.855\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1684]\ttrain's rmse: 60.1672\tvalid's rmse: 104.855\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1685]\ttrain's rmse: 60.1571\tvalid's rmse: 104.856\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1686]\ttrain's rmse: 60.1457\tvalid's rmse: 104.857\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1687]\ttrain's rmse: 60.136\tvalid's rmse: 104.859\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1688]\ttrain's rmse: 60.1197\tvalid's rmse: 104.859\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1689]\ttrain's rmse: 60.1103\tvalid's rmse: 104.859\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1690]\ttrain's rmse: 60.0986\tvalid's rmse: 104.857\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1691]\ttrain's rmse: 60.0894\tvalid's rmse: 104.857\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1692]\ttrain's rmse: 60.076\tvalid's rmse: 104.857\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1693]\ttrain's rmse: 60.0604\tvalid's rmse: 104.854\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1694]\ttrain's rmse: 60.0525\tvalid's rmse: 104.854\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1695]\ttrain's rmse: 60.043\tvalid's rmse: 104.853\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1696]\ttrain's rmse: 60.0279\tvalid's rmse: 104.854\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1697]\ttrain's rmse: 60.016\tvalid's rmse: 104.853\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1698]\ttrain's rmse: 60.0034\tvalid's rmse: 104.853\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1699]\ttrain's rmse: 59.9927\tvalid's rmse: 104.852\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1700]\ttrain's rmse: 59.9811\tvalid's rmse: 104.85\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1701]\ttrain's rmse: 59.9643\tvalid's rmse: 104.848\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1702]\ttrain's rmse: 59.9545\tvalid's rmse: 104.847\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1703]\ttrain's rmse: 59.9417\tvalid's rmse: 104.846\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1704]\ttrain's rmse: 59.931\tvalid's rmse: 104.845\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1705]\ttrain's rmse: 59.9235\tvalid's rmse: 104.845\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1706]\ttrain's rmse: 59.9128\tvalid's rmse: 104.845\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1707]\ttrain's rmse: 59.9052\tvalid's rmse: 104.845\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1708]\ttrain's rmse: 59.8919\tvalid's rmse: 104.843\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1709]\ttrain's rmse: 59.8833\tvalid's rmse: 104.841\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1710]\ttrain's rmse: 59.8718\tvalid's rmse: 104.84\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1711]\ttrain's rmse: 59.8605\tvalid's rmse: 104.841\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1712]\ttrain's rmse: 59.8516\tvalid's rmse: 104.84\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1713]\ttrain's rmse: 59.8397\tvalid's rmse: 104.84\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1714]\ttrain's rmse: 59.8275\tvalid's rmse: 104.839\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1715]\ttrain's rmse: 59.8141\tvalid's rmse: 104.837\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1716]\ttrain's rmse: 59.8065\tvalid's rmse: 104.838\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1717]\ttrain's rmse: 59.7965\tvalid's rmse: 104.838\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1718]\ttrain's rmse: 59.7861\tvalid's rmse: 104.839\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1719]\ttrain's rmse: 59.7772\tvalid's rmse: 104.838\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1720]\ttrain's rmse: 59.7538\tvalid's rmse: 104.839\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1721]\ttrain's rmse: 59.7424\tvalid's rmse: 104.838\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1722]\ttrain's rmse: 59.729\tvalid's rmse: 104.834\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1723]\ttrain's rmse: 59.7174\tvalid's rmse: 104.834\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1724]\ttrain's rmse: 59.7093\tvalid's rmse: 104.834\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1725]\ttrain's rmse: 59.6923\tvalid's rmse: 104.834\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1726]\ttrain's rmse: 59.6839\tvalid's rmse: 104.833\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1727]\ttrain's rmse: 59.6722\tvalid's rmse: 104.835\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1728]\ttrain's rmse: 59.6628\tvalid's rmse: 104.836\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1729]\ttrain's rmse: 59.6514\tvalid's rmse: 104.837\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1730]\ttrain's rmse: 59.6409\tvalid's rmse: 104.838\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1731]\ttrain's rmse: 59.631\tvalid's rmse: 104.838\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1732]\ttrain's rmse: 59.6159\tvalid's rmse: 104.836\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1733]\ttrain's rmse: 59.6068\tvalid's rmse: 104.837\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1734]\ttrain's rmse: 59.5949\tvalid's rmse: 104.836\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1735]\ttrain's rmse: 59.5804\tvalid's rmse: 104.834\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1736]\ttrain's rmse: 59.5735\tvalid's rmse: 104.834\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1737]\ttrain's rmse: 59.563\tvalid's rmse: 104.833\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1738]\ttrain's rmse: 59.5533\tvalid's rmse: 104.832\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1739]\ttrain's rmse: 59.5394\tvalid's rmse: 104.831\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1740]\ttrain's rmse: 59.5253\tvalid's rmse: 104.831\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1741]\ttrain's rmse: 59.5098\tvalid's rmse: 104.83\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1742]\ttrain's rmse: 59.4992\tvalid's rmse: 104.83\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1743]\ttrain's rmse: 59.4825\tvalid's rmse: 104.828\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1744]\ttrain's rmse: 59.4719\tvalid's rmse: 104.828\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1745]\ttrain's rmse: 59.4602\tvalid's rmse: 104.825\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1746]\ttrain's rmse: 59.4497\tvalid's rmse: 104.825\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1747]\ttrain's rmse: 59.4428\tvalid's rmse: 104.824\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1748]\ttrain's rmse: 59.4311\tvalid's rmse: 104.824\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1749]\ttrain's rmse: 59.4217\tvalid's rmse: 104.824\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1750]\ttrain's rmse: 59.4103\tvalid's rmse: 104.825\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1751]\ttrain's rmse: 59.3989\tvalid's rmse: 104.825\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1752]\ttrain's rmse: 59.3893\tvalid's rmse: 104.823\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1753]\ttrain's rmse: 59.381\tvalid's rmse: 104.822\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1754]\ttrain's rmse: 59.3683\tvalid's rmse: 104.823\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1755]\ttrain's rmse: 59.3576\tvalid's rmse: 104.822\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1756]\ttrain's rmse: 59.3498\tvalid's rmse: 104.821\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1757]\ttrain's rmse: 59.3365\tvalid's rmse: 104.821\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1758]\ttrain's rmse: 59.3237\tvalid's rmse: 104.821\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1759]\ttrain's rmse: 59.3142\tvalid's rmse: 104.82\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1760]\ttrain's rmse: 59.3051\tvalid's rmse: 104.819\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1761]\ttrain's rmse: 59.2979\tvalid's rmse: 104.819\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1762]\ttrain's rmse: 59.2873\tvalid's rmse: 104.818\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1763]\ttrain's rmse: 59.2792\tvalid's rmse: 104.818\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1764]\ttrain's rmse: 59.2629\tvalid's rmse: 104.819\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1765]\ttrain's rmse: 59.2501\tvalid's rmse: 104.819\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1766]\ttrain's rmse: 59.2418\tvalid's rmse: 104.819\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1767]\ttrain's rmse: 59.2287\tvalid's rmse: 104.819\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1768]\ttrain's rmse: 59.22\tvalid's rmse: 104.818\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1769]\ttrain's rmse: 59.2092\tvalid's rmse: 104.819\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1770]\ttrain's rmse: 59.1923\tvalid's rmse: 104.817\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1771]\ttrain's rmse: 59.1791\tvalid's rmse: 104.815\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1772]\ttrain's rmse: 59.1692\tvalid's rmse: 104.816\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1773]\ttrain's rmse: 59.1603\tvalid's rmse: 104.815\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1774]\ttrain's rmse: 59.1511\tvalid's rmse: 104.815\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1775]\ttrain's rmse: 59.1449\tvalid's rmse: 104.814\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1776]\ttrain's rmse: 59.137\tvalid's rmse: 104.813\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1777]\ttrain's rmse: 59.1223\tvalid's rmse: 104.813\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1778]\ttrain's rmse: 59.1126\tvalid's rmse: 104.811\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1779]\ttrain's rmse: 59.1058\tvalid's rmse: 104.811\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1780]\ttrain's rmse: 59.0975\tvalid's rmse: 104.811\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1781]\ttrain's rmse: 59.0858\tvalid's rmse: 104.811\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1782]\ttrain's rmse: 59.0742\tvalid's rmse: 104.81\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1783]\ttrain's rmse: 59.0638\tvalid's rmse: 104.81\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1784]\ttrain's rmse: 59.0587\tvalid's rmse: 104.81\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1785]\ttrain's rmse: 59.052\tvalid's rmse: 104.809\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1786]\ttrain's rmse: 59.0455\tvalid's rmse: 104.809\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1787]\ttrain's rmse: 59.0329\tvalid's rmse: 104.807\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1788]\ttrain's rmse: 59.0191\tvalid's rmse: 104.806\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1789]\ttrain's rmse: 59.0041\tvalid's rmse: 104.804\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1790]\ttrain's rmse: 58.9966\tvalid's rmse: 104.805\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1791]\ttrain's rmse: 58.9845\tvalid's rmse: 104.802\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1792]\ttrain's rmse: 58.9738\tvalid's rmse: 104.8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1793]\ttrain's rmse: 58.9633\tvalid's rmse: 104.798\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1794]\ttrain's rmse: 58.9505\tvalid's rmse: 104.798\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1795]\ttrain's rmse: 58.9401\tvalid's rmse: 104.797\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1796]\ttrain's rmse: 58.9282\tvalid's rmse: 104.798\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1797]\ttrain's rmse: 58.9204\tvalid's rmse: 104.797\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1798]\ttrain's rmse: 58.9102\tvalid's rmse: 104.798\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1799]\ttrain's rmse: 58.8981\tvalid's rmse: 104.796\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 25\n",
      "[1800]\ttrain's rmse: 58.8929\tvalid's rmse: 104.797\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1801]\ttrain's rmse: 58.878\tvalid's rmse: 104.797\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1802]\ttrain's rmse: 58.8687\tvalid's rmse: 104.796\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1803]\ttrain's rmse: 58.8612\tvalid's rmse: 104.795\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1804]\ttrain's rmse: 58.8516\tvalid's rmse: 104.796\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1805]\ttrain's rmse: 58.8419\tvalid's rmse: 104.796\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1806]\ttrain's rmse: 58.8353\tvalid's rmse: 104.796\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1807]\ttrain's rmse: 58.8238\tvalid's rmse: 104.794\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1808]\ttrain's rmse: 58.8076\tvalid's rmse: 104.793\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1809]\ttrain's rmse: 58.7981\tvalid's rmse: 104.793\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1810]\ttrain's rmse: 58.785\tvalid's rmse: 104.79\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1811]\ttrain's rmse: 58.7668\tvalid's rmse: 104.789\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1812]\ttrain's rmse: 58.7568\tvalid's rmse: 104.787\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1813]\ttrain's rmse: 58.7471\tvalid's rmse: 104.788\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1814]\ttrain's rmse: 58.7287\tvalid's rmse: 104.79\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1815]\ttrain's rmse: 58.7166\tvalid's rmse: 104.788\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1816]\ttrain's rmse: 58.7091\tvalid's rmse: 104.787\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1817]\ttrain's rmse: 58.7034\tvalid's rmse: 104.788\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1818]\ttrain's rmse: 58.6891\tvalid's rmse: 104.784\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1819]\ttrain's rmse: 58.681\tvalid's rmse: 104.784\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1820]\ttrain's rmse: 58.6714\tvalid's rmse: 104.784\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1821]\ttrain's rmse: 58.6604\tvalid's rmse: 104.783\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1822]\ttrain's rmse: 58.6472\tvalid's rmse: 104.784\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1823]\ttrain's rmse: 58.6341\tvalid's rmse: 104.781\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 26\n",
      "[1824]\ttrain's rmse: 58.622\tvalid's rmse: 104.781\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1825]\ttrain's rmse: 58.6049\tvalid's rmse: 104.782\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1826]\ttrain's rmse: 58.5918\tvalid's rmse: 104.783\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1827]\ttrain's rmse: 58.5793\tvalid's rmse: 104.782\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1828]\ttrain's rmse: 58.5707\tvalid's rmse: 104.781\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1829]\ttrain's rmse: 58.5612\tvalid's rmse: 104.782\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[1830]\ttrain's rmse: 58.5499\tvalid's rmse: 104.782\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1831]\ttrain's rmse: 58.5364\tvalid's rmse: 104.783\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1832]\ttrain's rmse: 58.5248\tvalid's rmse: 104.784\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1833]\ttrain's rmse: 58.516\tvalid's rmse: 104.784\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[1834]\ttrain's rmse: 58.5032\tvalid's rmse: 104.782\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1835]\ttrain's rmse: 58.4891\tvalid's rmse: 104.782\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1836]\ttrain's rmse: 58.4787\tvalid's rmse: 104.782\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1837]\ttrain's rmse: 58.4654\tvalid's rmse: 104.779\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1838]\ttrain's rmse: 58.4502\tvalid's rmse: 104.781\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1839]\ttrain's rmse: 58.4394\tvalid's rmse: 104.78\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1840]\ttrain's rmse: 58.4307\tvalid's rmse: 104.78\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1841]\ttrain's rmse: 58.4238\tvalid's rmse: 104.781\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1842]\ttrain's rmse: 58.4131\tvalid's rmse: 104.779\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1843]\ttrain's rmse: 58.4069\tvalid's rmse: 104.779\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1844]\ttrain's rmse: 58.3949\tvalid's rmse: 104.777\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1845]\ttrain's rmse: 58.3847\tvalid's rmse: 104.776\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1846]\ttrain's rmse: 58.3739\tvalid's rmse: 104.777\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 24\n",
      "[1847]\ttrain's rmse: 58.3617\tvalid's rmse: 104.775\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1848]\ttrain's rmse: 58.3539\tvalid's rmse: 104.774\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1849]\ttrain's rmse: 58.3426\tvalid's rmse: 104.773\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1850]\ttrain's rmse: 58.3305\tvalid's rmse: 104.772\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1851]\ttrain's rmse: 58.3229\tvalid's rmse: 104.771\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1852]\ttrain's rmse: 58.3116\tvalid's rmse: 104.77\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1853]\ttrain's rmse: 58.3054\tvalid's rmse: 104.77\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1854]\ttrain's rmse: 58.2942\tvalid's rmse: 104.77\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1855]\ttrain's rmse: 58.279\tvalid's rmse: 104.768\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1856]\ttrain's rmse: 58.2686\tvalid's rmse: 104.768\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1857]\ttrain's rmse: 58.2576\tvalid's rmse: 104.767\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1858]\ttrain's rmse: 58.2488\tvalid's rmse: 104.767\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[1859]\ttrain's rmse: 58.2356\tvalid's rmse: 104.768\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1860]\ttrain's rmse: 58.2246\tvalid's rmse: 104.767\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1861]\ttrain's rmse: 58.2166\tvalid's rmse: 104.765\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1862]\ttrain's rmse: 58.2079\tvalid's rmse: 104.765\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1863]\ttrain's rmse: 58.1963\tvalid's rmse: 104.764\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1864]\ttrain's rmse: 58.187\tvalid's rmse: 104.763\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1865]\ttrain's rmse: 58.1744\tvalid's rmse: 104.763\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1866]\ttrain's rmse: 58.1647\tvalid's rmse: 104.763\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1867]\ttrain's rmse: 58.1537\tvalid's rmse: 104.762\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1868]\ttrain's rmse: 58.1437\tvalid's rmse: 104.761\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1869]\ttrain's rmse: 58.1381\tvalid's rmse: 104.761\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1870]\ttrain's rmse: 58.1319\tvalid's rmse: 104.759\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1871]\ttrain's rmse: 58.1195\tvalid's rmse: 104.758\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1872]\ttrain's rmse: 58.1134\tvalid's rmse: 104.757\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[1873]\ttrain's rmse: 58.1004\tvalid's rmse: 104.755\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 23\n",
      "[1874]\ttrain's rmse: 58.0874\tvalid's rmse: 104.754\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1875]\ttrain's rmse: 58.0812\tvalid's rmse: 104.753\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1876]\ttrain's rmse: 58.0748\tvalid's rmse: 104.753\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 26\n",
      "[1877]\ttrain's rmse: 58.0637\tvalid's rmse: 104.752\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1878]\ttrain's rmse: 58.0522\tvalid's rmse: 104.751\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1879]\ttrain's rmse: 58.041\tvalid's rmse: 104.752\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1880]\ttrain's rmse: 58.0295\tvalid's rmse: 104.752\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1881]\ttrain's rmse: 58.0207\tvalid's rmse: 104.751\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1882]\ttrain's rmse: 58.0099\tvalid's rmse: 104.749\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1883]\ttrain's rmse: 57.999\tvalid's rmse: 104.744\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1884]\ttrain's rmse: 57.9857\tvalid's rmse: 104.744\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1885]\ttrain's rmse: 57.9805\tvalid's rmse: 104.744\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1886]\ttrain's rmse: 57.9667\tvalid's rmse: 104.743\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1887]\ttrain's rmse: 57.9554\tvalid's rmse: 104.744\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1888]\ttrain's rmse: 57.9458\tvalid's rmse: 104.743\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1889]\ttrain's rmse: 57.9334\tvalid's rmse: 104.741\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1890]\ttrain's rmse: 57.9245\tvalid's rmse: 104.741\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1891]\ttrain's rmse: 57.9179\tvalid's rmse: 104.739\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1892]\ttrain's rmse: 57.9032\tvalid's rmse: 104.739\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1893]\ttrain's rmse: 57.8919\tvalid's rmse: 104.738\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1894]\ttrain's rmse: 57.8825\tvalid's rmse: 104.739\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1895]\ttrain's rmse: 57.8732\tvalid's rmse: 104.738\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1896]\ttrain's rmse: 57.8611\tvalid's rmse: 104.737\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1897]\ttrain's rmse: 57.8523\tvalid's rmse: 104.736\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1898]\ttrain's rmse: 57.8393\tvalid's rmse: 104.738\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1899]\ttrain's rmse: 57.8321\tvalid's rmse: 104.739\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1900]\ttrain's rmse: 57.8266\tvalid's rmse: 104.738\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1901]\ttrain's rmse: 57.8187\tvalid's rmse: 104.737\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1902]\ttrain's rmse: 57.8115\tvalid's rmse: 104.737\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1903]\ttrain's rmse: 57.8054\tvalid's rmse: 104.736\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1904]\ttrain's rmse: 57.7974\tvalid's rmse: 104.735\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1905]\ttrain's rmse: 57.7846\tvalid's rmse: 104.733\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1906]\ttrain's rmse: 57.7747\tvalid's rmse: 104.732\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1907]\ttrain's rmse: 57.7623\tvalid's rmse: 104.732\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1908]\ttrain's rmse: 57.7517\tvalid's rmse: 104.731\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1909]\ttrain's rmse: 57.74\tvalid's rmse: 104.73\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1910]\ttrain's rmse: 57.7303\tvalid's rmse: 104.728\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1911]\ttrain's rmse: 57.7141\tvalid's rmse: 104.729\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1912]\ttrain's rmse: 57.7037\tvalid's rmse: 104.729\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1913]\ttrain's rmse: 57.6933\tvalid's rmse: 104.728\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1914]\ttrain's rmse: 57.6775\tvalid's rmse: 104.729\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1915]\ttrain's rmse: 57.6656\tvalid's rmse: 104.728\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1916]\ttrain's rmse: 57.6548\tvalid's rmse: 104.728\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1917]\ttrain's rmse: 57.6445\tvalid's rmse: 104.726\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1918]\ttrain's rmse: 57.6356\tvalid's rmse: 104.725\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1919]\ttrain's rmse: 57.6278\tvalid's rmse: 104.723\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1920]\ttrain's rmse: 57.6194\tvalid's rmse: 104.723\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1921]\ttrain's rmse: 57.6083\tvalid's rmse: 104.724\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1922]\ttrain's rmse: 57.6004\tvalid's rmse: 104.724\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1923]\ttrain's rmse: 57.5924\tvalid's rmse: 104.723\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1924]\ttrain's rmse: 57.5868\tvalid's rmse: 104.722\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1925]\ttrain's rmse: 57.5727\tvalid's rmse: 104.723\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1926]\ttrain's rmse: 57.56\tvalid's rmse: 104.723\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1927]\ttrain's rmse: 57.5476\tvalid's rmse: 104.724\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 29\n",
      "[1928]\ttrain's rmse: 57.5425\tvalid's rmse: 104.724\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1929]\ttrain's rmse: 57.5342\tvalid's rmse: 104.723\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1930]\ttrain's rmse: 57.5227\tvalid's rmse: 104.723\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1931]\ttrain's rmse: 57.5137\tvalid's rmse: 104.722\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1932]\ttrain's rmse: 57.5048\tvalid's rmse: 104.721\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1933]\ttrain's rmse: 57.4951\tvalid's rmse: 104.723\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1934]\ttrain's rmse: 57.4842\tvalid's rmse: 104.721\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1935]\ttrain's rmse: 57.4761\tvalid's rmse: 104.72\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1936]\ttrain's rmse: 57.4636\tvalid's rmse: 104.72\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1937]\ttrain's rmse: 57.4519\tvalid's rmse: 104.719\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1938]\ttrain's rmse: 57.4426\tvalid's rmse: 104.719\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1939]\ttrain's rmse: 57.4367\tvalid's rmse: 104.72\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1940]\ttrain's rmse: 57.4262\tvalid's rmse: 104.72\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1941]\ttrain's rmse: 57.4173\tvalid's rmse: 104.718\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[1942]\ttrain's rmse: 57.4069\tvalid's rmse: 104.717\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1943]\ttrain's rmse: 57.3988\tvalid's rmse: 104.717\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1944]\ttrain's rmse: 57.3921\tvalid's rmse: 104.716\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1945]\ttrain's rmse: 57.3848\tvalid's rmse: 104.716\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1946]\ttrain's rmse: 57.373\tvalid's rmse: 104.715\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1947]\ttrain's rmse: 57.3643\tvalid's rmse: 104.716\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1948]\ttrain's rmse: 57.3562\tvalid's rmse: 104.714\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1949]\ttrain's rmse: 57.3467\tvalid's rmse: 104.713\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[1950]\ttrain's rmse: 57.3398\tvalid's rmse: 104.713\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1951]\ttrain's rmse: 57.3306\tvalid's rmse: 104.712\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1952]\ttrain's rmse: 57.3239\tvalid's rmse: 104.711\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1953]\ttrain's rmse: 57.3155\tvalid's rmse: 104.711\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1954]\ttrain's rmse: 57.2979\tvalid's rmse: 104.713\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1955]\ttrain's rmse: 57.2864\tvalid's rmse: 104.711\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1956]\ttrain's rmse: 57.2794\tvalid's rmse: 104.711\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1957]\ttrain's rmse: 57.2672\tvalid's rmse: 104.71\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1958]\ttrain's rmse: 57.2573\tvalid's rmse: 104.709\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1959]\ttrain's rmse: 57.2482\tvalid's rmse: 104.708\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1960]\ttrain's rmse: 57.2362\tvalid's rmse: 104.706\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1961]\ttrain's rmse: 57.2297\tvalid's rmse: 104.705\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1962]\ttrain's rmse: 57.223\tvalid's rmse: 104.705\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1963]\ttrain's rmse: 57.2111\tvalid's rmse: 104.705\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1964]\ttrain's rmse: 57.2032\tvalid's rmse: 104.705\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1965]\ttrain's rmse: 57.1928\tvalid's rmse: 104.703\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1966]\ttrain's rmse: 57.1823\tvalid's rmse: 104.703\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1967]\ttrain's rmse: 57.1751\tvalid's rmse: 104.703\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1968]\ttrain's rmse: 57.1646\tvalid's rmse: 104.7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1969]\ttrain's rmse: 57.1592\tvalid's rmse: 104.7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1970]\ttrain's rmse: 57.1514\tvalid's rmse: 104.7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1971]\ttrain's rmse: 57.1397\tvalid's rmse: 104.699\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1972]\ttrain's rmse: 57.1315\tvalid's rmse: 104.696\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1973]\ttrain's rmse: 57.1239\tvalid's rmse: 104.696\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1974]\ttrain's rmse: 57.109\tvalid's rmse: 104.696\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[1975]\ttrain's rmse: 57.0961\tvalid's rmse: 104.699\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[1976]\ttrain's rmse: 57.09\tvalid's rmse: 104.698\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1977]\ttrain's rmse: 57.0802\tvalid's rmse: 104.697\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1978]\ttrain's rmse: 57.0679\tvalid's rmse: 104.696\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1979]\ttrain's rmse: 57.0555\tvalid's rmse: 104.694\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1980]\ttrain's rmse: 57.0483\tvalid's rmse: 104.694\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1981]\ttrain's rmse: 57.0415\tvalid's rmse: 104.693\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1982]\ttrain's rmse: 57.0307\tvalid's rmse: 104.693\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1983]\ttrain's rmse: 57.0196\tvalid's rmse: 104.694\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1984]\ttrain's rmse: 57.0119\tvalid's rmse: 104.693\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1985]\ttrain's rmse: 56.9947\tvalid's rmse: 104.688\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1986]\ttrain's rmse: 56.9857\tvalid's rmse: 104.689\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1987]\ttrain's rmse: 56.9737\tvalid's rmse: 104.688\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1988]\ttrain's rmse: 56.9658\tvalid's rmse: 104.689\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[1989]\ttrain's rmse: 56.9538\tvalid's rmse: 104.691\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[1990]\ttrain's rmse: 56.9413\tvalid's rmse: 104.688\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1991]\ttrain's rmse: 56.9308\tvalid's rmse: 104.685\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1992]\ttrain's rmse: 56.9214\tvalid's rmse: 104.686\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[1993]\ttrain's rmse: 56.9153\tvalid's rmse: 104.685\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[1994]\ttrain's rmse: 56.9051\tvalid's rmse: 104.686\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[1995]\ttrain's rmse: 56.8959\tvalid's rmse: 104.686\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1996]\ttrain's rmse: 56.8856\tvalid's rmse: 104.686\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[1997]\ttrain's rmse: 56.8748\tvalid's rmse: 104.688\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1998]\ttrain's rmse: 56.8635\tvalid's rmse: 104.688\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[1999]\ttrain's rmse: 56.8533\tvalid's rmse: 104.689\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[2000]\ttrain's rmse: 56.843\tvalid's rmse: 104.69\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2001]\ttrain's rmse: 56.8337\tvalid's rmse: 104.69\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2002]\ttrain's rmse: 56.8246\tvalid's rmse: 104.69\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2003]\ttrain's rmse: 56.8179\tvalid's rmse: 104.689\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2004]\ttrain's rmse: 56.8094\tvalid's rmse: 104.689\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2005]\ttrain's rmse: 56.8004\tvalid's rmse: 104.688\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2006]\ttrain's rmse: 56.7894\tvalid's rmse: 104.688\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2007]\ttrain's rmse: 56.7797\tvalid's rmse: 104.687\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2008]\ttrain's rmse: 56.7697\tvalid's rmse: 104.686\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2009]\ttrain's rmse: 56.7605\tvalid's rmse: 104.684\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2010]\ttrain's rmse: 56.752\tvalid's rmse: 104.685\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2011]\ttrain's rmse: 56.7384\tvalid's rmse: 104.685\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2012]\ttrain's rmse: 56.7301\tvalid's rmse: 104.684\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2013]\ttrain's rmse: 56.7246\tvalid's rmse: 104.683\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2014]\ttrain's rmse: 56.7155\tvalid's rmse: 104.682\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2015]\ttrain's rmse: 56.7084\tvalid's rmse: 104.682\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2016]\ttrain's rmse: 56.6987\tvalid's rmse: 104.681\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2017]\ttrain's rmse: 56.6901\tvalid's rmse: 104.681\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2018]\ttrain's rmse: 56.676\tvalid's rmse: 104.681\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2019]\ttrain's rmse: 56.6651\tvalid's rmse: 104.681\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 25\n",
      "[2020]\ttrain's rmse: 56.6602\tvalid's rmse: 104.68\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2021]\ttrain's rmse: 56.6513\tvalid's rmse: 104.679\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2022]\ttrain's rmse: 56.6415\tvalid's rmse: 104.68\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2023]\ttrain's rmse: 56.6325\tvalid's rmse: 104.68\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2024]\ttrain's rmse: 56.6199\tvalid's rmse: 104.678\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2025]\ttrain's rmse: 56.6082\tvalid's rmse: 104.678\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2026]\ttrain's rmse: 56.5986\tvalid's rmse: 104.677\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2027]\ttrain's rmse: 56.5887\tvalid's rmse: 104.676\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2028]\ttrain's rmse: 56.5811\tvalid's rmse: 104.677\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2029]\ttrain's rmse: 56.5746\tvalid's rmse: 104.676\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2030]\ttrain's rmse: 56.5683\tvalid's rmse: 104.677\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2031]\ttrain's rmse: 56.5569\tvalid's rmse: 104.676\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2032]\ttrain's rmse: 56.5487\tvalid's rmse: 104.675\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[2033]\ttrain's rmse: 56.5372\tvalid's rmse: 104.675\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2034]\ttrain's rmse: 56.5247\tvalid's rmse: 104.675\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 25\n",
      "[2035]\ttrain's rmse: 56.5171\tvalid's rmse: 104.675\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2036]\ttrain's rmse: 56.5056\tvalid's rmse: 104.674\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2037]\ttrain's rmse: 56.4971\tvalid's rmse: 104.673\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2038]\ttrain's rmse: 56.4894\tvalid's rmse: 104.673\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2039]\ttrain's rmse: 56.4818\tvalid's rmse: 104.673\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2040]\ttrain's rmse: 56.4727\tvalid's rmse: 104.673\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2041]\ttrain's rmse: 56.4649\tvalid's rmse: 104.673\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2042]\ttrain's rmse: 56.4563\tvalid's rmse: 104.673\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2043]\ttrain's rmse: 56.4472\tvalid's rmse: 104.674\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2044]\ttrain's rmse: 56.4419\tvalid's rmse: 104.673\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2045]\ttrain's rmse: 56.4319\tvalid's rmse: 104.671\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2046]\ttrain's rmse: 56.4233\tvalid's rmse: 104.672\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2047]\ttrain's rmse: 56.4146\tvalid's rmse: 104.672\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2048]\ttrain's rmse: 56.4001\tvalid's rmse: 104.674\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2049]\ttrain's rmse: 56.3935\tvalid's rmse: 104.674\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2050]\ttrain's rmse: 56.3863\tvalid's rmse: 104.673\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2051]\ttrain's rmse: 56.3801\tvalid's rmse: 104.673\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2052]\ttrain's rmse: 56.3695\tvalid's rmse: 104.673\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 25\n",
      "[2053]\ttrain's rmse: 56.3598\tvalid's rmse: 104.674\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2054]\ttrain's rmse: 56.3506\tvalid's rmse: 104.674\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2055]\ttrain's rmse: 56.3405\tvalid's rmse: 104.673\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2056]\ttrain's rmse: 56.3279\tvalid's rmse: 104.673\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[2057]\ttrain's rmse: 56.3207\tvalid's rmse: 104.672\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[2058]\ttrain's rmse: 56.3155\tvalid's rmse: 104.672\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2059]\ttrain's rmse: 56.3097\tvalid's rmse: 104.671\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2060]\ttrain's rmse: 56.3027\tvalid's rmse: 104.67\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2061]\ttrain's rmse: 56.2904\tvalid's rmse: 104.667\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2062]\ttrain's rmse: 56.2826\tvalid's rmse: 104.666\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[2063]\ttrain's rmse: 56.2741\tvalid's rmse: 104.665\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2064]\ttrain's rmse: 56.2662\tvalid's rmse: 104.665\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2065]\ttrain's rmse: 56.2578\tvalid's rmse: 104.664\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2066]\ttrain's rmse: 56.2512\tvalid's rmse: 104.664\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2067]\ttrain's rmse: 56.2461\tvalid's rmse: 104.662\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2068]\ttrain's rmse: 56.238\tvalid's rmse: 104.662\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2069]\ttrain's rmse: 56.2281\tvalid's rmse: 104.66\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2070]\ttrain's rmse: 56.2185\tvalid's rmse: 104.66\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2071]\ttrain's rmse: 56.2127\tvalid's rmse: 104.66\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2072]\ttrain's rmse: 56.2041\tvalid's rmse: 104.661\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2073]\ttrain's rmse: 56.1977\tvalid's rmse: 104.66\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2074]\ttrain's rmse: 56.19\tvalid's rmse: 104.658\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2075]\ttrain's rmse: 56.184\tvalid's rmse: 104.657\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2076]\ttrain's rmse: 56.1747\tvalid's rmse: 104.655\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2077]\ttrain's rmse: 56.1648\tvalid's rmse: 104.653\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2078]\ttrain's rmse: 56.1596\tvalid's rmse: 104.653\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2079]\ttrain's rmse: 56.1513\tvalid's rmse: 104.652\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2080]\ttrain's rmse: 56.141\tvalid's rmse: 104.652\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2081]\ttrain's rmse: 56.1345\tvalid's rmse: 104.651\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2082]\ttrain's rmse: 56.1262\tvalid's rmse: 104.649\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2083]\ttrain's rmse: 56.1154\tvalid's rmse: 104.646\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2084]\ttrain's rmse: 56.1047\tvalid's rmse: 104.646\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2085]\ttrain's rmse: 56.096\tvalid's rmse: 104.648\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2086]\ttrain's rmse: 56.0866\tvalid's rmse: 104.648\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2087]\ttrain's rmse: 56.0813\tvalid's rmse: 104.648\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2088]\ttrain's rmse: 56.0735\tvalid's rmse: 104.648\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2089]\ttrain's rmse: 56.0682\tvalid's rmse: 104.648\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2090]\ttrain's rmse: 56.0589\tvalid's rmse: 104.648\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2091]\ttrain's rmse: 56.0475\tvalid's rmse: 104.646\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2092]\ttrain's rmse: 56.0391\tvalid's rmse: 104.646\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2093]\ttrain's rmse: 56.0333\tvalid's rmse: 104.646\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2094]\ttrain's rmse: 56.0272\tvalid's rmse: 104.644\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2095]\ttrain's rmse: 56.0125\tvalid's rmse: 104.645\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2096]\ttrain's rmse: 56.0075\tvalid's rmse: 104.645\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2097]\ttrain's rmse: 56.0016\tvalid's rmse: 104.645\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 23\n",
      "[2098]\ttrain's rmse: 55.9962\tvalid's rmse: 104.646\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2099]\ttrain's rmse: 55.9855\tvalid's rmse: 104.646\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2100]\ttrain's rmse: 55.973\tvalid's rmse: 104.645\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2101]\ttrain's rmse: 55.9635\tvalid's rmse: 104.645\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2102]\ttrain's rmse: 55.9536\tvalid's rmse: 104.644\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2103]\ttrain's rmse: 55.9447\tvalid's rmse: 104.643\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2104]\ttrain's rmse: 55.9322\tvalid's rmse: 104.642\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2105]\ttrain's rmse: 55.9233\tvalid's rmse: 104.642\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2106]\ttrain's rmse: 55.9117\tvalid's rmse: 104.643\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2107]\ttrain's rmse: 55.9007\tvalid's rmse: 104.643\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2108]\ttrain's rmse: 55.8913\tvalid's rmse: 104.64\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2109]\ttrain's rmse: 55.8842\tvalid's rmse: 104.639\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2110]\ttrain's rmse: 55.8713\tvalid's rmse: 104.638\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2111]\ttrain's rmse: 55.8649\tvalid's rmse: 104.637\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2112]\ttrain's rmse: 55.8511\tvalid's rmse: 104.636\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[2113]\ttrain's rmse: 55.8418\tvalid's rmse: 104.636\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2114]\ttrain's rmse: 55.831\tvalid's rmse: 104.636\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2115]\ttrain's rmse: 55.8164\tvalid's rmse: 104.635\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2116]\ttrain's rmse: 55.8105\tvalid's rmse: 104.636\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2117]\ttrain's rmse: 55.7985\tvalid's rmse: 104.634\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2118]\ttrain's rmse: 55.7833\tvalid's rmse: 104.633\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2119]\ttrain's rmse: 55.7753\tvalid's rmse: 104.633\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2120]\ttrain's rmse: 55.7661\tvalid's rmse: 104.631\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2121]\ttrain's rmse: 55.7583\tvalid's rmse: 104.632\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2122]\ttrain's rmse: 55.7461\tvalid's rmse: 104.632\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2123]\ttrain's rmse: 55.7363\tvalid's rmse: 104.632\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2124]\ttrain's rmse: 55.7307\tvalid's rmse: 104.632\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2125]\ttrain's rmse: 55.7227\tvalid's rmse: 104.632\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2126]\ttrain's rmse: 55.7134\tvalid's rmse: 104.632\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2127]\ttrain's rmse: 55.7026\tvalid's rmse: 104.631\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2128]\ttrain's rmse: 55.6968\tvalid's rmse: 104.631\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2129]\ttrain's rmse: 55.6858\tvalid's rmse: 104.629\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2130]\ttrain's rmse: 55.6765\tvalid's rmse: 104.629\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2131]\ttrain's rmse: 55.666\tvalid's rmse: 104.629\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2132]\ttrain's rmse: 55.6559\tvalid's rmse: 104.627\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2133]\ttrain's rmse: 55.6487\tvalid's rmse: 104.626\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2134]\ttrain's rmse: 55.6399\tvalid's rmse: 104.626\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2135]\ttrain's rmse: 55.6285\tvalid's rmse: 104.623\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2136]\ttrain's rmse: 55.6102\tvalid's rmse: 104.623\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2137]\ttrain's rmse: 55.6003\tvalid's rmse: 104.62\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2138]\ttrain's rmse: 55.5884\tvalid's rmse: 104.619\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2139]\ttrain's rmse: 55.5774\tvalid's rmse: 104.617\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2140]\ttrain's rmse: 55.5725\tvalid's rmse: 104.617\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2141]\ttrain's rmse: 55.5666\tvalid's rmse: 104.616\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2142]\ttrain's rmse: 55.5547\tvalid's rmse: 104.615\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2143]\ttrain's rmse: 55.5453\tvalid's rmse: 104.615\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2144]\ttrain's rmse: 55.537\tvalid's rmse: 104.614\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[2145]\ttrain's rmse: 55.5271\tvalid's rmse: 104.614\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2146]\ttrain's rmse: 55.5207\tvalid's rmse: 104.614\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2147]\ttrain's rmse: 55.5105\tvalid's rmse: 104.613\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2148]\ttrain's rmse: 55.5044\tvalid's rmse: 104.612\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2149]\ttrain's rmse: 55.4954\tvalid's rmse: 104.613\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2150]\ttrain's rmse: 55.4883\tvalid's rmse: 104.611\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2151]\ttrain's rmse: 55.4771\tvalid's rmse: 104.609\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2152]\ttrain's rmse: 55.4697\tvalid's rmse: 104.608\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2153]\ttrain's rmse: 55.4622\tvalid's rmse: 104.607\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[2154]\ttrain's rmse: 55.4543\tvalid's rmse: 104.607\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2155]\ttrain's rmse: 55.4472\tvalid's rmse: 104.607\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[2156]\ttrain's rmse: 55.4376\tvalid's rmse: 104.607\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2157]\ttrain's rmse: 55.4307\tvalid's rmse: 104.606\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2158]\ttrain's rmse: 55.4242\tvalid's rmse: 104.604\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[2159]\ttrain's rmse: 55.4147\tvalid's rmse: 104.604\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2160]\ttrain's rmse: 55.4074\tvalid's rmse: 104.603\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[2161]\ttrain's rmse: 55.4018\tvalid's rmse: 104.602\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2162]\ttrain's rmse: 55.3914\tvalid's rmse: 104.601\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2163]\ttrain's rmse: 55.3832\tvalid's rmse: 104.6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2164]\ttrain's rmse: 55.3689\tvalid's rmse: 104.599\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[2165]\ttrain's rmse: 55.3561\tvalid's rmse: 104.599\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2166]\ttrain's rmse: 55.3482\tvalid's rmse: 104.598\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[2167]\ttrain's rmse: 55.339\tvalid's rmse: 104.599\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2168]\ttrain's rmse: 55.3305\tvalid's rmse: 104.598\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2169]\ttrain's rmse: 55.3219\tvalid's rmse: 104.599\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2170]\ttrain's rmse: 55.3109\tvalid's rmse: 104.598\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2171]\ttrain's rmse: 55.3041\tvalid's rmse: 104.599\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2172]\ttrain's rmse: 55.2973\tvalid's rmse: 104.599\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2173]\ttrain's rmse: 55.2919\tvalid's rmse: 104.599\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2174]\ttrain's rmse: 55.2858\tvalid's rmse: 104.599\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[2175]\ttrain's rmse: 55.2764\tvalid's rmse: 104.6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2176]\ttrain's rmse: 55.2708\tvalid's rmse: 104.6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2177]\ttrain's rmse: 55.2623\tvalid's rmse: 104.601\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2178]\ttrain's rmse: 55.2552\tvalid's rmse: 104.6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[2179]\ttrain's rmse: 55.2465\tvalid's rmse: 104.6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2180]\ttrain's rmse: 55.2395\tvalid's rmse: 104.6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2181]\ttrain's rmse: 55.2257\tvalid's rmse: 104.596\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 23\n",
      "[2182]\ttrain's rmse: 55.216\tvalid's rmse: 104.597\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 10\n",
      "[2183]\ttrain's rmse: 55.2036\tvalid's rmse: 104.598\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2184]\ttrain's rmse: 55.1931\tvalid's rmse: 104.597\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2185]\ttrain's rmse: 55.1834\tvalid's rmse: 104.597\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2186]\ttrain's rmse: 55.1768\tvalid's rmse: 104.596\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2187]\ttrain's rmse: 55.1668\tvalid's rmse: 104.596\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2188]\ttrain's rmse: 55.1573\tvalid's rmse: 104.597\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2189]\ttrain's rmse: 55.1453\tvalid's rmse: 104.597\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2190]\ttrain's rmse: 55.1379\tvalid's rmse: 104.597\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[2191]\ttrain's rmse: 55.1314\tvalid's rmse: 104.596\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[2192]\ttrain's rmse: 55.1265\tvalid's rmse: 104.597\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2193]\ttrain's rmse: 55.1181\tvalid's rmse: 104.596\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[2194]\ttrain's rmse: 55.1105\tvalid's rmse: 104.596\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2195]\ttrain's rmse: 55.1044\tvalid's rmse: 104.594\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 24\n",
      "[2196]\ttrain's rmse: 55.0956\tvalid's rmse: 104.595\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[2197]\ttrain's rmse: 55.087\tvalid's rmse: 104.595\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2198]\ttrain's rmse: 55.0752\tvalid's rmse: 104.594\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[2199]\ttrain's rmse: 55.0649\tvalid's rmse: 104.594\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2200]\ttrain's rmse: 55.0572\tvalid's rmse: 104.592\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2201]\ttrain's rmse: 55.0472\tvalid's rmse: 104.592\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[2202]\ttrain's rmse: 55.038\tvalid's rmse: 104.593\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2203]\ttrain's rmse: 55.0272\tvalid's rmse: 104.591\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2204]\ttrain's rmse: 55.02\tvalid's rmse: 104.591\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2205]\ttrain's rmse: 55.0146\tvalid's rmse: 104.591\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 22\n",
      "[2206]\ttrain's rmse: 55.0053\tvalid's rmse: 104.59\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2207]\ttrain's rmse: 54.9958\tvalid's rmse: 104.589\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2208]\ttrain's rmse: 54.9901\tvalid's rmse: 104.588\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 21\n",
      "[2209]\ttrain's rmse: 54.9771\tvalid's rmse: 104.585\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2210]\ttrain's rmse: 54.964\tvalid's rmse: 104.585\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2211]\ttrain's rmse: 54.9541\tvalid's rmse: 104.585\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2212]\ttrain's rmse: 54.9468\tvalid's rmse: 104.585\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2213]\ttrain's rmse: 54.9341\tvalid's rmse: 104.586\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2214]\ttrain's rmse: 54.9295\tvalid's rmse: 104.585\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2215]\ttrain's rmse: 54.9217\tvalid's rmse: 104.584\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2216]\ttrain's rmse: 54.9133\tvalid's rmse: 104.584\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2217]\ttrain's rmse: 54.9056\tvalid's rmse: 104.582\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2218]\ttrain's rmse: 54.8969\tvalid's rmse: 104.584\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2219]\ttrain's rmse: 54.8864\tvalid's rmse: 104.585\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2220]\ttrain's rmse: 54.8809\tvalid's rmse: 104.585\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2221]\ttrain's rmse: 54.8744\tvalid's rmse: 104.584\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2222]\ttrain's rmse: 54.8695\tvalid's rmse: 104.583\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2223]\ttrain's rmse: 54.8632\tvalid's rmse: 104.583\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2224]\ttrain's rmse: 54.8564\tvalid's rmse: 104.583\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2225]\ttrain's rmse: 54.8506\tvalid's rmse: 104.581\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2226]\ttrain's rmse: 54.8432\tvalid's rmse: 104.582\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2227]\ttrain's rmse: 54.8371\tvalid's rmse: 104.582\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2228]\ttrain's rmse: 54.8263\tvalid's rmse: 104.582\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2229]\ttrain's rmse: 54.8145\tvalid's rmse: 104.581\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2230]\ttrain's rmse: 54.8081\tvalid's rmse: 104.582\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2231]\ttrain's rmse: 54.796\tvalid's rmse: 104.581\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2232]\ttrain's rmse: 54.7906\tvalid's rmse: 104.58\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2233]\ttrain's rmse: 54.7837\tvalid's rmse: 104.579\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2234]\ttrain's rmse: 54.7772\tvalid's rmse: 104.579\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2235]\ttrain's rmse: 54.7678\tvalid's rmse: 104.578\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2236]\ttrain's rmse: 54.7551\tvalid's rmse: 104.576\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2237]\ttrain's rmse: 54.7483\tvalid's rmse: 104.574\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2238]\ttrain's rmse: 54.7376\tvalid's rmse: 104.575\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2239]\ttrain's rmse: 54.7279\tvalid's rmse: 104.574\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2240]\ttrain's rmse: 54.7229\tvalid's rmse: 104.574\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2241]\ttrain's rmse: 54.7132\tvalid's rmse: 104.574\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2242]\ttrain's rmse: 54.7049\tvalid's rmse: 104.573\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2243]\ttrain's rmse: 54.6959\tvalid's rmse: 104.571\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2244]\ttrain's rmse: 54.6901\tvalid's rmse: 104.572\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2245]\ttrain's rmse: 54.6784\tvalid's rmse: 104.573\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2246]\ttrain's rmse: 54.669\tvalid's rmse: 104.573\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2247]\ttrain's rmse: 54.6577\tvalid's rmse: 104.574\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2248]\ttrain's rmse: 54.6517\tvalid's rmse: 104.573\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2249]\ttrain's rmse: 54.6474\tvalid's rmse: 104.573\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2250]\ttrain's rmse: 54.6419\tvalid's rmse: 104.573\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2251]\ttrain's rmse: 54.6341\tvalid's rmse: 104.572\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2252]\ttrain's rmse: 54.6224\tvalid's rmse: 104.572\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2253]\ttrain's rmse: 54.6179\tvalid's rmse: 104.572\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2254]\ttrain's rmse: 54.6079\tvalid's rmse: 104.571\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2255]\ttrain's rmse: 54.6022\tvalid's rmse: 104.571\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2256]\ttrain's rmse: 54.5941\tvalid's rmse: 104.571\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2257]\ttrain's rmse: 54.5882\tvalid's rmse: 104.571\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2258]\ttrain's rmse: 54.5835\tvalid's rmse: 104.571\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2259]\ttrain's rmse: 54.572\tvalid's rmse: 104.568\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2260]\ttrain's rmse: 54.5623\tvalid's rmse: 104.568\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2261]\ttrain's rmse: 54.5492\tvalid's rmse: 104.568\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2262]\ttrain's rmse: 54.5379\tvalid's rmse: 104.566\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2263]\ttrain's rmse: 54.5248\tvalid's rmse: 104.566\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2264]\ttrain's rmse: 54.518\tvalid's rmse: 104.566\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2265]\ttrain's rmse: 54.5067\tvalid's rmse: 104.566\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2266]\ttrain's rmse: 54.5018\tvalid's rmse: 104.565\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2267]\ttrain's rmse: 54.4966\tvalid's rmse: 104.564\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2268]\ttrain's rmse: 54.4897\tvalid's rmse: 104.564\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2269]\ttrain's rmse: 54.4803\tvalid's rmse: 104.564\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2270]\ttrain's rmse: 54.4743\tvalid's rmse: 104.563\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2271]\ttrain's rmse: 54.4697\tvalid's rmse: 104.564\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2272]\ttrain's rmse: 54.4611\tvalid's rmse: 104.563\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[2273]\ttrain's rmse: 54.4563\tvalid's rmse: 104.564\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2274]\ttrain's rmse: 54.442\tvalid's rmse: 104.563\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2275]\ttrain's rmse: 54.4359\tvalid's rmse: 104.564\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2276]\ttrain's rmse: 54.43\tvalid's rmse: 104.563\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2277]\ttrain's rmse: 54.421\tvalid's rmse: 104.564\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2278]\ttrain's rmse: 54.414\tvalid's rmse: 104.564\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2279]\ttrain's rmse: 54.4032\tvalid's rmse: 104.562\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2280]\ttrain's rmse: 54.3935\tvalid's rmse: 104.562\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2281]\ttrain's rmse: 54.3829\tvalid's rmse: 104.563\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2282]\ttrain's rmse: 54.3718\tvalid's rmse: 104.562\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2283]\ttrain's rmse: 54.3608\tvalid's rmse: 104.561\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2284]\ttrain's rmse: 54.3552\tvalid's rmse: 104.56\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 19\n",
      "[2285]\ttrain's rmse: 54.3493\tvalid's rmse: 104.559\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2286]\ttrain's rmse: 54.3366\tvalid's rmse: 104.558\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2287]\ttrain's rmse: 54.3278\tvalid's rmse: 104.557\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2288]\ttrain's rmse: 54.321\tvalid's rmse: 104.556\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2289]\ttrain's rmse: 54.3127\tvalid's rmse: 104.555\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[2290]\ttrain's rmse: 54.3072\tvalid's rmse: 104.555\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2291]\ttrain's rmse: 54.2969\tvalid's rmse: 104.555\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2292]\ttrain's rmse: 54.2889\tvalid's rmse: 104.554\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2293]\ttrain's rmse: 54.2782\tvalid's rmse: 104.553\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2294]\ttrain's rmse: 54.2729\tvalid's rmse: 104.553\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2295]\ttrain's rmse: 54.266\tvalid's rmse: 104.552\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2296]\ttrain's rmse: 54.259\tvalid's rmse: 104.55\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2297]\ttrain's rmse: 54.2525\tvalid's rmse: 104.55\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[2298]\ttrain's rmse: 54.2437\tvalid's rmse: 104.55\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2299]\ttrain's rmse: 54.2396\tvalid's rmse: 104.55\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 18\n",
      "[2300]\ttrain's rmse: 54.2309\tvalid's rmse: 104.55\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2301]\ttrain's rmse: 54.2253\tvalid's rmse: 104.55\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2302]\ttrain's rmse: 54.218\tvalid's rmse: 104.55\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2303]\ttrain's rmse: 54.2131\tvalid's rmse: 104.551\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2304]\ttrain's rmse: 54.204\tvalid's rmse: 104.551\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2305]\ttrain's rmse: 54.1986\tvalid's rmse: 104.55\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2306]\ttrain's rmse: 54.1867\tvalid's rmse: 104.549\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2307]\ttrain's rmse: 54.1794\tvalid's rmse: 104.549\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2308]\ttrain's rmse: 54.1679\tvalid's rmse: 104.548\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2309]\ttrain's rmse: 54.1595\tvalid's rmse: 104.546\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2310]\ttrain's rmse: 54.1523\tvalid's rmse: 104.546\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2311]\ttrain's rmse: 54.1477\tvalid's rmse: 104.546\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2312]\ttrain's rmse: 54.1412\tvalid's rmse: 104.544\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2313]\ttrain's rmse: 54.1362\tvalid's rmse: 104.545\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2314]\ttrain's rmse: 54.1296\tvalid's rmse: 104.543\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2315]\ttrain's rmse: 54.1233\tvalid's rmse: 104.542\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 23\n",
      "[2316]\ttrain's rmse: 54.1158\tvalid's rmse: 104.542\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2317]\ttrain's rmse: 54.1104\tvalid's rmse: 104.542\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2318]\ttrain's rmse: 54.0975\tvalid's rmse: 104.543\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2319]\ttrain's rmse: 54.0887\tvalid's rmse: 104.543\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 11\n",
      "[2320]\ttrain's rmse: 54.0833\tvalid's rmse: 104.542\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2321]\ttrain's rmse: 54.076\tvalid's rmse: 104.542\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2322]\ttrain's rmse: 54.0654\tvalid's rmse: 104.543\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2323]\ttrain's rmse: 54.0552\tvalid's rmse: 104.543\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2324]\ttrain's rmse: 54.0507\tvalid's rmse: 104.544\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2325]\ttrain's rmse: 54.0412\tvalid's rmse: 104.544\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2326]\ttrain's rmse: 54.0359\tvalid's rmse: 104.544\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2327]\ttrain's rmse: 54.0262\tvalid's rmse: 104.545\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2328]\ttrain's rmse: 54.0192\tvalid's rmse: 104.545\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 15\n",
      "[2329]\ttrain's rmse: 54.0103\tvalid's rmse: 104.546\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 20\n",
      "[2330]\ttrain's rmse: 54.0035\tvalid's rmse: 104.547\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2331]\ttrain's rmse: 53.9937\tvalid's rmse: 104.548\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2332]\ttrain's rmse: 53.9823\tvalid's rmse: 104.548\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2333]\ttrain's rmse: 53.972\tvalid's rmse: 104.548\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 17\n",
      "[2334]\ttrain's rmse: 53.9651\tvalid's rmse: 104.547\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2335]\ttrain's rmse: 53.9598\tvalid's rmse: 104.547\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2336]\ttrain's rmse: 53.9492\tvalid's rmse: 104.547\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 16\n",
      "[2337]\ttrain's rmse: 53.9394\tvalid's rmse: 104.547\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2338]\ttrain's rmse: 53.9316\tvalid's rmse: 104.546\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 12\n",
      "[2339]\ttrain's rmse: 53.9268\tvalid's rmse: 104.547\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 13\n",
      "[2340]\ttrain's rmse: 53.916\tvalid's rmse: 104.546\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 73 and depth = 14\n",
      "[2341]\ttrain's rmse: 53.9071\tvalid's rmse: 104.546\n",
      "Early stopping, best iteration is:\n",
      "[2321]\ttrain's rmse: 54.076\tvalid's rmse: 104.542\n"
     ]
    }
   ],
   "source": [
    "FIT_PARAMS_LGB = {\"num_boost_round\": 10000, \"early_stopping_rounds\": 1000,}\n",
    "\n",
    "evaluation_results  = {}  # to record evaluation results for plotting\n",
    "model = lgb.train(lgbm_params, \n",
    "                  lgb_train,\n",
    "                   **FIT_PARAMS_LGB,\n",
    "                  \n",
    "                  valid_names=['train', 'valid'], \n",
    "                  valid_sets=[lgb_train, lgb_valid],\n",
    "                 evals_result = evaluation_results,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06046994-8185-483b-9175-9b6d7232a165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=[30, 10])\n",
    "\n",
    "# Plot the log loss during training\n",
    "axs[0,0].plot(evaluation_results['train']['rmse'], label='Train')\n",
    "axs[0,0].plot(evaluation_results['valid']['rmse'], label='valid')\n",
    "axs[0,0].set_ylabel('RMSE')\n",
    "axs[0,0].set_xlabel('Boosting round')\n",
    "axs[0,0].set_title('Training performance')\n",
    "axs[0,0].legend()\n",
    "\n",
    "# Plot feature importance\n",
    "importances = pd.DataFrame({'features': train_X.columns, \n",
    "                            'importance': model.feature_importance()}).sort_values('importance', ascending=False).head(10)\n",
    "axs[1,0].bar(x=np.arange(len(importances)), height=importances['importance'])\n",
    "axs[1,0].set_xticks(np.arange(len(importances)))\n",
    "axs[1,0].set_xticklabels(importances['features'])\n",
    "axs[1,0].set_ylabel('Feature importance (# times used to split)')\n",
    "axs[1,0].set_title('Feature importance')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Plot feature importance\n",
    "pre_importances = pd.DataFrame({'features': train_X.columns, \n",
    "                            'importance': model.feature_importance(importance_type='gain')}).sort_values('importance', ascending=False)\n",
    "importances = pre_importances.head(10)\n",
    "axs[1,1].bar(x=np.arange(len(importances)), height=importances['importance'])\n",
    "axs[1,1].set_xticks(np.arange(len(importances)))\n",
    "axs[1,1].set_xticklabels(importances['features'])\n",
    "axs[1,1].set_ylabel('Feature importance (# times used to split)')\n",
    "axs[1,1].set_title('Feature importance (GAIN)')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1458a028-872e-4c76-88c5-7cde752e75bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>property_type_Guest suite</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>property_type_Camper/RV</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>property_type_Yurt</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>property_type_Earth House</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>property_type_Cave</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      features  importance\n",
       "87   property_type_Guest suite         0.0\n",
       "79     property_type_Camper/RV         0.0\n",
       "106         property_type_Yurt         0.0\n",
       "86   property_type_Earth House         0.0\n",
       "82          property_type_Cave         0.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_importances.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2d324f39-7fa8-4e6f-9512-3fe6b5d63775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bed_par_bedrooms</td>\n",
       "      <td>3.882873e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            features    importance\n",
       "14  bed_par_bedrooms  3.882873e+08"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_importances[pre_importances['features'] == 'bed_par_bedrooms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dec61ad5-5473-415e-9442-290b45317f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x900 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_n=50\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "_df = pd.DataFrame()\n",
    "_df['feature_importance'] = model.feature_importance(importance_type='gain')\n",
    "_df['column'] = train_X.columns\n",
    "feature_importance_df = pd.concat([feature_importance_df, _df], axis=0, ignore_index=True)\n",
    "\n",
    "pre_order = feature_importance_df.groupby('column').sum()[['feature_importance']].sort_values('feature_importance', ascending=False)\n",
    "order = pre_order.index[:top_n]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, max(6, len(order) * .25)))\n",
    "sns.boxenplot(data=feature_importance_df,\n",
    "              x='feature_importance',\n",
    "              y='column',\n",
    "              order=order,\n",
    "              ax=ax,\n",
    "              palette='viridis',\n",
    "              orient='h')\n",
    "ax.tick_params(axis='x', rotation=90)\n",
    "ax.tick_params(axis='x', rotation=90)\n",
    "ax.grid()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37471efc-06ab-4019-a7fa-0ddf8bb7a4d7",
   "metadata": {},
   "source": [
    "# テストデータ(submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb958fb9-b9d3-46cc-8d4b-f44a202044bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>amenities</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>city</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>description</th>\n",
       "      <th>first_review</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_since</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>last_review</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>property_type</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>room_type</th>\n",
       "      <th>thumbnail_url</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>{TV,\"Cable TV\",\"Wireless Internet\",\"Air condit...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>strict</td>\n",
       "      <td>Boston</td>\n",
       "      <td>t</td>\n",
       "      <td>Feel free to book INSTANTLY. You can check-in ...</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>100%</td>\n",
       "      <td>2016-08-23</td>\n",
       "      <td>t</td>\n",
       "      <td>2017-09-25</td>\n",
       "      <td>42.359278</td>\n",
       "      <td>-71.069962</td>\n",
       "      <td>Gorgeous 2BR/2BA Duplex in Beacon Hill</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>58</td>\n",
       "      <td>House</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>https://a0.muscache.com/im/pictures/7e4808b4-5...</td>\n",
       "      <td>02114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>{TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>The guest house is close to: Equinox West Holl...</td>\n",
       "      <td>2016-08-17</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>100%</td>\n",
       "      <td>2014-09-03</td>\n",
       "      <td>f</td>\n",
       "      <td>2017-05-02</td>\n",
       "      <td>34.084747</td>\n",
       "      <td>-118.367355</td>\n",
       "      <td>Luxury 1 Bedroom West Hollywood City Center</td>\n",
       "      <td>West Hollywood</td>\n",
       "      <td>4</td>\n",
       "      <td>Guesthouse</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>https://a0.muscache.com/im/pictures/5392fbd6-6...</td>\n",
       "      <td>90046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{TV,\"Wireless Internet\",\"Air conditioning\",Kit...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>flexible</td>\n",
       "      <td>NYC</td>\n",
       "      <td>f</td>\n",
       "      <td>Private room in a three bedroom apartment in N...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>100%</td>\n",
       "      <td>2012-10-17</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.720541</td>\n",
       "      <td>-73.959192</td>\n",
       "      <td>Bedroom with Patio in Prime Williamsburg Locat...</td>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>0</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private room</td>\n",
       "      <td>https://a0.muscache.com/im/pictures/544d3b89-d...</td>\n",
       "      <td>11249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>{TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>strict</td>\n",
       "      <td>NYC</td>\n",
       "      <td>f</td>\n",
       "      <td>The apartment is located in historic Bed Stuy ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-23</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.681117</td>\n",
       "      <td>-73.944091</td>\n",
       "      <td>Cozy apartment in Brooklyn</td>\n",
       "      <td>Bedford-Stuyvesant</td>\n",
       "      <td>0</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>https://a0.muscache.com/im/pictures/26baf7ba-0...</td>\n",
       "      <td>11216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>{TV,Internet,\"Wireless Internet\",\"Air conditio...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>strict</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>Our cozy, pet friendly one bedroom apartment/l...</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>100%</td>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>f</td>\n",
       "      <td>2016-09-11</td>\n",
       "      <td>34.150995</td>\n",
       "      <td>-118.409359</td>\n",
       "      <td>Cozy, sunny, pet friendly loft/apt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>Loft</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>https://a0.muscache.com/im/pictures/86107545/9...</td>\n",
       "      <td>91604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accommodates                                          amenities  bathrooms  \\\n",
       "0             6  {TV,\"Cable TV\",\"Wireless Internet\",\"Air condit...        2.0   \n",
       "1             3  {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...        1.0   \n",
       "2             2  {TV,\"Wireless Internet\",\"Air conditioning\",Kit...        1.0   \n",
       "3             4  {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...        1.0   \n",
       "4             3  {TV,Internet,\"Wireless Internet\",\"Air conditio...        1.5   \n",
       "\n",
       "   bed_type  bedrooms  beds cancellation_policy    city cleaning_fee  \\\n",
       "0  Real Bed       2.0   2.0              strict  Boston            t   \n",
       "1  Real Bed       1.0   1.0            moderate      LA            t   \n",
       "2  Real Bed       0.0   1.0            flexible     NYC            f   \n",
       "3  Real Bed       1.0   2.0              strict     NYC            f   \n",
       "4  Real Bed       1.0   2.0              strict      LA            t   \n",
       "\n",
       "                                         description first_review  \\\n",
       "0  Feel free to book INSTANTLY. You can check-in ...   2017-01-09   \n",
       "1  The guest house is close to: Equinox West Holl...   2016-08-17   \n",
       "2  Private room in a three bedroom apartment in N...          NaN   \n",
       "3  The apartment is located in historic Bed Stuy ...          NaN   \n",
       "4  Our cozy, pet friendly one bedroom apartment/l...   2015-08-01   \n",
       "\n",
       "  host_has_profile_pic host_identity_verified host_response_rate  host_since  \\\n",
       "0                    t                      f               100%  2016-08-23   \n",
       "1                    t                      t               100%  2014-09-03   \n",
       "2                    t                      t               100%  2012-10-17   \n",
       "3                    t                      t                NaN  2013-01-23   \n",
       "4                    t                      t               100%  2014-12-28   \n",
       "\n",
       "  instant_bookable last_review   latitude   longitude  \\\n",
       "0                t  2017-09-25  42.359278  -71.069962   \n",
       "1                f  2017-05-02  34.084747 -118.367355   \n",
       "2                f         NaN  40.720541  -73.959192   \n",
       "3                f         NaN  40.681117  -73.944091   \n",
       "4                f  2016-09-11  34.150995 -118.409359   \n",
       "\n",
       "                                                name       neighbourhood  \\\n",
       "0             Gorgeous 2BR/2BA Duplex in Beacon Hill         Beacon Hill   \n",
       "1        Luxury 1 Bedroom West Hollywood City Center      West Hollywood   \n",
       "2  Bedroom with Patio in Prime Williamsburg Locat...        Williamsburg   \n",
       "3                         Cozy apartment in Brooklyn  Bedford-Stuyvesant   \n",
       "4                 Cozy, sunny, pet friendly loft/apt                 NaN   \n",
       "\n",
       "   number_of_reviews property_type  review_scores_rating        room_type  \\\n",
       "0                 58         House                  90.0  Entire home/apt   \n",
       "1                  4    Guesthouse                 100.0  Entire home/apt   \n",
       "2                  0     Apartment                   NaN     Private room   \n",
       "3                  0     Apartment                   NaN  Entire home/apt   \n",
       "4                  6          Loft                  92.0  Entire home/apt   \n",
       "\n",
       "                                       thumbnail_url  zipcode  \n",
       "0  https://a0.muscache.com/im/pictures/7e4808b4-5...    02114  \n",
       "1  https://a0.muscache.com/im/pictures/5392fbd6-6...    90046  \n",
       "2  https://a0.muscache.com/im/pictures/544d3b89-d...  11249.0  \n",
       "3  https://a0.muscache.com/im/pictures/26baf7ba-0...    11216  \n",
       "4  https://a0.muscache.com/im/pictures/86107545/9...    91604  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2430b04-0f74-435c-83d6-d249896dc807",
   "metadata": {},
   "source": [
    "## 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99b0181-8342-4526-b4a1-e8bfd61e4249",
   "metadata": {},
   "source": [
    "### 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33756209-60c0-4444-9866-3d8a06ecb4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_amenities_list : 更新\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 86/86 [00:01<00:00, 77.71it/s]\n"
     ]
    }
   ],
   "source": [
    "test_X, _ = gather_function.preprocessing(test, max_amenities_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d555be36-1c2a-490f-ba93-70ac8541ec47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>city</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>property_type</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>room_type</th>\n",
       "      <th>thumbnail_url</th>\n",
       "      <th>bathrooms_par_1</th>\n",
       "      <th>bedrooms_par_1</th>\n",
       "      <th>beds_par_1</th>\n",
       "      <th>bed_par_bedrooms</th>\n",
       "      <th>latitude_int</th>\n",
       "      <th>longitude_int</th>\n",
       "      <th>review_score_total</th>\n",
       "      <th>review_score_weight</th>\n",
       "      <th>amenities_count</th>\n",
       "      <th>TV</th>\n",
       "      <th>Cable TV</th>\n",
       "      <th>Wireless Internet</th>\n",
       "      <th>Air conditioning</th>\n",
       "      <th>Kitchen</th>\n",
       "      <th>Free parking on premises</th>\n",
       "      <th>Pets allowed</th>\n",
       "      <th>Breakfast</th>\n",
       "      <th>Elevator</th>\n",
       "      <th>Hot tub</th>\n",
       "      <th>Indoor fireplace</th>\n",
       "      <th>Heating</th>\n",
       "      <th>Family/kid friendly</th>\n",
       "      <th>Suitable for events</th>\n",
       "      <th>Washer</th>\n",
       "      <th>Dryer</th>\n",
       "      <th>Smoke detector</th>\n",
       "      <th>Carbon monoxide detector</th>\n",
       "      <th>First aid kit</th>\n",
       "      <th>Safety card</th>\n",
       "      <th>Fire extinguisher</th>\n",
       "      <th>Essentials</th>\n",
       "      <th>Shampoo</th>\n",
       "      <th>Lock on bedroom door</th>\n",
       "      <th>Hangers</th>\n",
       "      <th>Hair dryer</th>\n",
       "      <th>Iron</th>\n",
       "      <th>Laptop friendly workspace</th>\n",
       "      <th>Self Check-In</th>\n",
       "      <th>Keypad</th>\n",
       "      <th>Private entrance</th>\n",
       "      <th>Baby monitor</th>\n",
       "      <th>Bathtub</th>\n",
       "      <th>Baby bath</th>\n",
       "      <th>Changing table</th>\n",
       "      <th>Children’s books and toys</th>\n",
       "      <th>Window guards</th>\n",
       "      <th>Table corner guards</th>\n",
       "      <th>Fireplace guards</th>\n",
       "      <th>Babysitter recommendations</th>\n",
       "      <th>Crib</th>\n",
       "      <th>Room-darkening shades</th>\n",
       "      <th>Game console</th>\n",
       "      <th>Hot water</th>\n",
       "      <th>Bed linens</th>\n",
       "      <th>Extra pillows and blankets</th>\n",
       "      <th>Ethernet connection</th>\n",
       "      <th>Pocket wifi</th>\n",
       "      <th>Microwave</th>\n",
       "      <th>Coffee maker</th>\n",
       "      <th>Refrigerator</th>\n",
       "      <th>Dishwasher</th>\n",
       "      <th>Dishes and silverware</th>\n",
       "      <th>Cooking basics</th>\n",
       "      <th>Oven</th>\n",
       "      <th>Stove</th>\n",
       "      <th>EV charger</th>\n",
       "      <th>Single level home</th>\n",
       "      <th>BBQ grill</th>\n",
       "      <th>Patio or balcony</th>\n",
       "      <th>Garden or backyard</th>\n",
       "      <th>Beach essentials</th>\n",
       "      <th>Luggage dropoff allowed</th>\n",
       "      <th>Long term stays allowed</th>\n",
       "      <th>Wide hallway clearance</th>\n",
       "      <th>Step-free access</th>\n",
       "      <th>Wide doorway</th>\n",
       "      <th>Flat</th>\n",
       "      <th>smooth pathway to front door</th>\n",
       "      <th>Well-lit path to entrance</th>\n",
       "      <th>Disabled parking spot</th>\n",
       "      <th>Wide clearance to bed</th>\n",
       "      <th>Accessible-height bed</th>\n",
       "      <th>Fixed grab bars for shower &amp; toilet</th>\n",
       "      <th>Bathtub with shower chair</th>\n",
       "      <th>Roll-in shower with chair</th>\n",
       "      <th>Accessible-height toilet</th>\n",
       "      <th>Wide clearance to shower &amp; toilet</th>\n",
       "      <th>Wide entryway</th>\n",
       "      <th>Waterfront</th>\n",
       "      <th>Handheld shower head</th>\n",
       "      <th>rare_amenities_count</th>\n",
       "      <th>description_word_count</th>\n",
       "      <th>host_response_rate_weight</th>\n",
       "      <th>first_review_Year</th>\n",
       "      <th>first_review_Month</th>\n",
       "      <th>first_review_Day</th>\n",
       "      <th>BusinessOld</th>\n",
       "      <th>host_since_Year</th>\n",
       "      <th>host_since_Month</th>\n",
       "      <th>host_since_Day</th>\n",
       "      <th>BusinessOld2</th>\n",
       "      <th>first_reviewOld</th>\n",
       "      <th>last_review_Year</th>\n",
       "      <th>last_review_Month</th>\n",
       "      <th>last_review_Day</th>\n",
       "      <th>BusinessOld3</th>\n",
       "      <th>BusinessUpdate</th>\n",
       "      <th>BusinessPeriod</th>\n",
       "      <th>thumbnail_url_str</th>\n",
       "      <th>zipcode_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>strict</td>\n",
       "      <td>Boston</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>100</td>\n",
       "      <td>t</td>\n",
       "      <td>42.359278</td>\n",
       "      <td>-71.069962</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>58</td>\n",
       "      <td>House</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>-71</td>\n",
       "      <td>5220.0</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>1000</td>\n",
       "      <td>63.291139</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2975.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3095.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3234.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>moderate</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>100</td>\n",
       "      <td>f</td>\n",
       "      <td>34.084747</td>\n",
       "      <td>-118.367355</td>\n",
       "      <td>West Hollywood</td>\n",
       "      <td>4</td>\n",
       "      <td>Guesthouse</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>-118</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>1000</td>\n",
       "      <td>96.153846</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2830.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2375.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3088.0</td>\n",
       "      <td>1703.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>1</td>\n",
       "      <td>90046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>flexible</td>\n",
       "      <td>NYC</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>100</td>\n",
       "      <td>f</td>\n",
       "      <td>40.720541</td>\n",
       "      <td>-73.959192</td>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>0</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>-73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>11249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>strict</td>\n",
       "      <td>NYC</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>40.681117</td>\n",
       "      <td>-73.944091</td>\n",
       "      <td>Bedford-Stuyvesant</td>\n",
       "      <td>0</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40</td>\n",
       "      <td>-73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>11216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>strict</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>100</td>\n",
       "      <td>f</td>\n",
       "      <td>34.150995</td>\n",
       "      <td>-118.409359</td>\n",
       "      <td>Na</td>\n",
       "      <td>6</td>\n",
       "      <td>Loft</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34</td>\n",
       "      <td>-118</td>\n",
       "      <td>552.0</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>14</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>898</td>\n",
       "      <td>94.339623</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2448.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2491.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2855.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>1</td>\n",
       "      <td>91604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accommodates  bathrooms  bed_type  bedrooms  beds cancellation_policy  \\\n",
       "0             6          2  Real Bed         2     2              strict   \n",
       "1             3          1  Real Bed         1     1            moderate   \n",
       "2             2          1  Real Bed         0     1            flexible   \n",
       "3             4          1  Real Bed         1     2              strict   \n",
       "4             3          1  Real Bed         1     2              strict   \n",
       "\n",
       "     city cleaning_fee host_has_profile_pic host_identity_verified  \\\n",
       "0  Boston            t                    t                      f   \n",
       "1      LA            t                    t                      t   \n",
       "2     NYC            f                    t                      t   \n",
       "3     NYC            f                    t                      t   \n",
       "4      LA            t                    t                      t   \n",
       "\n",
       "   host_response_rate instant_bookable   latitude   longitude  \\\n",
       "0                 100                t  42.359278  -71.069962   \n",
       "1                 100                f  34.084747 -118.367355   \n",
       "2                 100                f  40.720541  -73.959192   \n",
       "3                   0                f  40.681117  -73.944091   \n",
       "4                 100                f  34.150995 -118.409359   \n",
       "\n",
       "        neighbourhood  number_of_reviews property_type  review_scores_rating  \\\n",
       "0         Beacon Hill                 58         House                  90.0   \n",
       "1      West Hollywood                  4    Guesthouse                 100.0   \n",
       "2        Williamsburg                  0     Apartment                   NaN   \n",
       "3  Bedford-Stuyvesant                  0     Apartment                   NaN   \n",
       "4                  Na                  6          Loft                  92.0   \n",
       "\n",
       "         room_type  thumbnail_url  bathrooms_par_1  bedrooms_par_1  \\\n",
       "0  Entire home/apt            1.0         0.333333        0.333333   \n",
       "1  Entire home/apt            1.0         0.333333        0.333333   \n",
       "2     Private room            1.0         0.500000        0.000000   \n",
       "3  Entire home/apt            1.0         0.250000        0.250000   \n",
       "4  Entire home/apt            1.0         0.333333        0.333333   \n",
       "\n",
       "   beds_par_1  bed_par_bedrooms  latitude_int  longitude_int  \\\n",
       "0    0.333333               1.0            42            -71   \n",
       "1    0.333333               1.0            34           -118   \n",
       "2    0.500000               0.0            40            -73   \n",
       "3    0.500000               2.0            40            -73   \n",
       "4    0.666667               2.0            34           -118   \n",
       "\n",
       "   review_score_total  review_score_weight  amenities_count    TV Cable TV  \\\n",
       "0              5220.0             0.569620               21  True     True   \n",
       "1               400.0             0.961538               20  True     True   \n",
       "2                 0.0             0.000000               10  True    False   \n",
       "3                 0.0             0.000000               17  True     True   \n",
       "4               552.0             0.867925               14  True    False   \n",
       "\n",
       "  Wireless Internet Air conditioning Kitchen Free parking on premises  \\\n",
       "0              True             True    True                    False   \n",
       "1              True             True    True                     True   \n",
       "2              True             True    True                    False   \n",
       "3              True             True    True                    False   \n",
       "4              True             True    True                     True   \n",
       "\n",
       "  Pets allowed Breakfast Elevator Hot tub Indoor fireplace Heating  \\\n",
       "0        False     False    False   False             True    True   \n",
       "1        False     False    False   False            False    True   \n",
       "2        False     False    False   False            False    True   \n",
       "3        False     False    False   False            False    True   \n",
       "4         True     False    False   False            False    True   \n",
       "\n",
       "  Family/kid friendly Suitable for events Washer  Dryer Smoke detector  \\\n",
       "0                True               False   True   True           True   \n",
       "1               False               False  False  False           True   \n",
       "2                True               False   True   True          False   \n",
       "3               False               False  False  False           True   \n",
       "4                True               False   True   True           True   \n",
       "\n",
       "  Carbon monoxide detector First aid kit Safety card Fire extinguisher  \\\n",
       "0                     True         False       False             False   \n",
       "1                     True         False       False              True   \n",
       "2                    False         False       False             False   \n",
       "3                     True         False       False             False   \n",
       "4                     True         False       False              True   \n",
       "\n",
       "  Essentials Shampoo Lock on bedroom door Hangers Hair dryer   Iron  \\\n",
       "0       True    True                 True    True       True   True   \n",
       "1       True    True                False    True       True   True   \n",
       "2       True   False                False    True      False  False   \n",
       "3       True    True                False    True       True   True   \n",
       "4      False   False                False   False      False  False   \n",
       "\n",
       "  Laptop friendly workspace Self Check-In Keypad Private entrance  \\\n",
       "0                      True          True  False            False   \n",
       "1                      True         False  False            False   \n",
       "2                     False         False  False            False   \n",
       "3                      True         False  False            False   \n",
       "4                     False         False  False            False   \n",
       "\n",
       "  Baby monitor Bathtub Baby bath Changing table Children’s books and toys  \\\n",
       "0        False   False     False          False                     False   \n",
       "1        False   False     False          False                     False   \n",
       "2        False   False     False          False                     False   \n",
       "3        False   False     False          False                     False   \n",
       "4        False   False     False          False                     False   \n",
       "\n",
       "  Window guards Table corner guards Fireplace guards  \\\n",
       "0         False               False            False   \n",
       "1         False               False            False   \n",
       "2         False               False            False   \n",
       "3         False               False            False   \n",
       "4         False               False            False   \n",
       "\n",
       "  Babysitter recommendations   Crib Room-darkening shades Game console  \\\n",
       "0                      False  False                 False        False   \n",
       "1                      False  False                 False        False   \n",
       "2                      False  False                 False        False   \n",
       "3                      False  False                 False        False   \n",
       "4                      False  False                 False        False   \n",
       "\n",
       "  Hot water Bed linens Extra pillows and blankets Ethernet connection  \\\n",
       "0     False      False                      False               False   \n",
       "1     False      False                      False               False   \n",
       "2     False      False                      False               False   \n",
       "3     False      False                      False               False   \n",
       "4     False      False                      False               False   \n",
       "\n",
       "  Pocket wifi Microwave Coffee maker Refrigerator Dishwasher  \\\n",
       "0       False     False        False        False      False   \n",
       "1       False     False        False        False      False   \n",
       "2       False     False        False        False      False   \n",
       "3       False     False        False        False      False   \n",
       "4       False     False        False        False      False   \n",
       "\n",
       "  Dishes and silverware Cooking basics   Oven  Stove EV charger  \\\n",
       "0                 False          False  False  False      False   \n",
       "1                 False          False  False  False      False   \n",
       "2                 False          False  False  False      False   \n",
       "3                 False          False  False  False      False   \n",
       "4                 False          False  False  False      False   \n",
       "\n",
       "  Single level home BBQ grill Patio or balcony Garden or backyard  \\\n",
       "0             False     False            False              False   \n",
       "1             False     False            False              False   \n",
       "2             False     False            False              False   \n",
       "3             False     False            False              False   \n",
       "4             False     False            False              False   \n",
       "\n",
       "  Beach essentials Luggage dropoff allowed Long term stays allowed  \\\n",
       "0            False                   False                   False   \n",
       "1            False                   False                   False   \n",
       "2            False                   False                   False   \n",
       "3            False                   False                   False   \n",
       "4            False                   False                   False   \n",
       "\n",
       "  Wide hallway clearance Step-free access Wide doorway   Flat  \\\n",
       "0                  False            False        False  False   \n",
       "1                  False            False        False  False   \n",
       "2                  False            False        False  False   \n",
       "3                  False            False        False  False   \n",
       "4                  False            False        False  False   \n",
       "\n",
       "   smooth pathway to front door Well-lit path to entrance  \\\n",
       "0                         False                     False   \n",
       "1                         False                     False   \n",
       "2                         False                     False   \n",
       "3                         False                     False   \n",
       "4                         False                     False   \n",
       "\n",
       "  Disabled parking spot Wide clearance to bed Accessible-height bed  \\\n",
       "0                 False                 False                 False   \n",
       "1                 False                 False                 False   \n",
       "2                 False                 False                 False   \n",
       "3                 False                 False                 False   \n",
       "4                 False                 False                 False   \n",
       "\n",
       "  Fixed grab bars for shower & toilet Bathtub with shower chair  \\\n",
       "0                               False                     False   \n",
       "1                               False                     False   \n",
       "2                               False                     False   \n",
       "3                               False                     False   \n",
       "4                               False                     False   \n",
       "\n",
       "  Roll-in shower with chair Accessible-height toilet  \\\n",
       "0                     False                    False   \n",
       "1                     False                    False   \n",
       "2                     False                    False   \n",
       "3                     False                    False   \n",
       "4                     False                    False   \n",
       "\n",
       "  Wide clearance to shower & toilet Wide entryway Waterfront  \\\n",
       "0                             False         False      False   \n",
       "1                             False         False      False   \n",
       "2                             False         False      False   \n",
       "3                             False         False      False   \n",
       "4                             False         False      False   \n",
       "\n",
       "  Handheld shower head  rare_amenities_count  description_word_count  \\\n",
       "0                False                    24                    1000   \n",
       "1                False                    24                    1000   \n",
       "2                False                     6                    1000   \n",
       "3                False                    16                     220   \n",
       "4                False                    16                     898   \n",
       "\n",
       "   host_response_rate_weight  first_review_Year  first_review_Month  \\\n",
       "0                  63.291139             2017.0                 1.0   \n",
       "1                  96.153846             2016.0                 8.0   \n",
       "2                 100.000000                NaN                 NaN   \n",
       "3                   0.000000                NaN                 NaN   \n",
       "4                  94.339623             2015.0                 8.0   \n",
       "\n",
       "   first_review_Day  BusinessOld  host_since_Year  host_since_Month  \\\n",
       "0               9.0       2975.0           2016.0               8.0   \n",
       "1              17.0       2830.0           2014.0               9.0   \n",
       "2               NaN          NaN           2012.0              10.0   \n",
       "3               NaN          NaN           2013.0               1.0   \n",
       "4               1.0       2448.0           2014.0              12.0   \n",
       "\n",
       "   host_since_Day  BusinessOld2  first_reviewOld  last_review_Year  \\\n",
       "0            23.0        3095.0            139.0            2017.0   \n",
       "1             3.0        2375.0            714.0            2017.0   \n",
       "2            17.0        1689.0              NaN               NaN   \n",
       "3            23.0        1787.0              NaN               NaN   \n",
       "4            28.0        2491.0            216.0            2016.0   \n",
       "\n",
       "   last_review_Month  last_review_Day  BusinessOld3  BusinessUpdate  \\\n",
       "0                9.0             25.0        3234.0          1557.0   \n",
       "1                5.0              2.0        3088.0          1703.0   \n",
       "2                NaN              NaN           NaN             NaN   \n",
       "3                NaN              NaN           NaN             NaN   \n",
       "4                9.0             11.0        2855.0          1936.0   \n",
       "\n",
       "   BusinessPeriod thumbnail_url_str  zipcode_int  \n",
       "0           259.0                 1         2114  \n",
       "1           258.0                 1        90046  \n",
       "2             NaN                 1        11249  \n",
       "3             NaN                 1        11216  \n",
       "4           407.0                 1        91604  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871bbbbe-2d23-4fd4-99d6-305b833c8b63",
   "metadata": {},
   "source": [
    "### 対数化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17331a80-2038-4ff3-8f57-42849cf37353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>city</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>property_type</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>room_type</th>\n",
       "      <th>thumbnail_url</th>\n",
       "      <th>bathrooms_par_1</th>\n",
       "      <th>bedrooms_par_1</th>\n",
       "      <th>beds_par_1</th>\n",
       "      <th>bed_par_bedrooms</th>\n",
       "      <th>latitude_int</th>\n",
       "      <th>longitude_int</th>\n",
       "      <th>review_score_total</th>\n",
       "      <th>review_score_weight</th>\n",
       "      <th>amenities_count</th>\n",
       "      <th>TV</th>\n",
       "      <th>Cable TV</th>\n",
       "      <th>Wireless Internet</th>\n",
       "      <th>Air conditioning</th>\n",
       "      <th>Kitchen</th>\n",
       "      <th>Free parking on premises</th>\n",
       "      <th>Pets allowed</th>\n",
       "      <th>Breakfast</th>\n",
       "      <th>Elevator</th>\n",
       "      <th>Hot tub</th>\n",
       "      <th>Indoor fireplace</th>\n",
       "      <th>Heating</th>\n",
       "      <th>Family/kid friendly</th>\n",
       "      <th>Suitable for events</th>\n",
       "      <th>Washer</th>\n",
       "      <th>Dryer</th>\n",
       "      <th>Smoke detector</th>\n",
       "      <th>Carbon monoxide detector</th>\n",
       "      <th>First aid kit</th>\n",
       "      <th>Safety card</th>\n",
       "      <th>Fire extinguisher</th>\n",
       "      <th>Essentials</th>\n",
       "      <th>Shampoo</th>\n",
       "      <th>Lock on bedroom door</th>\n",
       "      <th>Hangers</th>\n",
       "      <th>Hair dryer</th>\n",
       "      <th>Iron</th>\n",
       "      <th>Laptop friendly workspace</th>\n",
       "      <th>Self Check-In</th>\n",
       "      <th>Keypad</th>\n",
       "      <th>Private entrance</th>\n",
       "      <th>Baby monitor</th>\n",
       "      <th>Bathtub</th>\n",
       "      <th>Baby bath</th>\n",
       "      <th>Changing table</th>\n",
       "      <th>Children’s books and toys</th>\n",
       "      <th>Window guards</th>\n",
       "      <th>Table corner guards</th>\n",
       "      <th>Fireplace guards</th>\n",
       "      <th>Babysitter recommendations</th>\n",
       "      <th>Crib</th>\n",
       "      <th>Room-darkening shades</th>\n",
       "      <th>Game console</th>\n",
       "      <th>Hot water</th>\n",
       "      <th>Bed linens</th>\n",
       "      <th>Extra pillows and blankets</th>\n",
       "      <th>Ethernet connection</th>\n",
       "      <th>Pocket wifi</th>\n",
       "      <th>Microwave</th>\n",
       "      <th>Coffee maker</th>\n",
       "      <th>Refrigerator</th>\n",
       "      <th>Dishwasher</th>\n",
       "      <th>Dishes and silverware</th>\n",
       "      <th>Cooking basics</th>\n",
       "      <th>Oven</th>\n",
       "      <th>Stove</th>\n",
       "      <th>EV charger</th>\n",
       "      <th>Single level home</th>\n",
       "      <th>BBQ grill</th>\n",
       "      <th>Patio or balcony</th>\n",
       "      <th>Garden or backyard</th>\n",
       "      <th>Beach essentials</th>\n",
       "      <th>Luggage dropoff allowed</th>\n",
       "      <th>Long term stays allowed</th>\n",
       "      <th>Wide hallway clearance</th>\n",
       "      <th>Step-free access</th>\n",
       "      <th>Wide doorway</th>\n",
       "      <th>Flat</th>\n",
       "      <th>smooth pathway to front door</th>\n",
       "      <th>Well-lit path to entrance</th>\n",
       "      <th>Disabled parking spot</th>\n",
       "      <th>Wide clearance to bed</th>\n",
       "      <th>Accessible-height bed</th>\n",
       "      <th>Fixed grab bars for shower &amp; toilet</th>\n",
       "      <th>Bathtub with shower chair</th>\n",
       "      <th>Roll-in shower with chair</th>\n",
       "      <th>Accessible-height toilet</th>\n",
       "      <th>Wide clearance to shower &amp; toilet</th>\n",
       "      <th>Wide entryway</th>\n",
       "      <th>Waterfront</th>\n",
       "      <th>Handheld shower head</th>\n",
       "      <th>rare_amenities_count</th>\n",
       "      <th>description_word_count</th>\n",
       "      <th>host_response_rate_weight</th>\n",
       "      <th>first_review_Year</th>\n",
       "      <th>first_review_Month</th>\n",
       "      <th>first_review_Day</th>\n",
       "      <th>BusinessOld</th>\n",
       "      <th>host_since_Year</th>\n",
       "      <th>host_since_Month</th>\n",
       "      <th>host_since_Day</th>\n",
       "      <th>BusinessOld2</th>\n",
       "      <th>first_reviewOld</th>\n",
       "      <th>last_review_Year</th>\n",
       "      <th>last_review_Month</th>\n",
       "      <th>last_review_Day</th>\n",
       "      <th>BusinessOld3</th>\n",
       "      <th>BusinessUpdate</th>\n",
       "      <th>BusinessPeriod</th>\n",
       "      <th>thumbnail_url_str</th>\n",
       "      <th>zipcode_int</th>\n",
       "      <th>Log_beds_par_1</th>\n",
       "      <th>Log_bathrooms_par_1</th>\n",
       "      <th>Log_bathrooms</th>\n",
       "      <th>Log_review_score_total</th>\n",
       "      <th>Log_number_of_reviews</th>\n",
       "      <th>Log_beds</th>\n",
       "      <th>Log_accommodates</th>\n",
       "      <th>Log_bedrooms</th>\n",
       "      <th>Log_bedrooms_par_1</th>\n",
       "      <th>Log_rare_amenities_count</th>\n",
       "      <th>Log_amenities_count</th>\n",
       "      <th>Log_latitude</th>\n",
       "      <th>Log_host_response_rate_weight</th>\n",
       "      <th>Log_review_score_weight</th>\n",
       "      <th>Log_description_word_count</th>\n",
       "      <th>Log_host_response_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>strict</td>\n",
       "      <td>Boston</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>100</td>\n",
       "      <td>t</td>\n",
       "      <td>42.359278</td>\n",
       "      <td>-71.069962</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>58</td>\n",
       "      <td>House</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>-71</td>\n",
       "      <td>5220.0</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>1000</td>\n",
       "      <td>63.291139</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2975.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3095.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3234.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2114</td>\n",
       "      <td>-1.376763</td>\n",
       "      <td>-0.482101</td>\n",
       "      <td>1.687346</td>\n",
       "      <td>1.200628</td>\n",
       "      <td>1.325752</td>\n",
       "      <td>0.813030</td>\n",
       "      <td>1.393625</td>\n",
       "      <td>0.995675</td>\n",
       "      <td>-0.426083</td>\n",
       "      <td>0.639636</td>\n",
       "      <td>0.538261</td>\n",
       "      <td>1.592091</td>\n",
       "      <td>0.251120</td>\n",
       "      <td>-0.382477</td>\n",
       "      <td>0.782058</td>\n",
       "      <td>0.655069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>moderate</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>100</td>\n",
       "      <td>f</td>\n",
       "      <td>34.084747</td>\n",
       "      <td>-118.367355</td>\n",
       "      <td>West Hollywood</td>\n",
       "      <td>4</td>\n",
       "      <td>Guesthouse</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>-118</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>1000</td>\n",
       "      <td>96.153846</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2830.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2375.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3088.0</td>\n",
       "      <td>1703.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>1</td>\n",
       "      <td>90046</td>\n",
       "      <td>-1.376763</td>\n",
       "      <td>-0.482101</td>\n",
       "      <td>-0.301546</td>\n",
       "      <td>-0.006598</td>\n",
       "      <td>-0.173313</td>\n",
       "      <td>-0.716402</td>\n",
       "      <td>0.286632</td>\n",
       "      <td>-0.180486</td>\n",
       "      <td>-0.426083</td>\n",
       "      <td>0.639636</td>\n",
       "      <td>0.401933</td>\n",
       "      <td>-1.346662</td>\n",
       "      <td>0.858591</td>\n",
       "      <td>1.150064</td>\n",
       "      <td>0.782058</td>\n",
       "      <td>0.655069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>flexible</td>\n",
       "      <td>NYC</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>100</td>\n",
       "      <td>f</td>\n",
       "      <td>40.720541</td>\n",
       "      <td>-73.959192</td>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>0</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>-73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>11249</td>\n",
       "      <td>-0.250963</td>\n",
       "      <td>0.298715</td>\n",
       "      <td>-0.301546</td>\n",
       "      <td>-1.511131</td>\n",
       "      <td>-1.375018</td>\n",
       "      <td>-0.716402</td>\n",
       "      <td>-0.452805</td>\n",
       "      <td>-2.225104</td>\n",
       "      <td>-2.104475</td>\n",
       "      <td>-1.670391</td>\n",
       "      <td>-1.117572</td>\n",
       "      <td>0.708330</td>\n",
       "      <td>0.924450</td>\n",
       "      <td>-1.535764</td>\n",
       "      <td>0.782058</td>\n",
       "      <td>0.655069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>strict</td>\n",
       "      <td>NYC</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>40.681117</td>\n",
       "      <td>-73.944091</td>\n",
       "      <td>Bedford-Stuyvesant</td>\n",
       "      <td>0</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40</td>\n",
       "      <td>-73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>11216</td>\n",
       "      <td>-0.250963</td>\n",
       "      <td>-0.988289</td>\n",
       "      <td>-0.301546</td>\n",
       "      <td>-1.511131</td>\n",
       "      <td>-1.375018</td>\n",
       "      <td>0.813030</td>\n",
       "      <td>0.775040</td>\n",
       "      <td>-0.180486</td>\n",
       "      <td>-0.792371</td>\n",
       "      <td>-0.233947</td>\n",
       "      <td>-0.021079</td>\n",
       "      <td>0.689395</td>\n",
       "      <td>-1.609670</td>\n",
       "      <td>-1.535764</td>\n",
       "      <td>-1.633901</td>\n",
       "      <td>-1.666098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>strict</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>100</td>\n",
       "      <td>f</td>\n",
       "      <td>34.150995</td>\n",
       "      <td>-118.409359</td>\n",
       "      <td>Na</td>\n",
       "      <td>6</td>\n",
       "      <td>Loft</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34</td>\n",
       "      <td>-118</td>\n",
       "      <td>552.0</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>14</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>898</td>\n",
       "      <td>94.339623</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2448.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2491.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2855.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>1</td>\n",
       "      <td>91604</td>\n",
       "      <td>0.555377</td>\n",
       "      <td>-0.482101</td>\n",
       "      <td>-0.301546</td>\n",
       "      <td>0.119861</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.813030</td>\n",
       "      <td>0.286632</td>\n",
       "      <td>-0.180486</td>\n",
       "      <td>-0.426083</td>\n",
       "      <td>-0.233947</td>\n",
       "      <td>-0.468984</td>\n",
       "      <td>-1.334775</td>\n",
       "      <td>0.827203</td>\n",
       "      <td>0.717471</td>\n",
       "      <td>0.355890</td>\n",
       "      <td>0.655069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accommodates  bathrooms  bed_type  bedrooms  beds cancellation_policy  \\\n",
       "0             6          2  Real Bed         2     2              strict   \n",
       "1             3          1  Real Bed         1     1            moderate   \n",
       "2             2          1  Real Bed         0     1            flexible   \n",
       "3             4          1  Real Bed         1     2              strict   \n",
       "4             3          1  Real Bed         1     2              strict   \n",
       "\n",
       "     city cleaning_fee host_has_profile_pic host_identity_verified  \\\n",
       "0  Boston            t                    t                      f   \n",
       "1      LA            t                    t                      t   \n",
       "2     NYC            f                    t                      t   \n",
       "3     NYC            f                    t                      t   \n",
       "4      LA            t                    t                      t   \n",
       "\n",
       "   host_response_rate instant_bookable   latitude   longitude  \\\n",
       "0                 100                t  42.359278  -71.069962   \n",
       "1                 100                f  34.084747 -118.367355   \n",
       "2                 100                f  40.720541  -73.959192   \n",
       "3                   0                f  40.681117  -73.944091   \n",
       "4                 100                f  34.150995 -118.409359   \n",
       "\n",
       "        neighbourhood  number_of_reviews property_type  review_scores_rating  \\\n",
       "0         Beacon Hill                 58         House                  90.0   \n",
       "1      West Hollywood                  4    Guesthouse                 100.0   \n",
       "2        Williamsburg                  0     Apartment                   NaN   \n",
       "3  Bedford-Stuyvesant                  0     Apartment                   NaN   \n",
       "4                  Na                  6          Loft                  92.0   \n",
       "\n",
       "         room_type  thumbnail_url  bathrooms_par_1  bedrooms_par_1  \\\n",
       "0  Entire home/apt            1.0         0.333333        0.333333   \n",
       "1  Entire home/apt            1.0         0.333333        0.333333   \n",
       "2     Private room            1.0         0.500000        0.000000   \n",
       "3  Entire home/apt            1.0         0.250000        0.250000   \n",
       "4  Entire home/apt            1.0         0.333333        0.333333   \n",
       "\n",
       "   beds_par_1  bed_par_bedrooms  latitude_int  longitude_int  \\\n",
       "0    0.333333               1.0            42            -71   \n",
       "1    0.333333               1.0            34           -118   \n",
       "2    0.500000               0.0            40            -73   \n",
       "3    0.500000               2.0            40            -73   \n",
       "4    0.666667               2.0            34           -118   \n",
       "\n",
       "   review_score_total  review_score_weight  amenities_count    TV Cable TV  \\\n",
       "0              5220.0             0.569620               21  True     True   \n",
       "1               400.0             0.961538               20  True     True   \n",
       "2                 0.0             0.000000               10  True    False   \n",
       "3                 0.0             0.000000               17  True     True   \n",
       "4               552.0             0.867925               14  True    False   \n",
       "\n",
       "  Wireless Internet Air conditioning Kitchen Free parking on premises  \\\n",
       "0              True             True    True                    False   \n",
       "1              True             True    True                     True   \n",
       "2              True             True    True                    False   \n",
       "3              True             True    True                    False   \n",
       "4              True             True    True                     True   \n",
       "\n",
       "  Pets allowed Breakfast Elevator Hot tub Indoor fireplace Heating  \\\n",
       "0        False     False    False   False             True    True   \n",
       "1        False     False    False   False            False    True   \n",
       "2        False     False    False   False            False    True   \n",
       "3        False     False    False   False            False    True   \n",
       "4         True     False    False   False            False    True   \n",
       "\n",
       "  Family/kid friendly Suitable for events Washer  Dryer Smoke detector  \\\n",
       "0                True               False   True   True           True   \n",
       "1               False               False  False  False           True   \n",
       "2                True               False   True   True          False   \n",
       "3               False               False  False  False           True   \n",
       "4                True               False   True   True           True   \n",
       "\n",
       "  Carbon monoxide detector First aid kit Safety card Fire extinguisher  \\\n",
       "0                     True         False       False             False   \n",
       "1                     True         False       False              True   \n",
       "2                    False         False       False             False   \n",
       "3                     True         False       False             False   \n",
       "4                     True         False       False              True   \n",
       "\n",
       "  Essentials Shampoo Lock on bedroom door Hangers Hair dryer   Iron  \\\n",
       "0       True    True                 True    True       True   True   \n",
       "1       True    True                False    True       True   True   \n",
       "2       True   False                False    True      False  False   \n",
       "3       True    True                False    True       True   True   \n",
       "4      False   False                False   False      False  False   \n",
       "\n",
       "  Laptop friendly workspace Self Check-In Keypad Private entrance  \\\n",
       "0                      True          True  False            False   \n",
       "1                      True         False  False            False   \n",
       "2                     False         False  False            False   \n",
       "3                      True         False  False            False   \n",
       "4                     False         False  False            False   \n",
       "\n",
       "  Baby monitor Bathtub Baby bath Changing table Children’s books and toys  \\\n",
       "0        False   False     False          False                     False   \n",
       "1        False   False     False          False                     False   \n",
       "2        False   False     False          False                     False   \n",
       "3        False   False     False          False                     False   \n",
       "4        False   False     False          False                     False   \n",
       "\n",
       "  Window guards Table corner guards Fireplace guards  \\\n",
       "0         False               False            False   \n",
       "1         False               False            False   \n",
       "2         False               False            False   \n",
       "3         False               False            False   \n",
       "4         False               False            False   \n",
       "\n",
       "  Babysitter recommendations   Crib Room-darkening shades Game console  \\\n",
       "0                      False  False                 False        False   \n",
       "1                      False  False                 False        False   \n",
       "2                      False  False                 False        False   \n",
       "3                      False  False                 False        False   \n",
       "4                      False  False                 False        False   \n",
       "\n",
       "  Hot water Bed linens Extra pillows and blankets Ethernet connection  \\\n",
       "0     False      False                      False               False   \n",
       "1     False      False                      False               False   \n",
       "2     False      False                      False               False   \n",
       "3     False      False                      False               False   \n",
       "4     False      False                      False               False   \n",
       "\n",
       "  Pocket wifi Microwave Coffee maker Refrigerator Dishwasher  \\\n",
       "0       False     False        False        False      False   \n",
       "1       False     False        False        False      False   \n",
       "2       False     False        False        False      False   \n",
       "3       False     False        False        False      False   \n",
       "4       False     False        False        False      False   \n",
       "\n",
       "  Dishes and silverware Cooking basics   Oven  Stove EV charger  \\\n",
       "0                 False          False  False  False      False   \n",
       "1                 False          False  False  False      False   \n",
       "2                 False          False  False  False      False   \n",
       "3                 False          False  False  False      False   \n",
       "4                 False          False  False  False      False   \n",
       "\n",
       "  Single level home BBQ grill Patio or balcony Garden or backyard  \\\n",
       "0             False     False            False              False   \n",
       "1             False     False            False              False   \n",
       "2             False     False            False              False   \n",
       "3             False     False            False              False   \n",
       "4             False     False            False              False   \n",
       "\n",
       "  Beach essentials Luggage dropoff allowed Long term stays allowed  \\\n",
       "0            False                   False                   False   \n",
       "1            False                   False                   False   \n",
       "2            False                   False                   False   \n",
       "3            False                   False                   False   \n",
       "4            False                   False                   False   \n",
       "\n",
       "  Wide hallway clearance Step-free access Wide doorway   Flat  \\\n",
       "0                  False            False        False  False   \n",
       "1                  False            False        False  False   \n",
       "2                  False            False        False  False   \n",
       "3                  False            False        False  False   \n",
       "4                  False            False        False  False   \n",
       "\n",
       "   smooth pathway to front door Well-lit path to entrance  \\\n",
       "0                         False                     False   \n",
       "1                         False                     False   \n",
       "2                         False                     False   \n",
       "3                         False                     False   \n",
       "4                         False                     False   \n",
       "\n",
       "  Disabled parking spot Wide clearance to bed Accessible-height bed  \\\n",
       "0                 False                 False                 False   \n",
       "1                 False                 False                 False   \n",
       "2                 False                 False                 False   \n",
       "3                 False                 False                 False   \n",
       "4                 False                 False                 False   \n",
       "\n",
       "  Fixed grab bars for shower & toilet Bathtub with shower chair  \\\n",
       "0                               False                     False   \n",
       "1                               False                     False   \n",
       "2                               False                     False   \n",
       "3                               False                     False   \n",
       "4                               False                     False   \n",
       "\n",
       "  Roll-in shower with chair Accessible-height toilet  \\\n",
       "0                     False                    False   \n",
       "1                     False                    False   \n",
       "2                     False                    False   \n",
       "3                     False                    False   \n",
       "4                     False                    False   \n",
       "\n",
       "  Wide clearance to shower & toilet Wide entryway Waterfront  \\\n",
       "0                             False         False      False   \n",
       "1                             False         False      False   \n",
       "2                             False         False      False   \n",
       "3                             False         False      False   \n",
       "4                             False         False      False   \n",
       "\n",
       "  Handheld shower head  rare_amenities_count  description_word_count  \\\n",
       "0                False                    24                    1000   \n",
       "1                False                    24                    1000   \n",
       "2                False                     6                    1000   \n",
       "3                False                    16                     220   \n",
       "4                False                    16                     898   \n",
       "\n",
       "   host_response_rate_weight  first_review_Year  first_review_Month  \\\n",
       "0                  63.291139             2017.0                 1.0   \n",
       "1                  96.153846             2016.0                 8.0   \n",
       "2                 100.000000                NaN                 NaN   \n",
       "3                   0.000000                NaN                 NaN   \n",
       "4                  94.339623             2015.0                 8.0   \n",
       "\n",
       "   first_review_Day  BusinessOld  host_since_Year  host_since_Month  \\\n",
       "0               9.0       2975.0           2016.0               8.0   \n",
       "1              17.0       2830.0           2014.0               9.0   \n",
       "2               NaN          NaN           2012.0              10.0   \n",
       "3               NaN          NaN           2013.0               1.0   \n",
       "4               1.0       2448.0           2014.0              12.0   \n",
       "\n",
       "   host_since_Day  BusinessOld2  first_reviewOld  last_review_Year  \\\n",
       "0            23.0        3095.0            139.0            2017.0   \n",
       "1             3.0        2375.0            714.0            2017.0   \n",
       "2            17.0        1689.0              NaN               NaN   \n",
       "3            23.0        1787.0              NaN               NaN   \n",
       "4            28.0        2491.0            216.0            2016.0   \n",
       "\n",
       "   last_review_Month  last_review_Day  BusinessOld3  BusinessUpdate  \\\n",
       "0                9.0             25.0        3234.0          1557.0   \n",
       "1                5.0              2.0        3088.0          1703.0   \n",
       "2                NaN              NaN           NaN             NaN   \n",
       "3                NaN              NaN           NaN             NaN   \n",
       "4                9.0             11.0        2855.0          1936.0   \n",
       "\n",
       "   BusinessPeriod thumbnail_url_str  zipcode_int  Log_beds_par_1  \\\n",
       "0           259.0                 1         2114       -1.376763   \n",
       "1           258.0                 1        90046       -1.376763   \n",
       "2             NaN                 1        11249       -0.250963   \n",
       "3             NaN                 1        11216       -0.250963   \n",
       "4           407.0                 1        91604        0.555377   \n",
       "\n",
       "   Log_bathrooms_par_1  Log_bathrooms  Log_review_score_total  \\\n",
       "0            -0.482101       1.687346                1.200628   \n",
       "1            -0.482101      -0.301546               -0.006598   \n",
       "2             0.298715      -0.301546               -1.511131   \n",
       "3            -0.988289      -0.301546               -1.511131   \n",
       "4            -0.482101      -0.301546                0.119861   \n",
       "\n",
       "   Log_number_of_reviews  Log_beds  Log_accommodates  Log_bedrooms  \\\n",
       "0               1.325752  0.813030          1.393625      0.995675   \n",
       "1              -0.173313 -0.716402          0.286632     -0.180486   \n",
       "2              -1.375018 -0.716402         -0.452805     -2.225104   \n",
       "3              -1.375018  0.813030          0.775040     -0.180486   \n",
       "4               0.053936  0.813030          0.286632     -0.180486   \n",
       "\n",
       "   Log_bedrooms_par_1  Log_rare_amenities_count  Log_amenities_count  \\\n",
       "0           -0.426083                  0.639636             0.538261   \n",
       "1           -0.426083                  0.639636             0.401933   \n",
       "2           -2.104475                 -1.670391            -1.117572   \n",
       "3           -0.792371                 -0.233947            -0.021079   \n",
       "4           -0.426083                 -0.233947            -0.468984   \n",
       "\n",
       "   Log_latitude  Log_host_response_rate_weight  Log_review_score_weight  \\\n",
       "0      1.592091                       0.251120                -0.382477   \n",
       "1     -1.346662                       0.858591                 1.150064   \n",
       "2      0.708330                       0.924450                -1.535764   \n",
       "3      0.689395                      -1.609670                -1.535764   \n",
       "4     -1.334775                       0.827203                 0.717471   \n",
       "\n",
       "   Log_description_word_count  Log_host_response_rate  \n",
       "0                    0.782058                0.655069  \n",
       "1                    0.782058                0.655069  \n",
       "2                    0.782058                0.655069  \n",
       "3                   -1.633901               -1.666098  \n",
       "4                    0.355890                0.655069  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_log = test_X.copy()\n",
    "tmp = pd.DataFrame()\n",
    "tmp[num_col_feat_list] = pt.transform(test_X[num_col_feat_list])\n",
    "tmp = tmp.add_prefix('Log_')\n",
    "test_X_log[tmp.columns] = tmp\n",
    "test_X_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4476ed3-1f64-4215-ac91-9c6f54f2f025",
   "metadata": {},
   "source": [
    "### ダミー変数化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7582c413-4e67-4a60-8c8a-cddff8f84d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_LabelEncoding(categorical_columns, training_df, test_df):\n",
    "    \n",
    "    for column in tqdm(categorical_columns):\n",
    "        df = test_df.copy()\n",
    "        le_column = LabelEncoder().fit(training_df[column].fillna('Na'))\n",
    "        mask = df[column].isin(le_column.classes_)\n",
    "        column_new_data = df[column].mask(mask).unique()\n",
    "        le_column.classes_ = np.concatenate([le_column.classes_, column_new_data])\n",
    "        df[column] = le_column.transform(df[column])\n",
    "        \n",
    "    df[categorical_columns] = df[categorical_columns].astype('category')\n",
    "\n",
    "    return df\n",
    "\n",
    "def fit_dummy(categorical_columns, training_df, test_df):\n",
    "    df = test_df.copy()\n",
    "    fit_dummy_columns = []\n",
    "    for i in training_df.select_dtypes(include=object).columns.tolist():\n",
    "        if i not in categorical_columns:\n",
    "            fit_dummy_columns.append(i)\n",
    "            \n",
    "    for column in tqdm(training_df[fit_dummy_columns].columns):\n",
    "        fit_type = training_df[column].dropna().unique()\n",
    "        #NA = training_df[column].value_counts(dropna=False).index[0]\n",
    "        df[column] = pd.Categorical(df[column], fit_type)\n",
    "        \n",
    "    df = pd.get_dummies(df, columns=fit_dummy_columns, drop_first=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eed6172a-fd3c-4ef5-8caa-9df8fe737773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 23.79it/s]\n",
      "100%|██████████████████████████████████████████| 91/91 [00:00<00:00, 133.08it/s]\n"
     ]
    }
   ],
   "source": [
    "test_X_log_dummy = fit_LabelEncoding(categorical_columns, train_X_addEDA, test_X_log)\n",
    "test_X_log_dummy = fit_dummy(categorical_columns, train_X_addEDA, test_X_log_dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2ca591a-41b2-4c20-b8ea-f6ac6a8d2990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>thumbnail_url</th>\n",
       "      <th>bathrooms_par_1</th>\n",
       "      <th>bedrooms_par_1</th>\n",
       "      <th>beds_par_1</th>\n",
       "      <th>bed_par_bedrooms</th>\n",
       "      <th>latitude_int</th>\n",
       "      <th>longitude_int</th>\n",
       "      <th>review_score_total</th>\n",
       "      <th>review_score_weight</th>\n",
       "      <th>amenities_count</th>\n",
       "      <th>rare_amenities_count</th>\n",
       "      <th>description_word_count</th>\n",
       "      <th>host_response_rate_weight</th>\n",
       "      <th>first_review_Year</th>\n",
       "      <th>first_review_Month</th>\n",
       "      <th>first_review_Day</th>\n",
       "      <th>BusinessOld</th>\n",
       "      <th>host_since_Year</th>\n",
       "      <th>host_since_Month</th>\n",
       "      <th>host_since_Day</th>\n",
       "      <th>BusinessOld2</th>\n",
       "      <th>first_reviewOld</th>\n",
       "      <th>last_review_Year</th>\n",
       "      <th>last_review_Month</th>\n",
       "      <th>last_review_Day</th>\n",
       "      <th>BusinessOld3</th>\n",
       "      <th>BusinessUpdate</th>\n",
       "      <th>BusinessPeriod</th>\n",
       "      <th>zipcode_int</th>\n",
       "      <th>Log_beds_par_1</th>\n",
       "      <th>Log_bathrooms_par_1</th>\n",
       "      <th>Log_bathrooms</th>\n",
       "      <th>Log_review_score_total</th>\n",
       "      <th>Log_number_of_reviews</th>\n",
       "      <th>Log_beds</th>\n",
       "      <th>Log_accommodates</th>\n",
       "      <th>Log_bedrooms</th>\n",
       "      <th>Log_bedrooms_par_1</th>\n",
       "      <th>Log_rare_amenities_count</th>\n",
       "      <th>Log_amenities_count</th>\n",
       "      <th>Log_latitude</th>\n",
       "      <th>Log_host_response_rate_weight</th>\n",
       "      <th>Log_review_score_weight</th>\n",
       "      <th>Log_description_word_count</th>\n",
       "      <th>Log_host_response_rate</th>\n",
       "      <th>bed_type_Pull-out Sofa</th>\n",
       "      <th>bed_type_Airbed</th>\n",
       "      <th>bed_type_Futon</th>\n",
       "      <th>bed_type_Couch</th>\n",
       "      <th>cancellation_policy_strict</th>\n",
       "      <th>cancellation_policy_moderate</th>\n",
       "      <th>cancellation_policy_super_strict_30</th>\n",
       "      <th>cancellation_policy_super_strict_60</th>\n",
       "      <th>city_DC</th>\n",
       "      <th>city_NYC</th>\n",
       "      <th>city_SF</th>\n",
       "      <th>city_Chicago</th>\n",
       "      <th>city_Boston</th>\n",
       "      <th>cleaning_fee_f</th>\n",
       "      <th>host_has_profile_pic_Na</th>\n",
       "      <th>host_has_profile_pic_f</th>\n",
       "      <th>host_identity_verified_t</th>\n",
       "      <th>host_identity_verified_Na</th>\n",
       "      <th>instant_bookable_t</th>\n",
       "      <th>property_type_House</th>\n",
       "      <th>property_type_Townhouse</th>\n",
       "      <th>property_type_Loft</th>\n",
       "      <th>property_type_Cabin</th>\n",
       "      <th>property_type_Condominium</th>\n",
       "      <th>property_type_Guest suite</th>\n",
       "      <th>property_type_Guesthouse</th>\n",
       "      <th>property_type_Other</th>\n",
       "      <th>property_type_Bungalow</th>\n",
       "      <th>property_type_Villa</th>\n",
       "      <th>property_type_Bed &amp; Breakfast</th>\n",
       "      <th>property_type_Dorm</th>\n",
       "      <th>property_type_Timeshare</th>\n",
       "      <th>property_type_Camper/RV</th>\n",
       "      <th>property_type_Cave</th>\n",
       "      <th>property_type_Hostel</th>\n",
       "      <th>property_type_Earth House</th>\n",
       "      <th>property_type_In-law</th>\n",
       "      <th>property_type_Serviced apartment</th>\n",
       "      <th>property_type_Boat</th>\n",
       "      <th>property_type_Tent</th>\n",
       "      <th>property_type_Castle</th>\n",
       "      <th>property_type_Boutique hotel</th>\n",
       "      <th>property_type_Vacation home</th>\n",
       "      <th>property_type_Hut</th>\n",
       "      <th>property_type_Treehouse</th>\n",
       "      <th>property_type_Yurt</th>\n",
       "      <th>property_type_Chalet</th>\n",
       "      <th>property_type_Island</th>\n",
       "      <th>property_type_Tipi</th>\n",
       "      <th>property_type_Train</th>\n",
       "      <th>property_type_Parking Space</th>\n",
       "      <th>property_type_Casa particular</th>\n",
       "      <th>room_type_Entire home/apt</th>\n",
       "      <th>room_type_Shared room</th>\n",
       "      <th>TV_False</th>\n",
       "      <th>Cable TV_True</th>\n",
       "      <th>Wireless Internet_False</th>\n",
       "      <th>Air conditioning_True</th>\n",
       "      <th>Kitchen_False</th>\n",
       "      <th>Free parking on premises_False</th>\n",
       "      <th>Pets allowed_True</th>\n",
       "      <th>Breakfast_True</th>\n",
       "      <th>Elevator_True</th>\n",
       "      <th>Hot tub_True</th>\n",
       "      <th>Indoor fireplace_True</th>\n",
       "      <th>Heating_True</th>\n",
       "      <th>Family/kid friendly_True</th>\n",
       "      <th>Suitable for events_True</th>\n",
       "      <th>Washer_False</th>\n",
       "      <th>Dryer_False</th>\n",
       "      <th>Smoke detector_False</th>\n",
       "      <th>Carbon monoxide detector_True</th>\n",
       "      <th>First aid kit_True</th>\n",
       "      <th>Safety card_True</th>\n",
       "      <th>Fire extinguisher_True</th>\n",
       "      <th>Essentials_True</th>\n",
       "      <th>Shampoo_True</th>\n",
       "      <th>Lock on bedroom door_True</th>\n",
       "      <th>Hangers_True</th>\n",
       "      <th>Hair dryer_True</th>\n",
       "      <th>Iron_True</th>\n",
       "      <th>Laptop friendly workspace_True</th>\n",
       "      <th>Self Check-In_True</th>\n",
       "      <th>Keypad_True</th>\n",
       "      <th>Private entrance_True</th>\n",
       "      <th>Baby monitor_True</th>\n",
       "      <th>Bathtub_True</th>\n",
       "      <th>Baby bath_True</th>\n",
       "      <th>Changing table_True</th>\n",
       "      <th>Children’s books and toys_True</th>\n",
       "      <th>Window guards_True</th>\n",
       "      <th>Table corner guards_True</th>\n",
       "      <th>Fireplace guards_True</th>\n",
       "      <th>Babysitter recommendations_True</th>\n",
       "      <th>Crib_True</th>\n",
       "      <th>Room-darkening shades_True</th>\n",
       "      <th>Game console_True</th>\n",
       "      <th>Hot water_True</th>\n",
       "      <th>Bed linens_True</th>\n",
       "      <th>Extra pillows and blankets_True</th>\n",
       "      <th>Ethernet connection_True</th>\n",
       "      <th>Pocket wifi_True</th>\n",
       "      <th>Microwave_True</th>\n",
       "      <th>Coffee maker_True</th>\n",
       "      <th>Refrigerator_True</th>\n",
       "      <th>Dishwasher_True</th>\n",
       "      <th>Dishes and silverware_True</th>\n",
       "      <th>Cooking basics_True</th>\n",
       "      <th>Oven_True</th>\n",
       "      <th>Stove_True</th>\n",
       "      <th>EV charger_True</th>\n",
       "      <th>Single level home_True</th>\n",
       "      <th>BBQ grill_True</th>\n",
       "      <th>Patio or balcony_True</th>\n",
       "      <th>Garden or backyard_True</th>\n",
       "      <th>Beach essentials_True</th>\n",
       "      <th>Luggage dropoff allowed_True</th>\n",
       "      <th>Long term stays allowed_True</th>\n",
       "      <th>Wide hallway clearance_True</th>\n",
       "      <th>Step-free access_True</th>\n",
       "      <th>Wide doorway_True</th>\n",
       "      <th>Flat_True</th>\n",
       "      <th>smooth pathway to front door_True</th>\n",
       "      <th>Well-lit path to entrance_True</th>\n",
       "      <th>Disabled parking spot_True</th>\n",
       "      <th>Wide clearance to bed_True</th>\n",
       "      <th>Accessible-height bed_True</th>\n",
       "      <th>Fixed grab bars for shower &amp; toilet_True</th>\n",
       "      <th>Bathtub with shower chair_True</th>\n",
       "      <th>Roll-in shower with chair_True</th>\n",
       "      <th>Accessible-height toilet_True</th>\n",
       "      <th>Wide clearance to shower &amp; toilet_True</th>\n",
       "      <th>Wide entryway_True</th>\n",
       "      <th>Waterfront_True</th>\n",
       "      <th>Handheld shower head_True</th>\n",
       "      <th>thumbnail_url_str_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>42.359278</td>\n",
       "      <td>-71.069962</td>\n",
       "      <td>40</td>\n",
       "      <td>58</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>-71</td>\n",
       "      <td>5220.0</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>1000</td>\n",
       "      <td>63.291139</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2975.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3095.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3234.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>2114</td>\n",
       "      <td>-1.376763</td>\n",
       "      <td>-0.482101</td>\n",
       "      <td>1.687346</td>\n",
       "      <td>1.200628</td>\n",
       "      <td>1.325752</td>\n",
       "      <td>0.813030</td>\n",
       "      <td>1.393625</td>\n",
       "      <td>0.995675</td>\n",
       "      <td>-0.426083</td>\n",
       "      <td>0.639636</td>\n",
       "      <td>0.538261</td>\n",
       "      <td>1.592091</td>\n",
       "      <td>0.251120</td>\n",
       "      <td>-0.382477</td>\n",
       "      <td>0.782058</td>\n",
       "      <td>0.655069</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>34.084747</td>\n",
       "      <td>-118.367355</td>\n",
       "      <td>573</td>\n",
       "      <td>4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>-118</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>1000</td>\n",
       "      <td>96.153846</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2830.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2375.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3088.0</td>\n",
       "      <td>1703.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>90046</td>\n",
       "      <td>-1.376763</td>\n",
       "      <td>-0.482101</td>\n",
       "      <td>-0.301546</td>\n",
       "      <td>-0.006598</td>\n",
       "      <td>-0.173313</td>\n",
       "      <td>-0.716402</td>\n",
       "      <td>0.286632</td>\n",
       "      <td>-0.180486</td>\n",
       "      <td>-0.426083</td>\n",
       "      <td>0.639636</td>\n",
       "      <td>0.401933</td>\n",
       "      <td>-1.346662</td>\n",
       "      <td>0.858591</td>\n",
       "      <td>1.150064</td>\n",
       "      <td>0.782058</td>\n",
       "      <td>0.655069</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>40.720541</td>\n",
       "      <td>-73.959192</td>\n",
       "      <td>595</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>-73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11249</td>\n",
       "      <td>-0.250963</td>\n",
       "      <td>0.298715</td>\n",
       "      <td>-0.301546</td>\n",
       "      <td>-1.511131</td>\n",
       "      <td>-1.375018</td>\n",
       "      <td>-0.716402</td>\n",
       "      <td>-0.452805</td>\n",
       "      <td>-2.225104</td>\n",
       "      <td>-2.104475</td>\n",
       "      <td>-1.670391</td>\n",
       "      <td>-1.117572</td>\n",
       "      <td>0.708330</td>\n",
       "      <td>0.924450</td>\n",
       "      <td>-1.535764</td>\n",
       "      <td>0.782058</td>\n",
       "      <td>0.655069</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>40.681117</td>\n",
       "      <td>-73.944091</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40</td>\n",
       "      <td>-73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11216</td>\n",
       "      <td>-0.250963</td>\n",
       "      <td>-0.988289</td>\n",
       "      <td>-0.301546</td>\n",
       "      <td>-1.511131</td>\n",
       "      <td>-1.375018</td>\n",
       "      <td>0.813030</td>\n",
       "      <td>0.775040</td>\n",
       "      <td>-0.180486</td>\n",
       "      <td>-0.792371</td>\n",
       "      <td>-0.233947</td>\n",
       "      <td>-0.021079</td>\n",
       "      <td>0.689395</td>\n",
       "      <td>-1.609670</td>\n",
       "      <td>-1.535764</td>\n",
       "      <td>-1.633901</td>\n",
       "      <td>-1.666098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>34.150995</td>\n",
       "      <td>-118.409359</td>\n",
       "      <td>375</td>\n",
       "      <td>6</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34</td>\n",
       "      <td>-118</td>\n",
       "      <td>552.0</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>898</td>\n",
       "      <td>94.339623</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2448.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2491.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2855.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>91604</td>\n",
       "      <td>0.555377</td>\n",
       "      <td>-0.482101</td>\n",
       "      <td>-0.301546</td>\n",
       "      <td>0.119861</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.813030</td>\n",
       "      <td>0.286632</td>\n",
       "      <td>-0.180486</td>\n",
       "      <td>-0.426083</td>\n",
       "      <td>-0.233947</td>\n",
       "      <td>-0.468984</td>\n",
       "      <td>-1.334775</td>\n",
       "      <td>0.827203</td>\n",
       "      <td>0.717471</td>\n",
       "      <td>0.355890</td>\n",
       "      <td>0.655069</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accommodates  bathrooms  bedrooms  beds  host_response_rate   latitude  \\\n",
       "0             6          2         2     2                 100  42.359278   \n",
       "1             3          1         1     1                 100  34.084747   \n",
       "2             2          1         0     1                 100  40.720541   \n",
       "3             4          1         1     2                   0  40.681117   \n",
       "4             3          1         1     2                 100  34.150995   \n",
       "\n",
       "    longitude neighbourhood  number_of_reviews  review_scores_rating  \\\n",
       "0  -71.069962            40                 58                  90.0   \n",
       "1 -118.367355           573                  4                 100.0   \n",
       "2  -73.959192           595                  0                   NaN   \n",
       "3  -73.944091            42                  0                   NaN   \n",
       "4 -118.409359           375                  6                  92.0   \n",
       "\n",
       "   thumbnail_url  bathrooms_par_1  bedrooms_par_1  beds_par_1  \\\n",
       "0            1.0         0.333333        0.333333    0.333333   \n",
       "1            1.0         0.333333        0.333333    0.333333   \n",
       "2            1.0         0.500000        0.000000    0.500000   \n",
       "3            1.0         0.250000        0.250000    0.500000   \n",
       "4            1.0         0.333333        0.333333    0.666667   \n",
       "\n",
       "   bed_par_bedrooms  latitude_int  longitude_int  review_score_total  \\\n",
       "0               1.0            42            -71              5220.0   \n",
       "1               1.0            34           -118               400.0   \n",
       "2               0.0            40            -73                 0.0   \n",
       "3               2.0            40            -73                 0.0   \n",
       "4               2.0            34           -118               552.0   \n",
       "\n",
       "   review_score_weight  amenities_count  rare_amenities_count  \\\n",
       "0             0.569620               21                    24   \n",
       "1             0.961538               20                    24   \n",
       "2             0.000000               10                     6   \n",
       "3             0.000000               17                    16   \n",
       "4             0.867925               14                    16   \n",
       "\n",
       "   description_word_count  host_response_rate_weight  first_review_Year  \\\n",
       "0                    1000                  63.291139             2017.0   \n",
       "1                    1000                  96.153846             2016.0   \n",
       "2                    1000                 100.000000                NaN   \n",
       "3                     220                   0.000000                NaN   \n",
       "4                     898                  94.339623             2015.0   \n",
       "\n",
       "   first_review_Month  first_review_Day  BusinessOld  host_since_Year  \\\n",
       "0                 1.0               9.0       2975.0           2016.0   \n",
       "1                 8.0              17.0       2830.0           2014.0   \n",
       "2                 NaN               NaN          NaN           2012.0   \n",
       "3                 NaN               NaN          NaN           2013.0   \n",
       "4                 8.0               1.0       2448.0           2014.0   \n",
       "\n",
       "   host_since_Month  host_since_Day  BusinessOld2  first_reviewOld  \\\n",
       "0               8.0            23.0        3095.0            139.0   \n",
       "1               9.0             3.0        2375.0            714.0   \n",
       "2              10.0            17.0        1689.0              NaN   \n",
       "3               1.0            23.0        1787.0              NaN   \n",
       "4              12.0            28.0        2491.0            216.0   \n",
       "\n",
       "   last_review_Year  last_review_Month  last_review_Day  BusinessOld3  \\\n",
       "0            2017.0                9.0             25.0        3234.0   \n",
       "1            2017.0                5.0              2.0        3088.0   \n",
       "2               NaN                NaN              NaN           NaN   \n",
       "3               NaN                NaN              NaN           NaN   \n",
       "4            2016.0                9.0             11.0        2855.0   \n",
       "\n",
       "   BusinessUpdate  BusinessPeriod  zipcode_int  Log_beds_par_1  \\\n",
       "0          1557.0           259.0         2114       -1.376763   \n",
       "1          1703.0           258.0        90046       -1.376763   \n",
       "2             NaN             NaN        11249       -0.250963   \n",
       "3             NaN             NaN        11216       -0.250963   \n",
       "4          1936.0           407.0        91604        0.555377   \n",
       "\n",
       "   Log_bathrooms_par_1  Log_bathrooms  Log_review_score_total  \\\n",
       "0            -0.482101       1.687346                1.200628   \n",
       "1            -0.482101      -0.301546               -0.006598   \n",
       "2             0.298715      -0.301546               -1.511131   \n",
       "3            -0.988289      -0.301546               -1.511131   \n",
       "4            -0.482101      -0.301546                0.119861   \n",
       "\n",
       "   Log_number_of_reviews  Log_beds  Log_accommodates  Log_bedrooms  \\\n",
       "0               1.325752  0.813030          1.393625      0.995675   \n",
       "1              -0.173313 -0.716402          0.286632     -0.180486   \n",
       "2              -1.375018 -0.716402         -0.452805     -2.225104   \n",
       "3              -1.375018  0.813030          0.775040     -0.180486   \n",
       "4               0.053936  0.813030          0.286632     -0.180486   \n",
       "\n",
       "   Log_bedrooms_par_1  Log_rare_amenities_count  Log_amenities_count  \\\n",
       "0           -0.426083                  0.639636             0.538261   \n",
       "1           -0.426083                  0.639636             0.401933   \n",
       "2           -2.104475                 -1.670391            -1.117572   \n",
       "3           -0.792371                 -0.233947            -0.021079   \n",
       "4           -0.426083                 -0.233947            -0.468984   \n",
       "\n",
       "   Log_latitude  Log_host_response_rate_weight  Log_review_score_weight  \\\n",
       "0      1.592091                       0.251120                -0.382477   \n",
       "1     -1.346662                       0.858591                 1.150064   \n",
       "2      0.708330                       0.924450                -1.535764   \n",
       "3      0.689395                      -1.609670                -1.535764   \n",
       "4     -1.334775                       0.827203                 0.717471   \n",
       "\n",
       "   Log_description_word_count  Log_host_response_rate  bed_type_Pull-out Sofa  \\\n",
       "0                    0.782058                0.655069                       0   \n",
       "1                    0.782058                0.655069                       0   \n",
       "2                    0.782058                0.655069                       0   \n",
       "3                   -1.633901               -1.666098                       0   \n",
       "4                    0.355890                0.655069                       0   \n",
       "\n",
       "   bed_type_Airbed  bed_type_Futon  bed_type_Couch  \\\n",
       "0                0               0               0   \n",
       "1                0               0               0   \n",
       "2                0               0               0   \n",
       "3                0               0               0   \n",
       "4                0               0               0   \n",
       "\n",
       "   cancellation_policy_strict  cancellation_policy_moderate  \\\n",
       "0                           1                             0   \n",
       "1                           0                             1   \n",
       "2                           0                             0   \n",
       "3                           1                             0   \n",
       "4                           1                             0   \n",
       "\n",
       "   cancellation_policy_super_strict_30  cancellation_policy_super_strict_60  \\\n",
       "0                                    0                                    0   \n",
       "1                                    0                                    0   \n",
       "2                                    0                                    0   \n",
       "3                                    0                                    0   \n",
       "4                                    0                                    0   \n",
       "\n",
       "   city_DC  city_NYC  city_SF  city_Chicago  city_Boston  cleaning_fee_f  \\\n",
       "0        0         0        0             0            1               0   \n",
       "1        0         0        0             0            0               0   \n",
       "2        0         1        0             0            0               1   \n",
       "3        0         1        0             0            0               1   \n",
       "4        0         0        0             0            0               0   \n",
       "\n",
       "   host_has_profile_pic_Na  host_has_profile_pic_f  host_identity_verified_t  \\\n",
       "0                        0                       0                         0   \n",
       "1                        0                       0                         1   \n",
       "2                        0                       0                         1   \n",
       "3                        0                       0                         1   \n",
       "4                        0                       0                         1   \n",
       "\n",
       "   host_identity_verified_Na  instant_bookable_t  property_type_House  \\\n",
       "0                          0                   1                    1   \n",
       "1                          0                   0                    0   \n",
       "2                          0                   0                    0   \n",
       "3                          0                   0                    0   \n",
       "4                          0                   0                    0   \n",
       "\n",
       "   property_type_Townhouse  property_type_Loft  property_type_Cabin  \\\n",
       "0                        0                   0                    0   \n",
       "1                        0                   0                    0   \n",
       "2                        0                   0                    0   \n",
       "3                        0                   0                    0   \n",
       "4                        0                   1                    0   \n",
       "\n",
       "   property_type_Condominium  property_type_Guest suite  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "\n",
       "   property_type_Guesthouse  property_type_Other  property_type_Bungalow  \\\n",
       "0                         0                    0                       0   \n",
       "1                         1                    0                       0   \n",
       "2                         0                    0                       0   \n",
       "3                         0                    0                       0   \n",
       "4                         0                    0                       0   \n",
       "\n",
       "   property_type_Villa  property_type_Bed & Breakfast  property_type_Dorm  \\\n",
       "0                    0                              0                   0   \n",
       "1                    0                              0                   0   \n",
       "2                    0                              0                   0   \n",
       "3                    0                              0                   0   \n",
       "4                    0                              0                   0   \n",
       "\n",
       "   property_type_Timeshare  property_type_Camper/RV  property_type_Cave  \\\n",
       "0                        0                        0                   0   \n",
       "1                        0                        0                   0   \n",
       "2                        0                        0                   0   \n",
       "3                        0                        0                   0   \n",
       "4                        0                        0                   0   \n",
       "\n",
       "   property_type_Hostel  property_type_Earth House  property_type_In-law  \\\n",
       "0                     0                          0                     0   \n",
       "1                     0                          0                     0   \n",
       "2                     0                          0                     0   \n",
       "3                     0                          0                     0   \n",
       "4                     0                          0                     0   \n",
       "\n",
       "   property_type_Serviced apartment  property_type_Boat  property_type_Tent  \\\n",
       "0                                 0                   0                   0   \n",
       "1                                 0                   0                   0   \n",
       "2                                 0                   0                   0   \n",
       "3                                 0                   0                   0   \n",
       "4                                 0                   0                   0   \n",
       "\n",
       "   property_type_Castle  property_type_Boutique hotel  \\\n",
       "0                     0                             0   \n",
       "1                     0                             0   \n",
       "2                     0                             0   \n",
       "3                     0                             0   \n",
       "4                     0                             0   \n",
       "\n",
       "   property_type_Vacation home  property_type_Hut  property_type_Treehouse  \\\n",
       "0                            0                  0                        0   \n",
       "1                            0                  0                        0   \n",
       "2                            0                  0                        0   \n",
       "3                            0                  0                        0   \n",
       "4                            0                  0                        0   \n",
       "\n",
       "   property_type_Yurt  property_type_Chalet  property_type_Island  \\\n",
       "0                   0                     0                     0   \n",
       "1                   0                     0                     0   \n",
       "2                   0                     0                     0   \n",
       "3                   0                     0                     0   \n",
       "4                   0                     0                     0   \n",
       "\n",
       "   property_type_Tipi  property_type_Train  property_type_Parking Space  \\\n",
       "0                   0                    0                            0   \n",
       "1                   0                    0                            0   \n",
       "2                   0                    0                            0   \n",
       "3                   0                    0                            0   \n",
       "4                   0                    0                            0   \n",
       "\n",
       "   property_type_Casa particular  room_type_Entire home/apt  \\\n",
       "0                              0                          1   \n",
       "1                              0                          1   \n",
       "2                              0                          0   \n",
       "3                              0                          1   \n",
       "4                              0                          1   \n",
       "\n",
       "   room_type_Shared room  TV_False  Cable TV_True  Wireless Internet_False  \\\n",
       "0                      0         0              1                        0   \n",
       "1                      0         0              1                        0   \n",
       "2                      0         0              0                        0   \n",
       "3                      0         0              1                        0   \n",
       "4                      0         0              0                        0   \n",
       "\n",
       "   Air conditioning_True  Kitchen_False  Free parking on premises_False  \\\n",
       "0                      1              0                               1   \n",
       "1                      1              0                               0   \n",
       "2                      1              0                               1   \n",
       "3                      1              0                               1   \n",
       "4                      1              0                               0   \n",
       "\n",
       "   Pets allowed_True  Breakfast_True  Elevator_True  Hot tub_True  \\\n",
       "0                  0               0              0             0   \n",
       "1                  0               0              0             0   \n",
       "2                  0               0              0             0   \n",
       "3                  0               0              0             0   \n",
       "4                  1               0              0             0   \n",
       "\n",
       "   Indoor fireplace_True  Heating_True  Family/kid friendly_True  \\\n",
       "0                      1             1                         1   \n",
       "1                      0             1                         0   \n",
       "2                      0             1                         1   \n",
       "3                      0             1                         0   \n",
       "4                      0             1                         1   \n",
       "\n",
       "   Suitable for events_True  Washer_False  Dryer_False  Smoke detector_False  \\\n",
       "0                         0             0            0                     0   \n",
       "1                         0             1            1                     0   \n",
       "2                         0             0            0                     1   \n",
       "3                         0             1            1                     0   \n",
       "4                         0             0            0                     0   \n",
       "\n",
       "   Carbon monoxide detector_True  First aid kit_True  Safety card_True  \\\n",
       "0                              1                   0                 0   \n",
       "1                              1                   0                 0   \n",
       "2                              0                   0                 0   \n",
       "3                              1                   0                 0   \n",
       "4                              1                   0                 0   \n",
       "\n",
       "   Fire extinguisher_True  Essentials_True  Shampoo_True  \\\n",
       "0                       0                1             1   \n",
       "1                       1                1             1   \n",
       "2                       0                1             0   \n",
       "3                       0                1             1   \n",
       "4                       1                0             0   \n",
       "\n",
       "   Lock on bedroom door_True  Hangers_True  Hair dryer_True  Iron_True  \\\n",
       "0                          1             1                1          1   \n",
       "1                          0             1                1          1   \n",
       "2                          0             1                0          0   \n",
       "3                          0             1                1          1   \n",
       "4                          0             0                0          0   \n",
       "\n",
       "   Laptop friendly workspace_True  Self Check-In_True  Keypad_True  \\\n",
       "0                               1                   1            0   \n",
       "1                               1                   0            0   \n",
       "2                               0                   0            0   \n",
       "3                               1                   0            0   \n",
       "4                               0                   0            0   \n",
       "\n",
       "   Private entrance_True  Baby monitor_True  Bathtub_True  Baby bath_True  \\\n",
       "0                      0                  0             0               0   \n",
       "1                      0                  0             0               0   \n",
       "2                      0                  0             0               0   \n",
       "3                      0                  0             0               0   \n",
       "4                      0                  0             0               0   \n",
       "\n",
       "   Changing table_True  Children’s books and toys_True  Window guards_True  \\\n",
       "0                    0                               0                   0   \n",
       "1                    0                               0                   0   \n",
       "2                    0                               0                   0   \n",
       "3                    0                               0                   0   \n",
       "4                    0                               0                   0   \n",
       "\n",
       "   Table corner guards_True  Fireplace guards_True  \\\n",
       "0                         0                      0   \n",
       "1                         0                      0   \n",
       "2                         0                      0   \n",
       "3                         0                      0   \n",
       "4                         0                      0   \n",
       "\n",
       "   Babysitter recommendations_True  Crib_True  Room-darkening shades_True  \\\n",
       "0                                0          0                           0   \n",
       "1                                0          0                           0   \n",
       "2                                0          0                           0   \n",
       "3                                0          0                           0   \n",
       "4                                0          0                           0   \n",
       "\n",
       "   Game console_True  Hot water_True  Bed linens_True  \\\n",
       "0                  0               0                0   \n",
       "1                  0               0                0   \n",
       "2                  0               0                0   \n",
       "3                  0               0                0   \n",
       "4                  0               0                0   \n",
       "\n",
       "   Extra pillows and blankets_True  Ethernet connection_True  \\\n",
       "0                                0                         0   \n",
       "1                                0                         0   \n",
       "2                                0                         0   \n",
       "3                                0                         0   \n",
       "4                                0                         0   \n",
       "\n",
       "   Pocket wifi_True  Microwave_True  Coffee maker_True  Refrigerator_True  \\\n",
       "0                 0               0                  0                  0   \n",
       "1                 0               0                  0                  0   \n",
       "2                 0               0                  0                  0   \n",
       "3                 0               0                  0                  0   \n",
       "4                 0               0                  0                  0   \n",
       "\n",
       "   Dishwasher_True  Dishes and silverware_True  Cooking basics_True  \\\n",
       "0                0                           0                    0   \n",
       "1                0                           0                    0   \n",
       "2                0                           0                    0   \n",
       "3                0                           0                    0   \n",
       "4                0                           0                    0   \n",
       "\n",
       "   Oven_True  Stove_True  EV charger_True  Single level home_True  \\\n",
       "0          0           0                0                       0   \n",
       "1          0           0                0                       0   \n",
       "2          0           0                0                       0   \n",
       "3          0           0                0                       0   \n",
       "4          0           0                0                       0   \n",
       "\n",
       "   BBQ grill_True  Patio or balcony_True  Garden or backyard_True  \\\n",
       "0               0                      0                        0   \n",
       "1               0                      0                        0   \n",
       "2               0                      0                        0   \n",
       "3               0                      0                        0   \n",
       "4               0                      0                        0   \n",
       "\n",
       "   Beach essentials_True  Luggage dropoff allowed_True  \\\n",
       "0                      0                             0   \n",
       "1                      0                             0   \n",
       "2                      0                             0   \n",
       "3                      0                             0   \n",
       "4                      0                             0   \n",
       "\n",
       "   Long term stays allowed_True  Wide hallway clearance_True  \\\n",
       "0                             0                            0   \n",
       "1                             0                            0   \n",
       "2                             0                            0   \n",
       "3                             0                            0   \n",
       "4                             0                            0   \n",
       "\n",
       "   Step-free access_True  Wide doorway_True  Flat_True  \\\n",
       "0                      0                  0          0   \n",
       "1                      0                  0          0   \n",
       "2                      0                  0          0   \n",
       "3                      0                  0          0   \n",
       "4                      0                  0          0   \n",
       "\n",
       "    smooth pathway to front door_True  Well-lit path to entrance_True  \\\n",
       "0                                   0                               0   \n",
       "1                                   0                               0   \n",
       "2                                   0                               0   \n",
       "3                                   0                               0   \n",
       "4                                   0                               0   \n",
       "\n",
       "   Disabled parking spot_True  Wide clearance to bed_True  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   Accessible-height bed_True  Fixed grab bars for shower & toilet_True  \\\n",
       "0                           0                                         0   \n",
       "1                           0                                         0   \n",
       "2                           0                                         0   \n",
       "3                           0                                         0   \n",
       "4                           0                                         0   \n",
       "\n",
       "   Bathtub with shower chair_True  Roll-in shower with chair_True  \\\n",
       "0                               0                               0   \n",
       "1                               0                               0   \n",
       "2                               0                               0   \n",
       "3                               0                               0   \n",
       "4                               0                               0   \n",
       "\n",
       "   Accessible-height toilet_True  Wide clearance to shower & toilet_True  \\\n",
       "0                              0                                       0   \n",
       "1                              0                                       0   \n",
       "2                              0                                       0   \n",
       "3                              0                                       0   \n",
       "4                              0                                       0   \n",
       "\n",
       "   Wide entryway_True  Waterfront_True  Handheld shower head_True  \\\n",
       "0                   0                0                          0   \n",
       "1                   0                0                          0   \n",
       "2                   0                0                          0   \n",
       "3                   0                0                          0   \n",
       "4                   0                0                          0   \n",
       "\n",
       "   thumbnail_url_str_1  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_log_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a84f80-3d3a-4aa8-9991-2fff91c02a45",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c77a6d1c-acfb-4b45-b1dd-158549deae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_preds = pd.Series(model.predict(test_X_log_dummy.values,num_iteration=model.best_iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "930a3cda-5e48-492c-bea5-0950adb95376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub[\"y\"].isnull().sum()= 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>185.311747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>106.126052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>148.551651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>168.563524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>83.383462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18523</th>\n",
       "      <td>18523</td>\n",
       "      <td>212.222123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18524</th>\n",
       "      <td>18524</td>\n",
       "      <td>76.352099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18525</th>\n",
       "      <td>18525</td>\n",
       "      <td>118.671890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18526</th>\n",
       "      <td>18526</td>\n",
       "      <td>85.680771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18527</th>\n",
       "      <td>18527</td>\n",
       "      <td>45.694371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18528 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id           y\n",
       "0          0  185.311747\n",
       "1          1  106.126052\n",
       "2          2  148.551651\n",
       "3          3  168.563524\n",
       "4          4   83.383462\n",
       "...      ...         ...\n",
       "18523  18523  212.222123\n",
       "18524  18524   76.352099\n",
       "18525  18525  118.671890\n",
       "18526  18526   85.680771\n",
       "18527  18527   45.694371\n",
       "\n",
       "[18528 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit用のCSVを作成\n",
    "sub = pd.DataFrame({\"id\":original_test_data['id'], \"y\":sub_preds})\n",
    "print('sub[\"y\"].isnull().sum()=', sub['y'].isnull().sum())\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bef50a59-40c1-48ab-91ce-66a341b5dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('fifth_submission.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b17741-16aa-4a39-8277-20b4e0604637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('ukita_main_env': conda)",
   "language": "python",
   "name": "python395jvsc74a57bd0c19bd4dc0949b9af5049c50e337ed6e21b7d6fbec491433b163f7fe7b877fba9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
